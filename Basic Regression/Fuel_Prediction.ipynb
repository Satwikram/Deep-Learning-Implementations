{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fuel Prediction.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNinb/0ug4JWWsryVlTo5g9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Satwikram/Deep-Learning-Notebooks/blob/master/Basic%20Regression/Fuel_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHJoHVVsUy3j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "@Author: Satwik Ram K\n",
        "\n",
        "Basic Regression using Tensorflow\n",
        "\n",
        "\"\"\"\n",
        "import pathlib\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns"
      ],
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6wuhRTBVLSu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c2c023c1-2e8f-4c57-d609-f804352575a2"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s437xOy3VaWI",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "5c719020-59e4-44a5-9c1e-be222e97aad6"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.upload()\n"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-720b944c-b0cb-44f3-b01b-7940423957a2\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-720b944c-b0cb-44f3-b01b-7940423957a2\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle (1).json\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"satwikram\",\"key\":\"06c98063bdd0e68efaf2312bfe2c72df\"}'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fra3xLb2WdeN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "20e9df15-9a60-4c33-d8dd-697f08e955a4"
      },
      "source": [
        "! mkdir ~/.kaggle\n",
        "\n",
        "\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ljxCwBtWpPV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8f909152-7959-43e8-ab43-2f28b56e83f4"
      },
      "source": [
        "! kaggle datasets download -d uciml/autompg-dataset"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "autompg-dataset.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXnohSWjWsud",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "6f8edb98-85ec-49cc-e0af-5b250ab16768"
      },
      "source": [
        "! unzip /content/autompg-dataset.zip"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/autompg-dataset.zip\n",
            "replace auto-mpg.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dHPzMCdDW4DF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = pd.read_csv('/content/auto-mpg.csv')"
      ],
      "execution_count": 201,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3eL2hbDXJ8B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "8cb3fe73-d3db-4e5f-a942-4d371001a6a6"
      },
      "source": [
        "dataset.head()"
      ],
      "execution_count": 202,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mpg</th>\n",
              "      <th>cylinders</th>\n",
              "      <th>displacement</th>\n",
              "      <th>horsepower</th>\n",
              "      <th>weight</th>\n",
              "      <th>acceleration</th>\n",
              "      <th>model year</th>\n",
              "      <th>origin</th>\n",
              "      <th>car name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>18.0</td>\n",
              "      <td>8</td>\n",
              "      <td>307.0</td>\n",
              "      <td>130</td>\n",
              "      <td>3504</td>\n",
              "      <td>12.0</td>\n",
              "      <td>70</td>\n",
              "      <td>1</td>\n",
              "      <td>chevrolet chevelle malibu</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>15.0</td>\n",
              "      <td>8</td>\n",
              "      <td>350.0</td>\n",
              "      <td>165</td>\n",
              "      <td>3693</td>\n",
              "      <td>11.5</td>\n",
              "      <td>70</td>\n",
              "      <td>1</td>\n",
              "      <td>buick skylark 320</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>18.0</td>\n",
              "      <td>8</td>\n",
              "      <td>318.0</td>\n",
              "      <td>150</td>\n",
              "      <td>3436</td>\n",
              "      <td>11.0</td>\n",
              "      <td>70</td>\n",
              "      <td>1</td>\n",
              "      <td>plymouth satellite</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>16.0</td>\n",
              "      <td>8</td>\n",
              "      <td>304.0</td>\n",
              "      <td>150</td>\n",
              "      <td>3433</td>\n",
              "      <td>12.0</td>\n",
              "      <td>70</td>\n",
              "      <td>1</td>\n",
              "      <td>amc rebel sst</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>17.0</td>\n",
              "      <td>8</td>\n",
              "      <td>302.0</td>\n",
              "      <td>140</td>\n",
              "      <td>3449</td>\n",
              "      <td>10.5</td>\n",
              "      <td>70</td>\n",
              "      <td>1</td>\n",
              "      <td>ford torino</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    mpg  cylinders  displacement  ... model year  origin                   car name\n",
              "0  18.0          8         307.0  ...         70       1  chevrolet chevelle malibu\n",
              "1  15.0          8         350.0  ...         70       1          buick skylark 320\n",
              "2  18.0          8         318.0  ...         70       1         plymouth satellite\n",
              "3  16.0          8         304.0  ...         70       1              amc rebel sst\n",
              "4  17.0          8         302.0  ...         70       1                ford torino\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 202
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTL4oGwXXMWV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "colum_names = dataset.columns"
      ],
      "execution_count": 203,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FNHdEScXUk-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "0190a6dc-61fb-4e76-8854-8db14c751cff"
      },
      "source": [
        "colum_names"
      ],
      "execution_count": 204,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['mpg', 'cylinders', 'displacement', 'horsepower', 'weight',\n",
              "       'acceleration', 'model year', 'origin', 'car name'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 204
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M362E2B2XeAl",
        "colab_type": "text"
      },
      "source": [
        "Clean the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "By_uPve3XWI0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "d5b63fab-fc20-4fb9-8c62-274d004688e8"
      },
      "source": [
        "dataset.isna().sum()"
      ],
      "execution_count": 205,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "mpg             0\n",
              "cylinders       0\n",
              "displacement    0\n",
              "horsepower      0\n",
              "weight          0\n",
              "acceleration    0\n",
              "model year      0\n",
              "origin          0\n",
              "car name        0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 205
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HoPOznA7YKsf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "d304e2a6-fffc-4bc9-8726-818b4b2f2996"
      },
      "source": [
        "dataset.info()"
      ],
      "execution_count": 206,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 398 entries, 0 to 397\n",
            "Data columns (total 9 columns):\n",
            " #   Column        Non-Null Count  Dtype  \n",
            "---  ------        --------------  -----  \n",
            " 0   mpg           398 non-null    float64\n",
            " 1   cylinders     398 non-null    int64  \n",
            " 2   displacement  398 non-null    float64\n",
            " 3   horsepower    398 non-null    object \n",
            " 4   weight        398 non-null    int64  \n",
            " 5   acceleration  398 non-null    float64\n",
            " 6   model year    398 non-null    int64  \n",
            " 7   origin        398 non-null    int64  \n",
            " 8   car name      398 non-null    object \n",
            "dtypes: float64(3), int64(4), object(2)\n",
            "memory usage: 28.1+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQXJr4coYdyz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "d525ced0-caa0-4647-980d-c95e027143c6"
      },
      "source": [
        "dataset['horsepower']"
      ],
      "execution_count": 207,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      130\n",
              "1      165\n",
              "2      150\n",
              "3      150\n",
              "4      140\n",
              "      ... \n",
              "393     86\n",
              "394     52\n",
              "395     84\n",
              "396     79\n",
              "397     82\n",
              "Name: horsepower, Length: 398, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 207
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LId_bznnYjx4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "05433f2a-38bf-4ef1-8289-b9cda7750071"
      },
      "source": [
        "dataset['car name'].unique()"
      ],
      "execution_count": 208,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['chevrolet chevelle malibu', 'buick skylark 320',\n",
              "       'plymouth satellite', 'amc rebel sst', 'ford torino',\n",
              "       'ford galaxie 500', 'chevrolet impala', 'plymouth fury iii',\n",
              "       'pontiac catalina', 'amc ambassador dpl', 'dodge challenger se',\n",
              "       \"plymouth 'cuda 340\", 'chevrolet monte carlo',\n",
              "       'buick estate wagon (sw)', 'toyota corona mark ii',\n",
              "       'plymouth duster', 'amc hornet', 'ford maverick', 'datsun pl510',\n",
              "       'volkswagen 1131 deluxe sedan', 'peugeot 504', 'audi 100 ls',\n",
              "       'saab 99e', 'bmw 2002', 'amc gremlin', 'ford f250', 'chevy c20',\n",
              "       'dodge d200', 'hi 1200d', 'chevrolet vega 2300', 'toyota corona',\n",
              "       'ford pinto', 'plymouth satellite custom', 'ford torino 500',\n",
              "       'amc matador', 'pontiac catalina brougham', 'dodge monaco (sw)',\n",
              "       'ford country squire (sw)', 'pontiac safari (sw)',\n",
              "       'amc hornet sportabout (sw)', 'chevrolet vega (sw)',\n",
              "       'pontiac firebird', 'ford mustang', 'mercury capri 2000',\n",
              "       'opel 1900', 'peugeot 304', 'fiat 124b', 'toyota corolla 1200',\n",
              "       'datsun 1200', 'volkswagen model 111', 'plymouth cricket',\n",
              "       'toyota corona hardtop', 'dodge colt hardtop', 'volkswagen type 3',\n",
              "       'chevrolet vega', 'ford pinto runabout', 'amc ambassador sst',\n",
              "       'mercury marquis', 'buick lesabre custom',\n",
              "       'oldsmobile delta 88 royale', 'chrysler newport royal',\n",
              "       'mazda rx2 coupe', 'amc matador (sw)',\n",
              "       'chevrolet chevelle concours (sw)', 'ford gran torino (sw)',\n",
              "       'plymouth satellite custom (sw)', 'volvo 145e (sw)',\n",
              "       'volkswagen 411 (sw)', 'peugeot 504 (sw)', 'renault 12 (sw)',\n",
              "       'ford pinto (sw)', 'datsun 510 (sw)',\n",
              "       'toyouta corona mark ii (sw)', 'dodge colt (sw)',\n",
              "       'toyota corolla 1600 (sw)', 'buick century 350',\n",
              "       'chevrolet malibu', 'ford gran torino', 'dodge coronet custom',\n",
              "       'mercury marquis brougham', 'chevrolet caprice classic',\n",
              "       'ford ltd', 'plymouth fury gran sedan',\n",
              "       'chrysler new yorker brougham', 'buick electra 225 custom',\n",
              "       'amc ambassador brougham', 'plymouth valiant',\n",
              "       'chevrolet nova custom', 'volkswagen super beetle', 'ford country',\n",
              "       'plymouth custom suburb', 'oldsmobile vista cruiser',\n",
              "       'toyota carina', 'datsun 610', 'maxda rx3', 'mercury capri v6',\n",
              "       'fiat 124 sport coupe', 'chevrolet monte carlo s',\n",
              "       'pontiac grand prix', 'fiat 128', 'opel manta', 'audi 100ls',\n",
              "       'volvo 144ea', 'dodge dart custom', 'saab 99le', 'toyota mark ii',\n",
              "       'oldsmobile omega', 'chevrolet nova', 'datsun b210',\n",
              "       'chevrolet chevelle malibu classic', 'plymouth satellite sebring',\n",
              "       'buick century luxus (sw)', 'dodge coronet custom (sw)',\n",
              "       'audi fox', 'volkswagen dasher', 'datsun 710', 'dodge colt',\n",
              "       'fiat 124 tc', 'honda civic', 'subaru', 'fiat x1.9',\n",
              "       'plymouth valiant custom', 'mercury monarch', 'chevrolet bel air',\n",
              "       'plymouth grand fury', 'buick century',\n",
              "       'chevroelt chevelle malibu', 'plymouth fury', 'buick skyhawk',\n",
              "       'chevrolet monza 2+2', 'ford mustang ii', 'toyota corolla',\n",
              "       'pontiac astro', 'volkswagen rabbit', 'amc pacer', 'volvo 244dl',\n",
              "       'honda civic cvcc', 'fiat 131', 'capri ii', 'renault 12tl',\n",
              "       'dodge coronet brougham', 'chevrolet chevette', 'chevrolet woody',\n",
              "       'vw rabbit', 'dodge aspen se', 'ford granada ghia',\n",
              "       'pontiac ventura sj', 'amc pacer d/l', 'datsun b-210', 'volvo 245',\n",
              "       'plymouth volare premier v8', 'mercedes-benz 280s',\n",
              "       'cadillac seville', 'chevy c10', 'ford f108', 'dodge d100',\n",
              "       'honda accord cvcc', 'buick opel isuzu deluxe', 'renault 5 gtl',\n",
              "       'plymouth arrow gs', 'datsun f-10 hatchback',\n",
              "       'oldsmobile cutlass supreme', 'dodge monaco brougham',\n",
              "       'mercury cougar brougham', 'chevrolet concours', 'buick skylark',\n",
              "       'plymouth volare custom', 'ford granada', 'pontiac grand prix lj',\n",
              "       'chevrolet monte carlo landau', 'chrysler cordoba',\n",
              "       'ford thunderbird', 'volkswagen rabbit custom',\n",
              "       'pontiac sunbird coupe', 'toyota corolla liftback',\n",
              "       'ford mustang ii 2+2', 'dodge colt m/m', 'subaru dl', 'datsun 810',\n",
              "       'bmw 320i', 'mazda rx-4', 'volkswagen rabbit custom diesel',\n",
              "       'ford fiesta', 'mazda glc deluxe', 'datsun b210 gx',\n",
              "       'oldsmobile cutlass salon brougham', 'dodge diplomat',\n",
              "       'mercury monarch ghia', 'pontiac phoenix lj',\n",
              "       'ford fairmont (auto)', 'ford fairmont (man)', 'plymouth volare',\n",
              "       'amc concord', 'buick century special', 'mercury zephyr',\n",
              "       'dodge aspen', 'amc concord d/l',\n",
              "       'buick regal sport coupe (turbo)', 'ford futura',\n",
              "       'dodge magnum xe', 'datsun 510', 'dodge omni',\n",
              "       'toyota celica gt liftback', 'plymouth sapporo',\n",
              "       'oldsmobile starfire sx', 'datsun 200-sx', 'audi 5000',\n",
              "       'volvo 264gl', 'saab 99gle', 'peugeot 604sl',\n",
              "       'volkswagen scirocco', 'honda accord lx', 'pontiac lemans v6',\n",
              "       'mercury zephyr 6', 'ford fairmont 4', 'amc concord dl 6',\n",
              "       'dodge aspen 6', 'ford ltd landau', 'mercury grand marquis',\n",
              "       'dodge st. regis', 'chevrolet malibu classic (sw)',\n",
              "       'chrysler lebaron town @ country (sw)', 'vw rabbit custom',\n",
              "       'maxda glc deluxe', 'dodge colt hatchback custom', 'amc spirit dl',\n",
              "       'mercedes benz 300d', 'cadillac eldorado', 'plymouth horizon',\n",
              "       'plymouth horizon tc3', 'datsun 210', 'fiat strada custom',\n",
              "       'buick skylark limited', 'chevrolet citation',\n",
              "       'oldsmobile omega brougham', 'pontiac phoenix',\n",
              "       'toyota corolla tercel', 'datsun 310', 'ford fairmont',\n",
              "       'audi 4000', 'toyota corona liftback', 'mazda 626',\n",
              "       'datsun 510 hatchback', 'mazda glc', 'vw rabbit c (diesel)',\n",
              "       'vw dasher (diesel)', 'audi 5000s (diesel)', 'mercedes-benz 240d',\n",
              "       'honda civic 1500 gl', 'renault lecar deluxe', 'vokswagen rabbit',\n",
              "       'datsun 280-zx', 'mazda rx-7 gs', 'triumph tr7 coupe',\n",
              "       'ford mustang cobra', 'honda accord', 'plymouth reliant',\n",
              "       'dodge aries wagon (sw)', 'toyota starlet', 'plymouth champ',\n",
              "       'honda civic 1300', 'datsun 210 mpg', 'toyota tercel',\n",
              "       'mazda glc 4', 'plymouth horizon 4', 'ford escort 4w',\n",
              "       'ford escort 2h', 'volkswagen jetta', 'renault 18i',\n",
              "       'honda prelude', 'datsun 200sx', 'peugeot 505s turbo diesel',\n",
              "       'volvo diesel', 'toyota cressida', 'datsun 810 maxima',\n",
              "       'oldsmobile cutlass ls', 'ford granada gl',\n",
              "       'chrysler lebaron salon', 'chevrolet cavalier',\n",
              "       'chevrolet cavalier wagon', 'chevrolet cavalier 2-door',\n",
              "       'pontiac j2000 se hatchback', 'dodge aries se',\n",
              "       'ford fairmont futura', 'amc concord dl', 'volkswagen rabbit l',\n",
              "       'mazda glc custom l', 'mazda glc custom', 'plymouth horizon miser',\n",
              "       'mercury lynx l', 'nissan stanza xe', 'honda civic (auto)',\n",
              "       'datsun 310 gx', 'buick century limited',\n",
              "       'oldsmobile cutlass ciera (diesel)', 'chrysler lebaron medallion',\n",
              "       'ford granada l', 'toyota celica gt', 'dodge charger 2.2',\n",
              "       'chevrolet camaro', 'ford mustang gl', 'vw pickup',\n",
              "       'dodge rampage', 'ford ranger', 'chevy s-10'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 208
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdL9SDYqY_Rh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "5f806434-4835-4473-92e0-95d572ed4d8c"
      },
      "source": [
        "for i in range(len(dataset['horsepower'])):\n",
        "  if dataset['horsepower'][i]  == '?':\n",
        "    print(\"None\",i)\n",
        "    dataset['horsepower'][i] = np.nan\n",
        "  \n"
      ],
      "execution_count": 209,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "None 32\n",
            "None 126\n",
            "None 330\n",
            "None 336\n",
            "None 354\n",
            "None 374\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QqbBT-CcZod6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "cb24770c-16f8-418f-cef0-b82c9ce3fb63"
      },
      "source": [
        "dataset.isna().sum()"
      ],
      "execution_count": 210,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "mpg             0\n",
              "cylinders       0\n",
              "displacement    0\n",
              "horsepower      6\n",
              "weight          0\n",
              "acceleration    0\n",
              "model year      0\n",
              "origin          0\n",
              "car name        0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 210
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jd_DioGafzn5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset.dropna(inplace = True)"
      ],
      "execution_count": 211,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmCjy7LDbpYz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "dbef0508-5f13-4d9d-f130-310839044925"
      },
      "source": [
        "dataset.info()"
      ],
      "execution_count": 212,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 392 entries, 0 to 397\n",
            "Data columns (total 9 columns):\n",
            " #   Column        Non-Null Count  Dtype  \n",
            "---  ------        --------------  -----  \n",
            " 0   mpg           392 non-null    float64\n",
            " 1   cylinders     392 non-null    int64  \n",
            " 2   displacement  392 non-null    float64\n",
            " 3   horsepower    392 non-null    object \n",
            " 4   weight        392 non-null    int64  \n",
            " 5   acceleration  392 non-null    float64\n",
            " 6   model year    392 non-null    int64  \n",
            " 7   origin        392 non-null    int64  \n",
            " 8   car name      392 non-null    object \n",
            "dtypes: float64(3), int64(4), object(2)\n",
            "memory usage: 30.6+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Z5SzkTrb33x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "horse = dataset['horsepower']"
      ],
      "execution_count": 213,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JzWaboxbcNuC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "horse = np.array(horse)"
      ],
      "execution_count": 214,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DiofGyI6cRhZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(len(horse)):\n",
        "  horse[i] = int(horse[i])"
      ],
      "execution_count": 215,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kUi97KCqcUTy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "horse = horse.astype('int')"
      ],
      "execution_count": 216,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9L43lKxscu5a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "horse = pd.DataFrame(horse)"
      ],
      "execution_count": 217,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VcarfSg3c3VE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "802ab18c-a5fd-4626-8714-caf1ca71f445"
      },
      "source": [
        "type(horse)"
      ],
      "execution_count": 218,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.frame.DataFrame"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 218
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvEZSbVEc5Px",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "3766c9ef-af79-45ae-e225-8cc215800baa"
      },
      "source": [
        "print(horse)"
      ],
      "execution_count": 219,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       0\n",
            "0    130\n",
            "1    165\n",
            "2    150\n",
            "3    150\n",
            "4    140\n",
            "..   ...\n",
            "387   86\n",
            "388   52\n",
            "389   84\n",
            "390   79\n",
            "391   82\n",
            "\n",
            "[392 rows x 1 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uz2xF8zGhuDx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset.drop('horsepower', axis = 1, inplace = True)"
      ],
      "execution_count": 227,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WdNn292hc7q1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = pd.concat([dataset, horse], axis = 1)"
      ],
      "execution_count": 228,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WEG-smJMhSb4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4d86f138-97c0-42cb-9e38-4e542ec1c8a8"
      },
      "source": [
        "len(dataset)"
      ],
      "execution_count": 222,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "392"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 222
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tP4qUg7yiOc_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5f14cdf4-aace-407a-80a9-213cf0b6f23b"
      },
      "source": [
        "len(horse)"
      ],
      "execution_count": 223,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "392"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 223
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FocSAlTbir7a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "84d671ff-919c-4bf9-bfd8-7043627ea421"
      },
      "source": [
        "dataset.isna().sum()"
      ],
      "execution_count": 229,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "mpg             6\n",
              "cylinders       6\n",
              "displacement    6\n",
              "weight          6\n",
              "acceleration    6\n",
              "model year      6\n",
              "origin          6\n",
              "car name        6\n",
              "0               6\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 229
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ye7cURLHjLvO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset.dropna(inplace = True)"
      ],
      "execution_count": 230,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYhCUwgNjSPm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "db2d9cbe-91fb-4da0-85cf-a22331dad11d"
      },
      "source": [
        "dataset.head()"
      ],
      "execution_count": 235,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mpg</th>\n",
              "      <th>cylinders</th>\n",
              "      <th>displacement</th>\n",
              "      <th>weight</th>\n",
              "      <th>acceleration</th>\n",
              "      <th>model year</th>\n",
              "      <th>origin</th>\n",
              "      <th>car name</th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>18.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>307.0</td>\n",
              "      <td>3504.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>chevrolet chevelle malibu</td>\n",
              "      <td>130.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>15.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>350.0</td>\n",
              "      <td>3693.0</td>\n",
              "      <td>11.5</td>\n",
              "      <td>70.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>buick skylark 320</td>\n",
              "      <td>165.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>18.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>318.0</td>\n",
              "      <td>3436.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>plymouth satellite</td>\n",
              "      <td>150.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>16.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>304.0</td>\n",
              "      <td>3433.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>amc rebel sst</td>\n",
              "      <td>150.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>17.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>302.0</td>\n",
              "      <td>3449.0</td>\n",
              "      <td>10.5</td>\n",
              "      <td>70.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>ford torino</td>\n",
              "      <td>140.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    mpg  cylinders  displacement  ...  origin                   car name      0\n",
              "0  18.0        8.0         307.0  ...     1.0  chevrolet chevelle malibu  130.0\n",
              "1  15.0        8.0         350.0  ...     1.0          buick skylark 320  165.0\n",
              "2  18.0        8.0         318.0  ...     1.0         plymouth satellite  150.0\n",
              "3  16.0        8.0         304.0  ...     1.0              amc rebel sst  150.0\n",
              "4  17.0        8.0         302.0  ...     1.0                ford torino  140.0\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 235
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blEg8iUhje0V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset.rename(columns = {0:\"horsepower\"}, inplace = True)"
      ],
      "execution_count": 244,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TgYmOcQ4joas",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "206640b6-fa42-40ce-e514-2e0e515fd3b0"
      },
      "source": [
        "dataset.info()"
      ],
      "execution_count": 245,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 386 entries, horsepower to 391\n",
            "Data columns (total 9 columns):\n",
            " #   Column        Non-Null Count  Dtype  \n",
            "---  ------        --------------  -----  \n",
            " 0   mpg           386 non-null    float64\n",
            " 1   cylinders     386 non-null    float64\n",
            " 2   displacement  386 non-null    float64\n",
            " 3   weight        386 non-null    float64\n",
            " 4   acceleration  386 non-null    float64\n",
            " 5   model year    386 non-null    float64\n",
            " 6   origin        386 non-null    float64\n",
            " 7   car name      386 non-null    object \n",
            " 8   horsepower    386 non-null    float64\n",
            "dtypes: float64(8), object(1)\n",
            "memory usage: 30.2+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5lkpflTmkSr3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset.drop('car name', inplace = True, axis = 1)"
      ],
      "execution_count": 247,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRcy5rztkxps",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "ad7a26e3-3fd5-41e4-970b-9bbb976e580d"
      },
      "source": [
        "dataset.describe()"
      ],
      "execution_count": 248,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mpg</th>\n",
              "      <th>cylinders</th>\n",
              "      <th>displacement</th>\n",
              "      <th>weight</th>\n",
              "      <th>acceleration</th>\n",
              "      <th>model year</th>\n",
              "      <th>origin</th>\n",
              "      <th>horsepower</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>386.000000</td>\n",
              "      <td>386.000000</td>\n",
              "      <td>386.000000</td>\n",
              "      <td>386.000000</td>\n",
              "      <td>386.000000</td>\n",
              "      <td>386.000000</td>\n",
              "      <td>386.000000</td>\n",
              "      <td>386.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>23.320725</td>\n",
              "      <td>5.494819</td>\n",
              "      <td>195.459845</td>\n",
              "      <td>2983.686528</td>\n",
              "      <td>15.505440</td>\n",
              "      <td>75.886010</td>\n",
              "      <td>1.582902</td>\n",
              "      <td>104.559585</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>7.765096</td>\n",
              "      <td>1.709021</td>\n",
              "      <td>105.092187</td>\n",
              "      <td>853.830503</td>\n",
              "      <td>2.721057</td>\n",
              "      <td>3.634247</td>\n",
              "      <td>0.808794</td>\n",
              "      <td>38.728731</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>9.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>68.000000</td>\n",
              "      <td>1613.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>70.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>46.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>17.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>105.000000</td>\n",
              "      <td>2223.750000</td>\n",
              "      <td>13.725000</td>\n",
              "      <td>73.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>75.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>22.150000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>151.000000</td>\n",
              "      <td>2822.500000</td>\n",
              "      <td>15.500000</td>\n",
              "      <td>76.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>93.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>29.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>302.000000</td>\n",
              "      <td>3627.500000</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>79.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>128.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>46.600000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>455.000000</td>\n",
              "      <td>5140.000000</td>\n",
              "      <td>24.800000</td>\n",
              "      <td>82.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>230.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              mpg   cylinders  displacement  ...  model year      origin  horsepower\n",
              "count  386.000000  386.000000    386.000000  ...  386.000000  386.000000  386.000000\n",
              "mean    23.320725    5.494819    195.459845  ...   75.886010    1.582902  104.559585\n",
              "std      7.765096    1.709021    105.092187  ...    3.634247    0.808794   38.728731\n",
              "min      9.000000    3.000000     68.000000  ...   70.000000    1.000000   46.000000\n",
              "25%     17.000000    4.000000    105.000000  ...   73.000000    1.000000   75.000000\n",
              "50%     22.150000    4.000000    151.000000  ...   76.000000    1.000000   93.500000\n",
              "75%     29.000000    8.000000    302.000000  ...   79.000000    2.000000  128.000000\n",
              "max     46.600000    8.000000    455.000000  ...   82.000000    3.000000  230.000000\n",
              "\n",
              "[8 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 248
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_OEhIKoplpUJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = dataset.drop('mpg', axis = 1)\n",
        "y = dataset['mpg']"
      ],
      "execution_count": 249,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdnbN_rBmLz0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "f120a0aa-3e0a-44f9-ed70-299bcaede6b6"
      },
      "source": [
        "x"
      ],
      "execution_count": 250,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cylinders</th>\n",
              "      <th>displacement</th>\n",
              "      <th>weight</th>\n",
              "      <th>acceleration</th>\n",
              "      <th>model year</th>\n",
              "      <th>origin</th>\n",
              "      <th>horsepower</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>horsepower</th>\n",
              "      <td>8.0</td>\n",
              "      <td>307.0</td>\n",
              "      <td>3504.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>130.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8.0</td>\n",
              "      <td>350.0</td>\n",
              "      <td>3693.0</td>\n",
              "      <td>11.5</td>\n",
              "      <td>70.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>165.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8.0</td>\n",
              "      <td>318.0</td>\n",
              "      <td>3436.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>150.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8.0</td>\n",
              "      <td>304.0</td>\n",
              "      <td>3433.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>150.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8.0</td>\n",
              "      <td>302.0</td>\n",
              "      <td>3449.0</td>\n",
              "      <td>10.5</td>\n",
              "      <td>70.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>140.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>387</th>\n",
              "      <td>6.0</td>\n",
              "      <td>262.0</td>\n",
              "      <td>3015.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>82.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>86.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>388</th>\n",
              "      <td>4.0</td>\n",
              "      <td>156.0</td>\n",
              "      <td>2585.0</td>\n",
              "      <td>14.5</td>\n",
              "      <td>82.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>52.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>389</th>\n",
              "      <td>6.0</td>\n",
              "      <td>232.0</td>\n",
              "      <td>2835.0</td>\n",
              "      <td>14.7</td>\n",
              "      <td>82.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>84.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>390</th>\n",
              "      <td>4.0</td>\n",
              "      <td>144.0</td>\n",
              "      <td>2665.0</td>\n",
              "      <td>13.9</td>\n",
              "      <td>82.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>79.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>391</th>\n",
              "      <td>4.0</td>\n",
              "      <td>135.0</td>\n",
              "      <td>2370.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>82.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>82.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>386 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            cylinders  displacement  weight  ...  model year  origin  horsepower\n",
              "horsepower        8.0         307.0  3504.0  ...        70.0     1.0       130.0\n",
              "1                 8.0         350.0  3693.0  ...        70.0     1.0       165.0\n",
              "2                 8.0         318.0  3436.0  ...        70.0     1.0       150.0\n",
              "3                 8.0         304.0  3433.0  ...        70.0     1.0       150.0\n",
              "4                 8.0         302.0  3449.0  ...        70.0     1.0       140.0\n",
              "...               ...           ...     ...  ...         ...     ...         ...\n",
              "387               6.0         262.0  3015.0  ...        82.0     1.0        86.0\n",
              "388               4.0         156.0  2585.0  ...        82.0     1.0        52.0\n",
              "389               6.0         232.0  2835.0  ...        82.0     1.0        84.0\n",
              "390               4.0         144.0  2665.0  ...        82.0     3.0        79.0\n",
              "391               4.0         135.0  2370.0  ...        82.0     1.0        82.0\n",
              "\n",
              "[386 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 250
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BnHXTZVsk396",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Splitting the dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state = 388, test_size = 0.2)"
      ],
      "execution_count": 251,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sriST_82mWDs",
        "colab_type": "text"
      },
      "source": [
        "Normalizing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BlQxekramVEP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()"
      ],
      "execution_count": 252,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ml-NYG7vmgW3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = sc.fit_transform(x_train)\n",
        "x_test = sc.transform(x_test)"
      ],
      "execution_count": 253,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xUSsrgrxm011",
        "colab_type": "text"
      },
      "source": [
        "Building the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRp9BFCamnwU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model():\n",
        "  model = keras.Sequential([\n",
        "    layers.Dense(64, activation='relu', input_dim = 7 ),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(1)\n",
        "  ])\n",
        "\n",
        "  optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
        "\n",
        "  model.compile(loss='mse',\n",
        "                optimizer=optimizer,\n",
        "                metrics=['mae', 'mse'])\n",
        "  return model"
      ],
      "execution_count": 275,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Y79QmfPnB6v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = build_model()"
      ],
      "execution_count": 276,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCbVVZQrnNxk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "114418a0-e071-4a3c-a34e-03512cc1c4b5"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 277,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_10 (Dense)             (None, 64)                512       \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 4,737\n",
            "Trainable params: 4,737\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQlvYSwRnQhr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3d0d0f4f-0d12-4ba0-97fd-bb865bcae57b"
      },
      "source": [
        "EPOCHS = 1000\n",
        "\n",
        "history = model.fit(x_train, y_train,epochs=EPOCHS, validation_split = 0.2, verbose=1)"
      ],
      "execution_count": 278,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 591.6518 - mae: 22.9834 - mse: 591.6518 - val_loss: 561.3963 - val_mae: 22.2899 - val_mse: 561.3963\n",
            "Epoch 2/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 553.5474 - mae: 22.0314 - mse: 553.5474 - val_loss: 526.3509 - val_mae: 21.3617 - val_mse: 526.3509\n",
            "Epoch 3/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 516.7152 - mae: 21.0701 - mse: 516.7152 - val_loss: 488.0927 - val_mae: 20.3401 - val_mse: 488.0927\n",
            "Epoch 4/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 475.8940 - mae: 19.9895 - mse: 475.8940 - val_loss: 445.5249 - val_mae: 19.1688 - val_mse: 445.5249\n",
            "Epoch 5/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 430.6927 - mae: 18.7459 - mse: 430.6927 - val_loss: 399.0595 - val_mae: 17.8499 - val_mse: 399.0595\n",
            "Epoch 6/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 380.8524 - mae: 17.3662 - mse: 380.8524 - val_loss: 347.4949 - val_mae: 16.4959 - val_mse: 347.4949\n",
            "Epoch 7/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 327.2538 - mae: 15.9368 - mse: 327.2538 - val_loss: 294.2402 - val_mae: 15.0784 - val_mse: 294.2402\n",
            "Epoch 8/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 272.8477 - mae: 14.4392 - mse: 272.8477 - val_loss: 240.4752 - val_mae: 13.6247 - val_mse: 240.4752\n",
            "Epoch 9/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 218.4870 - mae: 12.9155 - mse: 218.4870 - val_loss: 187.2802 - val_mae: 12.0464 - val_mse: 187.2802\n",
            "Epoch 10/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 167.4803 - mae: 11.2994 - mse: 167.4803 - val_loss: 139.4766 - val_mae: 10.3751 - val_mse: 139.4766\n",
            "Epoch 11/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 122.1522 - mae: 9.6132 - mse: 122.1522 - val_loss: 97.3944 - val_mae: 8.6100 - val_mse: 97.3944\n",
            "Epoch 12/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 84.0241 - mae: 7.9310 - mse: 84.0241 - val_loss: 64.1694 - val_mae: 6.8933 - val_mse: 64.1694\n",
            "Epoch 13/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 55.3326 - mae: 6.3397 - mse: 55.3326 - val_loss: 40.2918 - val_mae: 5.3504 - val_mse: 40.2918\n",
            "Epoch 14/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 37.4222 - mae: 5.0744 - mse: 37.4222 - val_loss: 28.4629 - val_mae: 4.4473 - val_mse: 28.4629\n",
            "Epoch 15/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 28.8837 - mae: 4.3806 - mse: 28.8837 - val_loss: 22.8015 - val_mae: 3.9827 - val_mse: 22.8015\n",
            "Epoch 16/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 24.8509 - mae: 4.0389 - mse: 24.8509 - val_loss: 20.3186 - val_mae: 3.7455 - val_mse: 20.3186\n",
            "Epoch 17/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 22.3082 - mae: 3.8105 - mse: 22.3082 - val_loss: 19.0479 - val_mae: 3.6287 - val_mse: 19.0479\n",
            "Epoch 18/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 20.3141 - mae: 3.6199 - mse: 20.3141 - val_loss: 17.2370 - val_mae: 3.4206 - val_mse: 17.2370\n",
            "Epoch 19/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 18.6057 - mae: 3.4402 - mse: 18.6057 - val_loss: 16.7631 - val_mae: 3.3702 - val_mse: 16.7631\n",
            "Epoch 20/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 17.2867 - mae: 3.2916 - mse: 17.2867 - val_loss: 16.3820 - val_mae: 3.3046 - val_mse: 16.3820\n",
            "Epoch 21/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 16.1296 - mae: 3.1778 - mse: 16.1296 - val_loss: 15.7135 - val_mae: 3.2102 - val_mse: 15.7135\n",
            "Epoch 22/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 15.1710 - mae: 3.0743 - mse: 15.1710 - val_loss: 14.3581 - val_mae: 2.9921 - val_mse: 14.3581\n",
            "Epoch 23/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 14.3412 - mae: 2.9209 - mse: 14.3412 - val_loss: 14.2688 - val_mae: 2.9980 - val_mse: 14.2688\n",
            "Epoch 24/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 13.4959 - mae: 2.8454 - mse: 13.4959 - val_loss: 14.2345 - val_mae: 2.9593 - val_mse: 14.2345\n",
            "Epoch 25/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 13.1433 - mae: 2.7759 - mse: 13.1433 - val_loss: 13.3941 - val_mae: 2.8494 - val_mse: 13.3941\n",
            "Epoch 26/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 12.5940 - mae: 2.7197 - mse: 12.5940 - val_loss: 12.8756 - val_mae: 2.7587 - val_mse: 12.8756\n",
            "Epoch 27/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 11.9966 - mae: 2.6338 - mse: 11.9966 - val_loss: 12.7635 - val_mae: 2.7158 - val_mse: 12.7635\n",
            "Epoch 28/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 11.6253 - mae: 2.5721 - mse: 11.6253 - val_loss: 12.3456 - val_mae: 2.6434 - val_mse: 12.3456\n",
            "Epoch 29/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 11.3488 - mae: 2.5143 - mse: 11.3488 - val_loss: 11.9096 - val_mae: 2.5743 - val_mse: 11.9096\n",
            "Epoch 30/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 10.7467 - mae: 2.4763 - mse: 10.7467 - val_loss: 11.8872 - val_mae: 2.5479 - val_mse: 11.8872\n",
            "Epoch 31/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 10.5331 - mae: 2.4032 - mse: 10.5331 - val_loss: 11.6238 - val_mae: 2.5369 - val_mse: 11.6238\n",
            "Epoch 32/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 10.5707 - mae: 2.4157 - mse: 10.5707 - val_loss: 11.7576 - val_mae: 2.5522 - val_mse: 11.7576\n",
            "Epoch 33/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 10.1233 - mae: 2.3499 - mse: 10.1233 - val_loss: 11.2029 - val_mae: 2.4406 - val_mse: 11.2029\n",
            "Epoch 34/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 9.9879 - mae: 2.3203 - mse: 9.9879 - val_loss: 11.1977 - val_mae: 2.4304 - val_mse: 11.1977\n",
            "Epoch 35/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 9.6256 - mae: 2.2654 - mse: 9.6256 - val_loss: 10.9667 - val_mae: 2.3629 - val_mse: 10.9667\n",
            "Epoch 36/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 9.6116 - mae: 2.2640 - mse: 9.6116 - val_loss: 10.8729 - val_mae: 2.3828 - val_mse: 10.8729\n",
            "Epoch 37/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 9.1681 - mae: 2.2494 - mse: 9.1681 - val_loss: 10.8625 - val_mae: 2.3238 - val_mse: 10.8625\n",
            "Epoch 38/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 9.2129 - mae: 2.2276 - mse: 9.2129 - val_loss: 10.7746 - val_mae: 2.3490 - val_mse: 10.7746\n",
            "Epoch 39/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 9.2264 - mae: 2.2131 - mse: 9.2264 - val_loss: 10.4813 - val_mae: 2.2870 - val_mse: 10.4813\n",
            "Epoch 40/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 9.0943 - mae: 2.2064 - mse: 9.0943 - val_loss: 10.5213 - val_mae: 2.3136 - val_mse: 10.5213\n",
            "Epoch 41/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 8.9064 - mae: 2.1864 - mse: 8.9064 - val_loss: 10.2673 - val_mae: 2.2396 - val_mse: 10.2673\n",
            "Epoch 42/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 8.9362 - mae: 2.1911 - mse: 8.9362 - val_loss: 10.3994 - val_mae: 2.2757 - val_mse: 10.3994\n",
            "Epoch 43/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 8.8176 - mae: 2.1327 - mse: 8.8176 - val_loss: 10.4175 - val_mae: 2.2664 - val_mse: 10.4175\n",
            "Epoch 44/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 8.4277 - mae: 2.1206 - mse: 8.4277 - val_loss: 10.3088 - val_mae: 2.2395 - val_mse: 10.3088\n",
            "Epoch 45/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 8.3815 - mae: 2.1032 - mse: 8.3815 - val_loss: 10.0297 - val_mae: 2.1872 - val_mse: 10.0297\n",
            "Epoch 46/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 8.3175 - mae: 2.0965 - mse: 8.3175 - val_loss: 10.4692 - val_mae: 2.2958 - val_mse: 10.4692\n",
            "Epoch 47/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 8.3362 - mae: 2.1145 - mse: 8.3362 - val_loss: 9.9879 - val_mae: 2.2000 - val_mse: 9.9879\n",
            "Epoch 48/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 8.0737 - mae: 2.0479 - mse: 8.0737 - val_loss: 9.9543 - val_mae: 2.1877 - val_mse: 9.9543\n",
            "Epoch 49/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 7.9399 - mae: 2.0700 - mse: 7.9399 - val_loss: 10.5754 - val_mae: 2.3286 - val_mse: 10.5754\n",
            "Epoch 50/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 8.0235 - mae: 2.0938 - mse: 8.0235 - val_loss: 9.8522 - val_mae: 2.2195 - val_mse: 9.8522\n",
            "Epoch 51/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 7.9221 - mae: 2.0601 - mse: 7.9221 - val_loss: 10.1607 - val_mae: 2.2221 - val_mse: 10.1607\n",
            "Epoch 52/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 7.8996 - mae: 2.0484 - mse: 7.8996 - val_loss: 9.7359 - val_mae: 2.1383 - val_mse: 9.7359\n",
            "Epoch 53/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 7.8170 - mae: 2.0530 - mse: 7.8170 - val_loss: 9.7302 - val_mae: 2.1942 - val_mse: 9.7302\n",
            "Epoch 54/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.7278 - mae: 2.0253 - mse: 7.7278 - val_loss: 9.8701 - val_mae: 2.1890 - val_mse: 9.8701\n",
            "Epoch 55/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 7.6432 - mae: 2.0184 - mse: 7.6432 - val_loss: 9.7699 - val_mae: 2.2013 - val_mse: 9.7699\n",
            "Epoch 56/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 7.6167 - mae: 2.0006 - mse: 7.6167 - val_loss: 9.7126 - val_mae: 2.1721 - val_mse: 9.7126\n",
            "Epoch 57/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 7.6392 - mae: 2.0053 - mse: 7.6392 - val_loss: 9.6199 - val_mae: 2.1301 - val_mse: 9.6199\n",
            "Epoch 58/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 7.6053 - mae: 2.0059 - mse: 7.6053 - val_loss: 9.5057 - val_mae: 2.1091 - val_mse: 9.5057\n",
            "Epoch 59/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 7.3140 - mae: 1.9789 - mse: 7.3140 - val_loss: 10.0237 - val_mae: 2.2125 - val_mse: 10.0237\n",
            "Epoch 60/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 7.7334 - mae: 2.0391 - mse: 7.7334 - val_loss: 9.6328 - val_mae: 2.1639 - val_mse: 9.6328\n",
            "Epoch 61/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 7.1935 - mae: 1.9452 - mse: 7.1935 - val_loss: 9.3575 - val_mae: 2.1082 - val_mse: 9.3575\n",
            "Epoch 62/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 7.1441 - mae: 1.9414 - mse: 7.1441 - val_loss: 9.8481 - val_mae: 2.2113 - val_mse: 9.8481\n",
            "Epoch 63/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 7.4155 - mae: 1.9518 - mse: 7.4155 - val_loss: 9.4057 - val_mae: 2.1074 - val_mse: 9.4057\n",
            "Epoch 64/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 7.1656 - mae: 1.9339 - mse: 7.1656 - val_loss: 9.8127 - val_mae: 2.1840 - val_mse: 9.8127\n",
            "Epoch 65/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.2883 - mae: 1.9556 - mse: 7.2883 - val_loss: 9.3124 - val_mae: 2.0887 - val_mse: 9.3124\n",
            "Epoch 66/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 7.1159 - mae: 1.9307 - mse: 7.1159 - val_loss: 9.2827 - val_mae: 2.0710 - val_mse: 9.2827\n",
            "Epoch 67/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 7.1918 - mae: 1.9788 - mse: 7.1918 - val_loss: 9.2453 - val_mae: 2.0887 - val_mse: 9.2453\n",
            "Epoch 68/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 6.8096 - mae: 1.8952 - mse: 6.8096 - val_loss: 9.6795 - val_mae: 2.1541 - val_mse: 9.6795\n",
            "Epoch 69/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 6.9585 - mae: 1.8931 - mse: 6.9585 - val_loss: 9.1707 - val_mae: 2.0694 - val_mse: 9.1707\n",
            "Epoch 70/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 6.9529 - mae: 1.9045 - mse: 6.9529 - val_loss: 9.3040 - val_mae: 2.0913 - val_mse: 9.3040\n",
            "Epoch 71/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 6.8959 - mae: 1.9005 - mse: 6.8959 - val_loss: 9.4847 - val_mae: 2.1330 - val_mse: 9.4847\n",
            "Epoch 72/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 6.9230 - mae: 1.9051 - mse: 6.9230 - val_loss: 9.1845 - val_mae: 2.0637 - val_mse: 9.1845\n",
            "Epoch 73/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.9417 - mae: 1.8933 - mse: 6.9417 - val_loss: 9.5280 - val_mae: 2.1203 - val_mse: 9.5280\n",
            "Epoch 74/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 6.7265 - mae: 1.8673 - mse: 6.7265 - val_loss: 9.2087 - val_mae: 2.0544 - val_mse: 9.2087\n",
            "Epoch 75/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 6.7371 - mae: 1.8890 - mse: 6.7371 - val_loss: 9.5171 - val_mae: 2.1320 - val_mse: 9.5171\n",
            "Epoch 76/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 6.7804 - mae: 1.8609 - mse: 6.7804 - val_loss: 9.5358 - val_mae: 2.1143 - val_mse: 9.5358\n",
            "Epoch 77/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 6.6175 - mae: 1.8531 - mse: 6.6175 - val_loss: 9.3928 - val_mae: 2.0900 - val_mse: 9.3928\n",
            "Epoch 78/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 6.8431 - mae: 1.8996 - mse: 6.8431 - val_loss: 9.1555 - val_mae: 2.0413 - val_mse: 9.1555\n",
            "Epoch 79/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 6.6927 - mae: 1.8642 - mse: 6.6927 - val_loss: 9.3025 - val_mae: 2.0790 - val_mse: 9.3025\n",
            "Epoch 80/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 6.5013 - mae: 1.8498 - mse: 6.5013 - val_loss: 9.2146 - val_mae: 2.0492 - val_mse: 9.2146\n",
            "Epoch 81/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 6.7105 - mae: 1.8654 - mse: 6.7105 - val_loss: 9.4211 - val_mae: 2.0858 - val_mse: 9.4211\n",
            "Epoch 82/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.5964 - mae: 1.8640 - mse: 6.5964 - val_loss: 9.3697 - val_mae: 2.0744 - val_mse: 9.3697\n",
            "Epoch 83/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 6.5260 - mae: 1.8755 - mse: 6.5260 - val_loss: 9.1836 - val_mae: 2.0505 - val_mse: 9.1836\n",
            "Epoch 84/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 6.5160 - mae: 1.8433 - mse: 6.5160 - val_loss: 9.4843 - val_mae: 2.1030 - val_mse: 9.4843\n",
            "Epoch 85/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 6.4525 - mae: 1.8130 - mse: 6.4525 - val_loss: 9.2011 - val_mae: 2.0515 - val_mse: 9.2011\n",
            "Epoch 86/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 6.5664 - mae: 1.8421 - mse: 6.5664 - val_loss: 9.0969 - val_mae: 2.0570 - val_mse: 9.0969\n",
            "Epoch 87/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.4946 - mae: 1.8459 - mse: 6.4946 - val_loss: 9.0755 - val_mae: 2.0387 - val_mse: 9.0755\n",
            "Epoch 88/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 6.2540 - mae: 1.8052 - mse: 6.2540 - val_loss: 9.7298 - val_mae: 2.1653 - val_mse: 9.7298\n",
            "Epoch 89/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 6.3944 - mae: 1.8312 - mse: 6.3944 - val_loss: 9.0245 - val_mae: 2.0579 - val_mse: 9.0245\n",
            "Epoch 90/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 6.1819 - mae: 1.7990 - mse: 6.1819 - val_loss: 9.5408 - val_mae: 2.1346 - val_mse: 9.5408\n",
            "Epoch 91/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.3108 - mae: 1.8317 - mse: 6.3108 - val_loss: 9.4165 - val_mae: 2.1130 - val_mse: 9.4165\n",
            "Epoch 92/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.5101 - mae: 1.8277 - mse: 6.5101 - val_loss: 8.9891 - val_mae: 2.0436 - val_mse: 8.9891\n",
            "Epoch 93/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 6.3206 - mae: 1.8264 - mse: 6.3206 - val_loss: 8.9186 - val_mae: 2.0295 - val_mse: 8.9186\n",
            "Epoch 94/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 6.2732 - mae: 1.7994 - mse: 6.2732 - val_loss: 8.9382 - val_mae: 2.0195 - val_mse: 8.9382\n",
            "Epoch 95/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 6.3396 - mae: 1.8164 - mse: 6.3396 - val_loss: 8.9281 - val_mae: 2.0095 - val_mse: 8.9281\n",
            "Epoch 96/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 6.1022 - mae: 1.7884 - mse: 6.1022 - val_loss: 9.2890 - val_mae: 2.0811 - val_mse: 9.2890\n",
            "Epoch 97/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 6.1873 - mae: 1.7755 - mse: 6.1873 - val_loss: 9.3685 - val_mae: 2.1200 - val_mse: 9.3685\n",
            "Epoch 98/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 6.2144 - mae: 1.8003 - mse: 6.2144 - val_loss: 8.8996 - val_mae: 2.0202 - val_mse: 8.8996\n",
            "Epoch 99/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 6.3249 - mae: 1.7805 - mse: 6.3249 - val_loss: 8.9484 - val_mae: 2.0359 - val_mse: 8.9484\n",
            "Epoch 100/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 6.0499 - mae: 1.7593 - mse: 6.0499 - val_loss: 9.3500 - val_mae: 2.1080 - val_mse: 9.3500\n",
            "Epoch 101/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.1822 - mae: 1.7861 - mse: 6.1822 - val_loss: 9.0228 - val_mae: 2.0187 - val_mse: 9.0228\n",
            "Epoch 102/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 6.0517 - mae: 1.7729 - mse: 6.0517 - val_loss: 8.9165 - val_mae: 2.0230 - val_mse: 8.9165\n",
            "Epoch 103/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 6.0498 - mae: 1.7800 - mse: 6.0498 - val_loss: 9.1695 - val_mae: 2.0545 - val_mse: 9.1695\n",
            "Epoch 104/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.8882 - mae: 1.7333 - mse: 5.8882 - val_loss: 9.8919 - val_mae: 2.2020 - val_mse: 9.8919\n",
            "Epoch 105/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 6.4230 - mae: 1.8085 - mse: 6.4230 - val_loss: 9.3042 - val_mae: 2.0851 - val_mse: 9.3042\n",
            "Epoch 106/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.9394 - mae: 1.7393 - mse: 5.9394 - val_loss: 8.9379 - val_mae: 2.0225 - val_mse: 8.9379\n",
            "Epoch 107/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.9993 - mae: 1.8178 - mse: 5.9993 - val_loss: 8.9405 - val_mae: 2.0140 - val_mse: 8.9405\n",
            "Epoch 108/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 6.2370 - mae: 1.7748 - mse: 6.2370 - val_loss: 8.8839 - val_mae: 2.0181 - val_mse: 8.8839\n",
            "Epoch 109/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 6.0771 - mae: 1.7584 - mse: 6.0771 - val_loss: 9.2123 - val_mae: 2.0708 - val_mse: 9.2123\n",
            "Epoch 110/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 6.1452 - mae: 1.7675 - mse: 6.1452 - val_loss: 8.9570 - val_mae: 2.0429 - val_mse: 8.9570\n",
            "Epoch 111/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.8906 - mae: 1.7501 - mse: 5.8906 - val_loss: 8.8402 - val_mae: 2.0053 - val_mse: 8.8402\n",
            "Epoch 112/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.8284 - mae: 1.7179 - mse: 5.8284 - val_loss: 8.7979 - val_mae: 2.0080 - val_mse: 8.7979\n",
            "Epoch 113/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.9755 - mae: 1.7287 - mse: 5.9755 - val_loss: 8.8273 - val_mae: 2.0220 - val_mse: 8.8273\n",
            "Epoch 114/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 6.1271 - mae: 1.7727 - mse: 6.1271 - val_loss: 8.7342 - val_mae: 2.0034 - val_mse: 8.7342\n",
            "Epoch 115/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.8415 - mae: 1.7201 - mse: 5.8415 - val_loss: 8.7650 - val_mae: 1.9909 - val_mse: 8.7650\n",
            "Epoch 116/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.9800 - mae: 1.7336 - mse: 5.9800 - val_loss: 8.8313 - val_mae: 2.0192 - val_mse: 8.8313\n",
            "Epoch 117/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.7704 - mae: 1.7292 - mse: 5.7704 - val_loss: 8.8185 - val_mae: 1.9888 - val_mse: 8.8185\n",
            "Epoch 118/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.9034 - mae: 1.7449 - mse: 5.9034 - val_loss: 9.0613 - val_mae: 2.0561 - val_mse: 9.0613\n",
            "Epoch 119/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.9662 - mae: 1.7485 - mse: 5.9662 - val_loss: 8.7989 - val_mae: 2.0129 - val_mse: 8.7989\n",
            "Epoch 120/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.6967 - mae: 1.7105 - mse: 5.6967 - val_loss: 9.0461 - val_mae: 2.0259 - val_mse: 9.0461\n",
            "Epoch 121/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 6.0129 - mae: 1.7847 - mse: 6.0129 - val_loss: 8.9329 - val_mae: 2.0363 - val_mse: 8.9329\n",
            "Epoch 122/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.7661 - mae: 1.7187 - mse: 5.7661 - val_loss: 8.9352 - val_mae: 2.0376 - val_mse: 8.9352\n",
            "Epoch 123/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.7036 - mae: 1.7146 - mse: 5.7036 - val_loss: 9.4381 - val_mae: 2.1366 - val_mse: 9.4381\n",
            "Epoch 124/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.8914 - mae: 1.7481 - mse: 5.8914 - val_loss: 8.9221 - val_mae: 2.0160 - val_mse: 8.9221\n",
            "Epoch 125/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.9018 - mae: 1.7366 - mse: 5.9018 - val_loss: 8.8325 - val_mae: 2.0162 - val_mse: 8.8325\n",
            "Epoch 126/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.7314 - mae: 1.7085 - mse: 5.7314 - val_loss: 8.9925 - val_mae: 2.0496 - val_mse: 8.9925\n",
            "Epoch 127/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.7145 - mae: 1.7204 - mse: 5.7145 - val_loss: 8.8929 - val_mae: 2.0086 - val_mse: 8.8929\n",
            "Epoch 128/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.6146 - mae: 1.6827 - mse: 5.6146 - val_loss: 8.9792 - val_mae: 2.0495 - val_mse: 8.9792\n",
            "Epoch 129/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.5822 - mae: 1.7047 - mse: 5.5822 - val_loss: 8.7270 - val_mae: 1.9876 - val_mse: 8.7270\n",
            "Epoch 130/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.5619 - mae: 1.6954 - mse: 5.5619 - val_loss: 9.2245 - val_mae: 2.0927 - val_mse: 9.2245\n",
            "Epoch 131/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.6826 - mae: 1.6884 - mse: 5.6826 - val_loss: 9.1934 - val_mae: 2.0796 - val_mse: 9.1934\n",
            "Epoch 132/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.7635 - mae: 1.7333 - mse: 5.7635 - val_loss: 8.7324 - val_mae: 2.0015 - val_mse: 8.7324\n",
            "Epoch 133/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.5822 - mae: 1.6859 - mse: 5.5822 - val_loss: 9.0326 - val_mae: 2.1156 - val_mse: 9.0326\n",
            "Epoch 134/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.6727 - mae: 1.7090 - mse: 5.6727 - val_loss: 8.9969 - val_mae: 2.0426 - val_mse: 8.9969\n",
            "Epoch 135/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.5381 - mae: 1.6728 - mse: 5.5381 - val_loss: 8.6613 - val_mae: 1.9987 - val_mse: 8.6613\n",
            "Epoch 136/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.6769 - mae: 1.7002 - mse: 5.6769 - val_loss: 8.6709 - val_mae: 1.9964 - val_mse: 8.6709\n",
            "Epoch 137/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.4754 - mae: 1.6611 - mse: 5.4754 - val_loss: 8.7643 - val_mae: 2.0374 - val_mse: 8.7643\n",
            "Epoch 138/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.5985 - mae: 1.7008 - mse: 5.5985 - val_loss: 8.6891 - val_mae: 1.9911 - val_mse: 8.6891\n",
            "Epoch 139/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.6932 - mae: 1.6944 - mse: 5.6932 - val_loss: 8.6799 - val_mae: 1.9887 - val_mse: 8.6799\n",
            "Epoch 140/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.6501 - mae: 1.6842 - mse: 5.6501 - val_loss: 8.6688 - val_mae: 1.9936 - val_mse: 8.6688\n",
            "Epoch 141/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.5081 - mae: 1.6720 - mse: 5.5081 - val_loss: 8.7264 - val_mae: 2.0186 - val_mse: 8.7264\n",
            "Epoch 142/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.6393 - mae: 1.6797 - mse: 5.6393 - val_loss: 8.6493 - val_mae: 1.9963 - val_mse: 8.6493\n",
            "Epoch 143/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.3589 - mae: 1.6405 - mse: 5.3589 - val_loss: 8.7398 - val_mae: 1.9973 - val_mse: 8.7398\n",
            "Epoch 144/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.6106 - mae: 1.6782 - mse: 5.6106 - val_loss: 8.6880 - val_mae: 2.0167 - val_mse: 8.6880\n",
            "Epoch 145/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.5042 - mae: 1.6802 - mse: 5.5042 - val_loss: 8.5884 - val_mae: 1.9804 - val_mse: 8.5884\n",
            "Epoch 146/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.4380 - mae: 1.6756 - mse: 5.4380 - val_loss: 8.6659 - val_mae: 1.9869 - val_mse: 8.6659\n",
            "Epoch 147/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.3598 - mae: 1.6440 - mse: 5.3598 - val_loss: 8.7442 - val_mae: 2.0099 - val_mse: 8.7442\n",
            "Epoch 148/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.3936 - mae: 1.6404 - mse: 5.3936 - val_loss: 8.9257 - val_mae: 2.0540 - val_mse: 8.9257\n",
            "Epoch 149/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.6061 - mae: 1.6666 - mse: 5.6061 - val_loss: 8.6004 - val_mae: 1.9743 - val_mse: 8.6004\n",
            "Epoch 150/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.3243 - mae: 1.6437 - mse: 5.3243 - val_loss: 8.8930 - val_mae: 2.0645 - val_mse: 8.8930\n",
            "Epoch 151/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.3196 - mae: 1.6495 - mse: 5.3196 - val_loss: 8.8178 - val_mae: 2.0417 - val_mse: 8.8178\n",
            "Epoch 152/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.2651 - mae: 1.6340 - mse: 5.2651 - val_loss: 8.6943 - val_mae: 2.0133 - val_mse: 8.6943\n",
            "Epoch 153/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.1860 - mae: 1.6431 - mse: 5.1860 - val_loss: 8.6532 - val_mae: 2.0233 - val_mse: 8.6532\n",
            "Epoch 154/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.4571 - mae: 1.6784 - mse: 5.4571 - val_loss: 8.7324 - val_mae: 2.0409 - val_mse: 8.7324\n",
            "Epoch 155/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.3410 - mae: 1.6330 - mse: 5.3410 - val_loss: 8.6245 - val_mae: 2.0001 - val_mse: 8.6245\n",
            "Epoch 156/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.3324 - mae: 1.6483 - mse: 5.3324 - val_loss: 8.5981 - val_mae: 1.9807 - val_mse: 8.5981\n",
            "Epoch 157/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.3771 - mae: 1.6625 - mse: 5.3771 - val_loss: 8.6248 - val_mae: 1.9991 - val_mse: 8.6248\n",
            "Epoch 158/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.3583 - mae: 1.6493 - mse: 5.3583 - val_loss: 8.4860 - val_mae: 1.9804 - val_mse: 8.4860\n",
            "Epoch 159/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.1604 - mae: 1.6050 - mse: 5.1604 - val_loss: 8.6217 - val_mae: 1.9965 - val_mse: 8.6217\n",
            "Epoch 160/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.4182 - mae: 1.6630 - mse: 5.4182 - val_loss: 8.5502 - val_mae: 1.9769 - val_mse: 8.5502\n",
            "Epoch 161/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.2075 - mae: 1.6152 - mse: 5.2075 - val_loss: 8.5814 - val_mae: 1.9946 - val_mse: 8.5814\n",
            "Epoch 162/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.2452 - mae: 1.6084 - mse: 5.2452 - val_loss: 8.6681 - val_mae: 2.0229 - val_mse: 8.6681\n",
            "Epoch 163/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.1969 - mae: 1.6265 - mse: 5.1969 - val_loss: 8.6996 - val_mae: 2.0210 - val_mse: 8.6996\n",
            "Epoch 164/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.1881 - mae: 1.6201 - mse: 5.1881 - val_loss: 8.8157 - val_mae: 2.0375 - val_mse: 8.8157\n",
            "Epoch 165/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.2104 - mae: 1.6165 - mse: 5.2104 - val_loss: 8.6559 - val_mae: 2.0361 - val_mse: 8.6559\n",
            "Epoch 166/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.2032 - mae: 1.6195 - mse: 5.2032 - val_loss: 8.6179 - val_mae: 2.0122 - val_mse: 8.6179\n",
            "Epoch 167/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.3932 - mae: 1.6523 - mse: 5.3932 - val_loss: 8.5703 - val_mae: 2.0096 - val_mse: 8.5703\n",
            "Epoch 168/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.2325 - mae: 1.6222 - mse: 5.2325 - val_loss: 8.5645 - val_mae: 1.9664 - val_mse: 8.5645\n",
            "Epoch 169/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.1045 - mae: 1.6056 - mse: 5.1045 - val_loss: 8.5449 - val_mae: 1.9752 - val_mse: 8.5449\n",
            "Epoch 170/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.1313 - mae: 1.5894 - mse: 5.1313 - val_loss: 8.5050 - val_mae: 1.9668 - val_mse: 8.5050\n",
            "Epoch 171/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.1200 - mae: 1.6532 - mse: 5.1200 - val_loss: 8.5339 - val_mae: 1.9991 - val_mse: 8.5339\n",
            "Epoch 172/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.1035 - mae: 1.5900 - mse: 5.1035 - val_loss: 8.5173 - val_mae: 1.9900 - val_mse: 8.5173\n",
            "Epoch 173/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.9972 - mae: 1.6123 - mse: 4.9972 - val_loss: 9.0295 - val_mae: 2.1029 - val_mse: 9.0295\n",
            "Epoch 174/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.3361 - mae: 1.6523 - mse: 5.3361 - val_loss: 8.6639 - val_mae: 1.9984 - val_mse: 8.6639\n",
            "Epoch 175/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.1404 - mae: 1.6142 - mse: 5.1404 - val_loss: 8.6561 - val_mae: 2.0068 - val_mse: 8.6561\n",
            "Epoch 176/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.1594 - mae: 1.6008 - mse: 5.1594 - val_loss: 8.5071 - val_mae: 1.9641 - val_mse: 8.5071\n",
            "Epoch 177/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.9718 - mae: 1.5844 - mse: 4.9718 - val_loss: 8.4532 - val_mae: 1.9685 - val_mse: 8.4532\n",
            "Epoch 178/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.0400 - mae: 1.6086 - mse: 5.0400 - val_loss: 8.6338 - val_mae: 2.0185 - val_mse: 8.6338\n",
            "Epoch 179/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.2031 - mae: 1.6060 - mse: 5.2031 - val_loss: 9.0745 - val_mae: 2.0922 - val_mse: 9.0745\n",
            "Epoch 180/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.1116 - mae: 1.6025 - mse: 5.1116 - val_loss: 8.5312 - val_mae: 1.9918 - val_mse: 8.5312\n",
            "Epoch 181/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.0478 - mae: 1.5915 - mse: 5.0478 - val_loss: 8.5433 - val_mae: 1.9900 - val_mse: 8.5433\n",
            "Epoch 182/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.1383 - mae: 1.6024 - mse: 5.1383 - val_loss: 8.8581 - val_mae: 2.0542 - val_mse: 8.8581\n",
            "Epoch 183/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.1628 - mae: 1.6007 - mse: 5.1628 - val_loss: 8.6204 - val_mae: 1.9985 - val_mse: 8.6204\n",
            "Epoch 184/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.9481 - mae: 1.5418 - mse: 4.9481 - val_loss: 8.8200 - val_mae: 2.0231 - val_mse: 8.8200\n",
            "Epoch 185/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.7564 - mae: 1.5587 - mse: 4.7564 - val_loss: 8.6582 - val_mae: 2.0035 - val_mse: 8.6582\n",
            "Epoch 186/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.8948 - mae: 1.5720 - mse: 4.8948 - val_loss: 8.7282 - val_mae: 2.0403 - val_mse: 8.7282\n",
            "Epoch 187/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.1454 - mae: 1.6221 - mse: 5.1454 - val_loss: 8.4947 - val_mae: 1.9769 - val_mse: 8.4947\n",
            "Epoch 188/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.0450 - mae: 1.5816 - mse: 5.0450 - val_loss: 8.4810 - val_mae: 1.9809 - val_mse: 8.4810\n",
            "Epoch 189/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.9296 - mae: 1.5762 - mse: 4.9296 - val_loss: 8.5075 - val_mae: 1.9737 - val_mse: 8.5075\n",
            "Epoch 190/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.8542 - mae: 1.5631 - mse: 4.8542 - val_loss: 8.5945 - val_mae: 2.0043 - val_mse: 8.5945\n",
            "Epoch 191/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.9097 - mae: 1.5487 - mse: 4.9097 - val_loss: 8.6724 - val_mae: 2.0309 - val_mse: 8.6724\n",
            "Epoch 192/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.8518 - mae: 1.5580 - mse: 4.8518 - val_loss: 8.4256 - val_mae: 1.9599 - val_mse: 8.4256\n",
            "Epoch 193/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.0235 - mae: 1.6001 - mse: 5.0235 - val_loss: 9.3325 - val_mae: 2.1229 - val_mse: 9.3325\n",
            "Epoch 194/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.8209 - mae: 1.6006 - mse: 4.8209 - val_loss: 9.0560 - val_mae: 2.1069 - val_mse: 9.0560\n",
            "Epoch 195/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.9054 - mae: 1.5600 - mse: 4.9054 - val_loss: 8.9894 - val_mae: 2.0671 - val_mse: 8.9894\n",
            "Epoch 196/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.0797 - mae: 1.5932 - mse: 5.0797 - val_loss: 8.5951 - val_mae: 2.0072 - val_mse: 8.5951\n",
            "Epoch 197/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.8314 - mae: 1.6111 - mse: 4.8314 - val_loss: 8.4019 - val_mae: 1.9543 - val_mse: 8.4019\n",
            "Epoch 198/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.8793 - mae: 1.5457 - mse: 4.8793 - val_loss: 8.8534 - val_mae: 2.0379 - val_mse: 8.8534\n",
            "Epoch 199/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.0125 - mae: 1.5786 - mse: 5.0125 - val_loss: 8.6183 - val_mae: 2.0280 - val_mse: 8.6183\n",
            "Epoch 200/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.9000 - mae: 1.5997 - mse: 4.9000 - val_loss: 8.7443 - val_mae: 2.0366 - val_mse: 8.7443\n",
            "Epoch 201/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.8694 - mae: 1.5460 - mse: 4.8694 - val_loss: 8.5726 - val_mae: 2.0016 - val_mse: 8.5726\n",
            "Epoch 202/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.7130 - mae: 1.5394 - mse: 4.7130 - val_loss: 8.7665 - val_mae: 2.0209 - val_mse: 8.7665\n",
            "Epoch 203/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.8460 - mae: 1.5808 - mse: 4.8460 - val_loss: 8.4573 - val_mae: 1.9561 - val_mse: 8.4573\n",
            "Epoch 204/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.7164 - mae: 1.5627 - mse: 4.7164 - val_loss: 8.5522 - val_mae: 2.0023 - val_mse: 8.5522\n",
            "Epoch 205/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.8298 - mae: 1.5480 - mse: 4.8298 - val_loss: 8.5068 - val_mae: 1.9673 - val_mse: 8.5068\n",
            "Epoch 206/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.8898 - mae: 1.5543 - mse: 4.8898 - val_loss: 8.5381 - val_mae: 1.9999 - val_mse: 8.5381\n",
            "Epoch 207/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.7133 - mae: 1.5506 - mse: 4.7133 - val_loss: 8.5278 - val_mae: 1.9726 - val_mse: 8.5278\n",
            "Epoch 208/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.8593 - mae: 1.5516 - mse: 4.8593 - val_loss: 8.3902 - val_mae: 1.9496 - val_mse: 8.3902\n",
            "Epoch 209/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.6976 - mae: 1.5378 - mse: 4.6976 - val_loss: 8.4620 - val_mae: 1.9923 - val_mse: 8.4620\n",
            "Epoch 210/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.9316 - mae: 1.6129 - mse: 4.9316 - val_loss: 8.3725 - val_mae: 1.9546 - val_mse: 8.3725\n",
            "Epoch 211/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.9821 - mae: 1.5758 - mse: 4.9821 - val_loss: 8.5899 - val_mae: 2.0007 - val_mse: 8.5899\n",
            "Epoch 212/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.6607 - mae: 1.5524 - mse: 4.6607 - val_loss: 8.5445 - val_mae: 1.9876 - val_mse: 8.5445\n",
            "Epoch 213/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.6110 - mae: 1.5245 - mse: 4.6110 - val_loss: 8.4432 - val_mae: 1.9536 - val_mse: 8.4432\n",
            "Epoch 214/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.6986 - mae: 1.5205 - mse: 4.6986 - val_loss: 8.6646 - val_mae: 2.0227 - val_mse: 8.6647\n",
            "Epoch 215/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.6694 - mae: 1.5257 - mse: 4.6694 - val_loss: 8.8684 - val_mae: 2.0267 - val_mse: 8.8684\n",
            "Epoch 216/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.6734 - mae: 1.5143 - mse: 4.6734 - val_loss: 8.4382 - val_mae: 2.0023 - val_mse: 8.4382\n",
            "Epoch 217/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.6606 - mae: 1.5542 - mse: 4.6606 - val_loss: 8.5205 - val_mae: 2.0096 - val_mse: 8.5205\n",
            "Epoch 218/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.7488 - mae: 1.5118 - mse: 4.7488 - val_loss: 8.7818 - val_mae: 2.0311 - val_mse: 8.7818\n",
            "Epoch 219/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.8127 - mae: 1.5447 - mse: 4.8127 - val_loss: 8.4643 - val_mae: 1.9916 - val_mse: 8.4643\n",
            "Epoch 220/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.7373 - mae: 1.5456 - mse: 4.7373 - val_loss: 8.5248 - val_mae: 1.9696 - val_mse: 8.5248\n",
            "Epoch 221/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.6714 - mae: 1.5273 - mse: 4.6714 - val_loss: 8.4562 - val_mae: 1.9744 - val_mse: 8.4562\n",
            "Epoch 222/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.7169 - mae: 1.5486 - mse: 4.7169 - val_loss: 8.5146 - val_mae: 1.9884 - val_mse: 8.5146\n",
            "Epoch 223/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.7524 - mae: 1.5479 - mse: 4.7524 - val_loss: 8.6833 - val_mae: 2.0192 - val_mse: 8.6833\n",
            "Epoch 224/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.6151 - mae: 1.5543 - mse: 4.6151 - val_loss: 8.3706 - val_mae: 1.9707 - val_mse: 8.3706\n",
            "Epoch 225/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.6380 - mae: 1.5099 - mse: 4.6380 - val_loss: 8.6349 - val_mae: 2.0109 - val_mse: 8.6349\n",
            "Epoch 226/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.6451 - mae: 1.5578 - mse: 4.6451 - val_loss: 8.8545 - val_mae: 2.0586 - val_mse: 8.8545\n",
            "Epoch 227/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.8251 - mae: 1.5469 - mse: 4.8251 - val_loss: 8.9142 - val_mae: 2.0540 - val_mse: 8.9142\n",
            "Epoch 228/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.6397 - mae: 1.5510 - mse: 4.6397 - val_loss: 8.4292 - val_mae: 1.9793 - val_mse: 8.4292\n",
            "Epoch 229/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.6028 - mae: 1.5075 - mse: 4.6028 - val_loss: 8.3211 - val_mae: 1.9475 - val_mse: 8.3211\n",
            "Epoch 230/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.5662 - mae: 1.5150 - mse: 4.5662 - val_loss: 8.3143 - val_mae: 1.9479 - val_mse: 8.3143\n",
            "Epoch 231/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.4891 - mae: 1.4902 - mse: 4.4891 - val_loss: 8.3983 - val_mae: 1.9675 - val_mse: 8.3983\n",
            "Epoch 232/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.6187 - mae: 1.5173 - mse: 4.6187 - val_loss: 8.5080 - val_mae: 1.9996 - val_mse: 8.5080\n",
            "Epoch 233/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.8118 - mae: 1.5466 - mse: 4.8118 - val_loss: 8.6311 - val_mae: 2.0229 - val_mse: 8.6311\n",
            "Epoch 234/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.5907 - mae: 1.5204 - mse: 4.5907 - val_loss: 8.4052 - val_mae: 1.9891 - val_mse: 8.4052\n",
            "Epoch 235/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.7106 - mae: 1.5421 - mse: 4.7106 - val_loss: 8.2543 - val_mae: 1.9486 - val_mse: 8.2543\n",
            "Epoch 236/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.6666 - mae: 1.5280 - mse: 4.6666 - val_loss: 8.2662 - val_mae: 1.9487 - val_mse: 8.2662\n",
            "Epoch 237/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.5441 - mae: 1.5246 - mse: 4.5441 - val_loss: 8.2848 - val_mae: 1.9503 - val_mse: 8.2848\n",
            "Epoch 238/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.6046 - mae: 1.5093 - mse: 4.6046 - val_loss: 8.3422 - val_mae: 1.9726 - val_mse: 8.3422\n",
            "Epoch 239/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.5978 - mae: 1.4936 - mse: 4.5978 - val_loss: 8.2525 - val_mae: 1.9582 - val_mse: 8.2525\n",
            "Epoch 240/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.4433 - mae: 1.4735 - mse: 4.4433 - val_loss: 8.3515 - val_mae: 1.9917 - val_mse: 8.3515\n",
            "Epoch 241/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.6333 - mae: 1.5253 - mse: 4.6333 - val_loss: 8.6381 - val_mae: 2.0309 - val_mse: 8.6381\n",
            "Epoch 242/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.6141 - mae: 1.4978 - mse: 4.6141 - val_loss: 8.3533 - val_mae: 1.9553 - val_mse: 8.3533\n",
            "Epoch 243/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.3107 - mae: 1.4777 - mse: 4.3107 - val_loss: 8.5917 - val_mae: 2.0355 - val_mse: 8.5917\n",
            "Epoch 244/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.6364 - mae: 1.5207 - mse: 4.6364 - val_loss: 8.5565 - val_mae: 2.0379 - val_mse: 8.5565\n",
            "Epoch 245/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.6130 - mae: 1.4928 - mse: 4.6130 - val_loss: 8.4461 - val_mae: 2.0085 - val_mse: 8.4461\n",
            "Epoch 246/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.5737 - mae: 1.4982 - mse: 4.5737 - val_loss: 8.2547 - val_mae: 1.9515 - val_mse: 8.2547\n",
            "Epoch 247/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.5184 - mae: 1.5248 - mse: 4.5184 - val_loss: 8.4496 - val_mae: 1.9902 - val_mse: 8.4496\n",
            "Epoch 248/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.4466 - mae: 1.5094 - mse: 4.4466 - val_loss: 8.3740 - val_mae: 1.9937 - val_mse: 8.3740\n",
            "Epoch 249/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.5441 - mae: 1.4893 - mse: 4.5441 - val_loss: 8.4135 - val_mae: 1.9709 - val_mse: 8.4135\n",
            "Epoch 250/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.4059 - mae: 1.4844 - mse: 4.4059 - val_loss: 8.2597 - val_mae: 1.9354 - val_mse: 8.2597\n",
            "Epoch 251/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.6399 - mae: 1.5103 - mse: 4.6399 - val_loss: 8.3359 - val_mae: 1.9501 - val_mse: 8.3359\n",
            "Epoch 252/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.4155 - mae: 1.4717 - mse: 4.4155 - val_loss: 8.3152 - val_mae: 1.9643 - val_mse: 8.3152\n",
            "Epoch 253/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.4714 - mae: 1.4950 - mse: 4.4714 - val_loss: 8.4420 - val_mae: 1.9770 - val_mse: 8.4420\n",
            "Epoch 254/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.4835 - mae: 1.4666 - mse: 4.4835 - val_loss: 8.7160 - val_mae: 1.9965 - val_mse: 8.7160\n",
            "Epoch 255/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.3557 - mae: 1.4935 - mse: 4.3557 - val_loss: 8.3927 - val_mae: 1.9717 - val_mse: 8.3927\n",
            "Epoch 256/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.4171 - mae: 1.4895 - mse: 4.4171 - val_loss: 8.3151 - val_mae: 1.9468 - val_mse: 8.3151\n",
            "Epoch 257/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.4374 - mae: 1.4723 - mse: 4.4374 - val_loss: 8.5164 - val_mae: 1.9597 - val_mse: 8.5164\n",
            "Epoch 258/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.5360 - mae: 1.4867 - mse: 4.5360 - val_loss: 8.5617 - val_mae: 1.9859 - val_mse: 8.5617\n",
            "Epoch 259/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.4034 - mae: 1.4715 - mse: 4.4034 - val_loss: 8.3871 - val_mae: 1.9941 - val_mse: 8.3871\n",
            "Epoch 260/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.3080 - mae: 1.4567 - mse: 4.3080 - val_loss: 8.4385 - val_mae: 1.9789 - val_mse: 8.4385\n",
            "Epoch 261/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.5292 - mae: 1.4947 - mse: 4.5292 - val_loss: 8.7254 - val_mae: 2.0214 - val_mse: 8.7254\n",
            "Epoch 262/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.4041 - mae: 1.4745 - mse: 4.4041 - val_loss: 8.4126 - val_mae: 1.9961 - val_mse: 8.4126\n",
            "Epoch 263/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.4478 - mae: 1.4804 - mse: 4.4478 - val_loss: 8.7688 - val_mae: 2.0340 - val_mse: 8.7688\n",
            "Epoch 264/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.4733 - mae: 1.4778 - mse: 4.4733 - val_loss: 8.4392 - val_mae: 1.9870 - val_mse: 8.4392\n",
            "Epoch 265/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.4450 - mae: 1.4910 - mse: 4.4450 - val_loss: 8.3419 - val_mae: 2.0140 - val_mse: 8.3419\n",
            "Epoch 266/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.3739 - mae: 1.4610 - mse: 4.3739 - val_loss: 8.3485 - val_mae: 1.9467 - val_mse: 8.3485\n",
            "Epoch 267/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.3885 - mae: 1.4476 - mse: 4.3885 - val_loss: 8.3357 - val_mae: 1.9758 - val_mse: 8.3357\n",
            "Epoch 268/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.3442 - mae: 1.4449 - mse: 4.3442 - val_loss: 8.2555 - val_mae: 1.9419 - val_mse: 8.2555\n",
            "Epoch 269/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.3150 - mae: 1.4406 - mse: 4.3150 - val_loss: 8.5717 - val_mae: 1.9917 - val_mse: 8.5717\n",
            "Epoch 270/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.5118 - mae: 1.5337 - mse: 4.5118 - val_loss: 8.4404 - val_mae: 1.9968 - val_mse: 8.4404\n",
            "Epoch 271/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.3616 - mae: 1.4553 - mse: 4.3616 - val_loss: 8.7284 - val_mae: 2.0204 - val_mse: 8.7284\n",
            "Epoch 272/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.2987 - mae: 1.4567 - mse: 4.2987 - val_loss: 8.3507 - val_mae: 1.9907 - val_mse: 8.3507\n",
            "Epoch 273/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.2950 - mae: 1.4457 - mse: 4.2950 - val_loss: 8.4569 - val_mae: 1.9739 - val_mse: 8.4569\n",
            "Epoch 274/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.4003 - mae: 1.4818 - mse: 4.4003 - val_loss: 8.1681 - val_mae: 1.9465 - val_mse: 8.1681\n",
            "Epoch 275/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.1934 - mae: 1.3967 - mse: 4.1934 - val_loss: 8.2046 - val_mae: 1.9624 - val_mse: 8.2046\n",
            "Epoch 276/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.4478 - mae: 1.4693 - mse: 4.4478 - val_loss: 8.5273 - val_mae: 1.9994 - val_mse: 8.5273\n",
            "Epoch 277/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.1829 - mae: 1.4517 - mse: 4.1829 - val_loss: 8.5868 - val_mae: 1.9977 - val_mse: 8.5868\n",
            "Epoch 278/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.2596 - mae: 1.4534 - mse: 4.2596 - val_loss: 8.3569 - val_mae: 2.0196 - val_mse: 8.3569\n",
            "Epoch 279/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.4651 - mae: 1.4542 - mse: 4.4651 - val_loss: 8.4275 - val_mae: 1.9686 - val_mse: 8.4275\n",
            "Epoch 280/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.3560 - mae: 1.4647 - mse: 4.3560 - val_loss: 8.4446 - val_mae: 1.9657 - val_mse: 8.4446\n",
            "Epoch 281/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.2416 - mae: 1.4471 - mse: 4.2416 - val_loss: 8.6563 - val_mae: 2.0731 - val_mse: 8.6563\n",
            "Epoch 282/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.4963 - mae: 1.4877 - mse: 4.4963 - val_loss: 8.3395 - val_mae: 1.9636 - val_mse: 8.3395\n",
            "Epoch 283/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.2316 - mae: 1.4536 - mse: 4.2316 - val_loss: 8.2140 - val_mae: 1.9419 - val_mse: 8.2140\n",
            "Epoch 284/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.2713 - mae: 1.4266 - mse: 4.2713 - val_loss: 8.2147 - val_mae: 1.9777 - val_mse: 8.2147\n",
            "Epoch 285/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.3741 - mae: 1.4525 - mse: 4.3741 - val_loss: 8.3764 - val_mae: 1.9953 - val_mse: 8.3764\n",
            "Epoch 286/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.2001 - mae: 1.4320 - mse: 4.2001 - val_loss: 8.3597 - val_mae: 1.9642 - val_mse: 8.3597\n",
            "Epoch 287/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.2524 - mae: 1.4342 - mse: 4.2524 - val_loss: 8.4909 - val_mae: 2.0053 - val_mse: 8.4909\n",
            "Epoch 288/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.3023 - mae: 1.4520 - mse: 4.3023 - val_loss: 8.4735 - val_mae: 1.9943 - val_mse: 8.4735\n",
            "Epoch 289/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.3013 - mae: 1.4490 - mse: 4.3013 - val_loss: 8.2366 - val_mae: 1.9878 - val_mse: 8.2366\n",
            "Epoch 290/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.3717 - mae: 1.4547 - mse: 4.3717 - val_loss: 8.3777 - val_mae: 1.9916 - val_mse: 8.3777\n",
            "Epoch 291/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.3186 - mae: 1.4363 - mse: 4.3186 - val_loss: 8.3556 - val_mae: 1.9582 - val_mse: 8.3556\n",
            "Epoch 292/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.1114 - mae: 1.4048 - mse: 4.1114 - val_loss: 8.2878 - val_mae: 1.9412 - val_mse: 8.2878\n",
            "Epoch 293/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.3224 - mae: 1.4513 - mse: 4.3224 - val_loss: 8.3468 - val_mae: 1.9487 - val_mse: 8.3468\n",
            "Epoch 294/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.1928 - mae: 1.4306 - mse: 4.1928 - val_loss: 8.2608 - val_mae: 1.9588 - val_mse: 8.2608\n",
            "Epoch 295/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.3050 - mae: 1.4249 - mse: 4.3050 - val_loss: 8.3035 - val_mae: 1.9660 - val_mse: 8.3035\n",
            "Epoch 296/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.1788 - mae: 1.4100 - mse: 4.1788 - val_loss: 8.1498 - val_mae: 1.9415 - val_mse: 8.1498\n",
            "Epoch 297/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.0551 - mae: 1.3958 - mse: 4.0551 - val_loss: 8.3640 - val_mae: 1.9859 - val_mse: 8.3640\n",
            "Epoch 298/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.3711 - mae: 1.4550 - mse: 4.3711 - val_loss: 8.3742 - val_mae: 1.9713 - val_mse: 8.3742\n",
            "Epoch 299/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.2005 - mae: 1.4008 - mse: 4.2005 - val_loss: 8.3645 - val_mae: 1.9708 - val_mse: 8.3645\n",
            "Epoch 300/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.2485 - mae: 1.4214 - mse: 4.2485 - val_loss: 8.2403 - val_mae: 1.9627 - val_mse: 8.2403\n",
            "Epoch 301/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.0487 - mae: 1.4079 - mse: 4.0487 - val_loss: 8.2137 - val_mae: 1.9631 - val_mse: 8.2137\n",
            "Epoch 302/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.1908 - mae: 1.4231 - mse: 4.1908 - val_loss: 8.2950 - val_mae: 1.9769 - val_mse: 8.2950\n",
            "Epoch 303/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.1308 - mae: 1.3976 - mse: 4.1308 - val_loss: 8.3458 - val_mae: 1.9814 - val_mse: 8.3458\n",
            "Epoch 304/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.1069 - mae: 1.4000 - mse: 4.1069 - val_loss: 8.3876 - val_mae: 1.9800 - val_mse: 8.3876\n",
            "Epoch 305/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.1333 - mae: 1.4135 - mse: 4.1333 - val_loss: 8.3773 - val_mae: 1.9947 - val_mse: 8.3773\n",
            "Epoch 306/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.0588 - mae: 1.4290 - mse: 4.0588 - val_loss: 8.3648 - val_mae: 1.9597 - val_mse: 8.3648\n",
            "Epoch 307/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.1320 - mae: 1.4267 - mse: 4.1320 - val_loss: 8.3220 - val_mae: 1.9687 - val_mse: 8.3220\n",
            "Epoch 308/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.1933 - mae: 1.4175 - mse: 4.1933 - val_loss: 8.4436 - val_mae: 1.9760 - val_mse: 8.4436\n",
            "Epoch 309/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.0979 - mae: 1.4170 - mse: 4.0979 - val_loss: 8.4161 - val_mae: 1.9813 - val_mse: 8.4161\n",
            "Epoch 310/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.1237 - mae: 1.4016 - mse: 4.1237 - val_loss: 8.2427 - val_mae: 1.9525 - val_mse: 8.2427\n",
            "Epoch 311/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.2214 - mae: 1.3842 - mse: 4.2214 - val_loss: 8.5079 - val_mae: 1.9819 - val_mse: 8.5079\n",
            "Epoch 312/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.1128 - mae: 1.4083 - mse: 4.1128 - val_loss: 8.4276 - val_mae: 1.9575 - val_mse: 8.4276\n",
            "Epoch 313/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.1016 - mae: 1.4141 - mse: 4.1016 - val_loss: 8.5543 - val_mae: 1.9780 - val_mse: 8.5543\n",
            "Epoch 314/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.0764 - mae: 1.4078 - mse: 4.0764 - val_loss: 8.1789 - val_mae: 1.9519 - val_mse: 8.1789\n",
            "Epoch 315/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.0334 - mae: 1.3961 - mse: 4.0334 - val_loss: 8.1395 - val_mae: 1.9337 - val_mse: 8.1395\n",
            "Epoch 316/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.1670 - mae: 1.3853 - mse: 4.1670 - val_loss: 8.7026 - val_mae: 2.0307 - val_mse: 8.7026\n",
            "Epoch 317/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.0398 - mae: 1.3870 - mse: 4.0398 - val_loss: 8.4454 - val_mae: 2.0174 - val_mse: 8.4454\n",
            "Epoch 318/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.2603 - mae: 1.4792 - mse: 4.2603 - val_loss: 8.2801 - val_mae: 1.9651 - val_mse: 8.2801\n",
            "Epoch 319/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.0762 - mae: 1.4232 - mse: 4.0762 - val_loss: 8.4058 - val_mae: 1.9752 - val_mse: 8.4058\n",
            "Epoch 320/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.1124 - mae: 1.3820 - mse: 4.1124 - val_loss: 8.3222 - val_mae: 1.9740 - val_mse: 8.3222\n",
            "Epoch 321/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.1083 - mae: 1.3993 - mse: 4.1083 - val_loss: 8.2299 - val_mae: 1.9486 - val_mse: 8.2299\n",
            "Epoch 322/1000\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 3.9713 - mae: 1.3832 - mse: 3.9713 - val_loss: 8.3247 - val_mae: 1.9927 - val_mse: 8.3247\n",
            "Epoch 323/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.2978 - mae: 1.4239 - mse: 4.2978 - val_loss: 8.3248 - val_mae: 1.9510 - val_mse: 8.3248\n",
            "Epoch 324/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.9687 - mae: 1.3919 - mse: 3.9687 - val_loss: 8.2271 - val_mae: 1.9710 - val_mse: 8.2271\n",
            "Epoch 325/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.2672 - mae: 1.4342 - mse: 4.2672 - val_loss: 8.2079 - val_mae: 1.9637 - val_mse: 8.2079\n",
            "Epoch 326/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.1109 - mae: 1.3913 - mse: 4.1109 - val_loss: 8.1951 - val_mae: 1.9504 - val_mse: 8.1951\n",
            "Epoch 327/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.9920 - mae: 1.3944 - mse: 3.9920 - val_loss: 8.3428 - val_mae: 1.9719 - val_mse: 8.3428\n",
            "Epoch 328/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.1093 - mae: 1.4047 - mse: 4.1093 - val_loss: 8.7561 - val_mae: 2.0194 - val_mse: 8.7561\n",
            "Epoch 329/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.0015 - mae: 1.4036 - mse: 4.0015 - val_loss: 8.3296 - val_mae: 1.9763 - val_mse: 8.3296\n",
            "Epoch 330/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.9737 - mae: 1.3639 - mse: 3.9737 - val_loss: 8.2363 - val_mae: 1.9675 - val_mse: 8.2363\n",
            "Epoch 331/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.0680 - mae: 1.3750 - mse: 4.0680 - val_loss: 8.3671 - val_mae: 1.9856 - val_mse: 8.3671\n",
            "Epoch 332/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.2848 - mae: 1.3894 - mse: 4.2848 - val_loss: 8.5946 - val_mae: 1.9925 - val_mse: 8.5946\n",
            "Epoch 333/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.9671 - mae: 1.3662 - mse: 3.9671 - val_loss: 8.3530 - val_mae: 2.0043 - val_mse: 8.3530\n",
            "Epoch 334/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.1142 - mae: 1.4066 - mse: 4.1142 - val_loss: 8.4584 - val_mae: 1.9833 - val_mse: 8.4584\n",
            "Epoch 335/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.1187 - mae: 1.3968 - mse: 4.1187 - val_loss: 8.6266 - val_mae: 2.0186 - val_mse: 8.6266\n",
            "Epoch 336/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.9540 - mae: 1.3508 - mse: 3.9540 - val_loss: 8.3161 - val_mae: 1.9596 - val_mse: 8.3161\n",
            "Epoch 337/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.1507 - mae: 1.3806 - mse: 4.1507 - val_loss: 8.3640 - val_mae: 1.9811 - val_mse: 8.3640\n",
            "Epoch 338/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.0771 - mae: 1.3852 - mse: 4.0771 - val_loss: 8.3179 - val_mae: 1.9496 - val_mse: 8.3179\n",
            "Epoch 339/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.0095 - mae: 1.3690 - mse: 4.0095 - val_loss: 8.8783 - val_mae: 2.0519 - val_mse: 8.8783\n",
            "Epoch 340/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.1387 - mae: 1.3767 - mse: 4.1387 - val_loss: 8.2111 - val_mae: 1.9345 - val_mse: 8.2111\n",
            "Epoch 341/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.9476 - mae: 1.3718 - mse: 3.9476 - val_loss: 8.7087 - val_mae: 2.0299 - val_mse: 8.7087\n",
            "Epoch 342/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.7911 - mae: 1.3576 - mse: 3.7911 - val_loss: 8.5589 - val_mae: 2.0452 - val_mse: 8.5589\n",
            "Epoch 343/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.0668 - mae: 1.3915 - mse: 4.0668 - val_loss: 8.2924 - val_mae: 1.9617 - val_mse: 8.2924\n",
            "Epoch 344/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.2188 - mae: 1.4118 - mse: 4.2188 - val_loss: 9.2552 - val_mae: 2.1247 - val_mse: 9.2552\n",
            "Epoch 345/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.0671 - mae: 1.3912 - mse: 4.0671 - val_loss: 9.2921 - val_mae: 2.1456 - val_mse: 9.2921\n",
            "Epoch 346/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.1047 - mae: 1.4046 - mse: 4.1047 - val_loss: 8.1568 - val_mae: 1.9464 - val_mse: 8.1568\n",
            "Epoch 347/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.0614 - mae: 1.3854 - mse: 4.0614 - val_loss: 8.3040 - val_mae: 1.9836 - val_mse: 8.3040\n",
            "Epoch 348/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.0367 - mae: 1.3545 - mse: 4.0367 - val_loss: 8.4445 - val_mae: 2.0010 - val_mse: 8.4445\n",
            "Epoch 349/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.1173 - mae: 1.3713 - mse: 4.1173 - val_loss: 8.6893 - val_mae: 2.0282 - val_mse: 8.6893\n",
            "Epoch 350/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.9309 - mae: 1.3571 - mse: 3.9309 - val_loss: 8.1562 - val_mae: 1.9512 - val_mse: 8.1562\n",
            "Epoch 351/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.8864 - mae: 1.3382 - mse: 3.8864 - val_loss: 8.2372 - val_mae: 1.9551 - val_mse: 8.2372\n",
            "Epoch 352/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.9305 - mae: 1.3573 - mse: 3.9305 - val_loss: 8.1401 - val_mae: 1.9442 - val_mse: 8.1401\n",
            "Epoch 353/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.8324 - mae: 1.3555 - mse: 3.8324 - val_loss: 8.1760 - val_mae: 1.9353 - val_mse: 8.1760\n",
            "Epoch 354/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.8010 - mae: 1.3638 - mse: 3.8010 - val_loss: 8.2130 - val_mae: 1.9554 - val_mse: 8.2130\n",
            "Epoch 355/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.9256 - mae: 1.3769 - mse: 3.9256 - val_loss: 9.1077 - val_mae: 2.1136 - val_mse: 9.1077\n",
            "Epoch 356/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.2246 - mae: 1.4315 - mse: 4.2246 - val_loss: 8.9133 - val_mae: 2.0648 - val_mse: 8.9133\n",
            "Epoch 357/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.8305 - mae: 1.3592 - mse: 3.8305 - val_loss: 8.2321 - val_mae: 1.9372 - val_mse: 8.2321\n",
            "Epoch 358/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.8681 - mae: 1.3432 - mse: 3.8681 - val_loss: 8.5127 - val_mae: 1.9849 - val_mse: 8.5127\n",
            "Epoch 359/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.0533 - mae: 1.3642 - mse: 4.0533 - val_loss: 8.1025 - val_mae: 1.9480 - val_mse: 8.1025\n",
            "Epoch 360/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.9860 - mae: 1.3694 - mse: 3.9860 - val_loss: 8.1828 - val_mae: 1.9396 - val_mse: 8.1828\n",
            "Epoch 361/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.8595 - mae: 1.3335 - mse: 3.8595 - val_loss: 8.4180 - val_mae: 1.9884 - val_mse: 8.4180\n",
            "Epoch 362/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.9413 - mae: 1.3819 - mse: 3.9413 - val_loss: 8.3319 - val_mae: 1.9536 - val_mse: 8.3319\n",
            "Epoch 363/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.8741 - mae: 1.3198 - mse: 3.8741 - val_loss: 8.2176 - val_mae: 1.9549 - val_mse: 8.2176\n",
            "Epoch 364/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.0161 - mae: 1.3354 - mse: 4.0161 - val_loss: 8.2352 - val_mae: 1.9753 - val_mse: 8.2352\n",
            "Epoch 365/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.8875 - mae: 1.3536 - mse: 3.8875 - val_loss: 8.7561 - val_mae: 2.0322 - val_mse: 8.7561\n",
            "Epoch 366/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.9037 - mae: 1.3701 - mse: 3.9037 - val_loss: 8.2804 - val_mae: 1.9971 - val_mse: 8.2804\n",
            "Epoch 367/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.9096 - mae: 1.3485 - mse: 3.9096 - val_loss: 8.4568 - val_mae: 2.0016 - val_mse: 8.4568\n",
            "Epoch 368/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.0309 - mae: 1.3917 - mse: 4.0309 - val_loss: 8.5123 - val_mae: 2.0084 - val_mse: 8.5123\n",
            "Epoch 369/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.8151 - mae: 1.3298 - mse: 3.8151 - val_loss: 8.5440 - val_mae: 1.9924 - val_mse: 8.5440\n",
            "Epoch 370/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.9496 - mae: 1.3575 - mse: 3.9496 - val_loss: 9.4513 - val_mae: 2.1481 - val_mse: 9.4513\n",
            "Epoch 371/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.0334 - mae: 1.3753 - mse: 4.0334 - val_loss: 8.2052 - val_mae: 1.9582 - val_mse: 8.2052\n",
            "Epoch 372/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.9215 - mae: 1.3416 - mse: 3.9215 - val_loss: 8.2890 - val_mae: 1.9568 - val_mse: 8.2890\n",
            "Epoch 373/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.8211 - mae: 1.3590 - mse: 3.8211 - val_loss: 8.4014 - val_mae: 1.9822 - val_mse: 8.4014\n",
            "Epoch 374/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.9954 - mae: 1.3535 - mse: 3.9954 - val_loss: 8.1145 - val_mae: 1.9430 - val_mse: 8.1145\n",
            "Epoch 375/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.8007 - mae: 1.3274 - mse: 3.8007 - val_loss: 8.0869 - val_mae: 1.9280 - val_mse: 8.0869\n",
            "Epoch 376/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.8393 - mae: 1.3209 - mse: 3.8393 - val_loss: 8.3278 - val_mae: 1.9646 - val_mse: 8.3278\n",
            "Epoch 377/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.9208 - mae: 1.3455 - mse: 3.9208 - val_loss: 8.8500 - val_mae: 2.0574 - val_mse: 8.8500\n",
            "Epoch 378/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.9151 - mae: 1.3518 - mse: 3.9151 - val_loss: 8.8315 - val_mae: 2.0499 - val_mse: 8.8315\n",
            "Epoch 379/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.0431 - mae: 1.3488 - mse: 4.0431 - val_loss: 8.3602 - val_mae: 1.9508 - val_mse: 8.3602\n",
            "Epoch 380/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.8056 - mae: 1.3427 - mse: 3.8056 - val_loss: 8.1170 - val_mae: 1.9279 - val_mse: 8.1170\n",
            "Epoch 381/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.9687 - mae: 1.4000 - mse: 3.9687 - val_loss: 8.3728 - val_mae: 1.9639 - val_mse: 8.3728\n",
            "Epoch 382/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.9037 - mae: 1.3353 - mse: 3.9037 - val_loss: 9.3028 - val_mae: 2.1273 - val_mse: 9.3028\n",
            "Epoch 383/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.8476 - mae: 1.3610 - mse: 3.8476 - val_loss: 8.1674 - val_mae: 1.9330 - val_mse: 8.1674\n",
            "Epoch 384/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.7599 - mae: 1.3183 - mse: 3.7599 - val_loss: 8.5995 - val_mae: 2.0120 - val_mse: 8.5995\n",
            "Epoch 385/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.9984 - mae: 1.3874 - mse: 3.9984 - val_loss: 8.2673 - val_mae: 1.9672 - val_mse: 8.2673\n",
            "Epoch 386/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.8945 - mae: 1.3318 - mse: 3.8945 - val_loss: 8.9116 - val_mae: 2.0621 - val_mse: 8.9116\n",
            "Epoch 387/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.8265 - mae: 1.3510 - mse: 3.8265 - val_loss: 8.3612 - val_mae: 1.9875 - val_mse: 8.3612\n",
            "Epoch 388/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.0122 - mae: 1.3283 - mse: 4.0122 - val_loss: 8.9143 - val_mae: 2.0896 - val_mse: 8.9143\n",
            "Epoch 389/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.9835 - mae: 1.3718 - mse: 3.9835 - val_loss: 8.3309 - val_mae: 1.9876 - val_mse: 8.3309\n",
            "Epoch 390/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.7031 - mae: 1.3082 - mse: 3.7031 - val_loss: 8.4641 - val_mae: 1.9875 - val_mse: 8.4641\n",
            "Epoch 391/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.8756 - mae: 1.3515 - mse: 3.8756 - val_loss: 8.5724 - val_mae: 2.0799 - val_mse: 8.5724\n",
            "Epoch 392/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.1392 - mae: 1.3801 - mse: 4.1392 - val_loss: 8.1933 - val_mae: 1.9482 - val_mse: 8.1933\n",
            "Epoch 393/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.8584 - mae: 1.3548 - mse: 3.8584 - val_loss: 8.3027 - val_mae: 1.9811 - val_mse: 8.3027\n",
            "Epoch 394/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.8540 - mae: 1.3164 - mse: 3.8540 - val_loss: 8.2842 - val_mae: 1.9650 - val_mse: 8.2842\n",
            "Epoch 395/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.8300 - mae: 1.3311 - mse: 3.8300 - val_loss: 8.2793 - val_mae: 1.9639 - val_mse: 8.2793\n",
            "Epoch 396/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.7598 - mae: 1.2978 - mse: 3.7598 - val_loss: 8.2645 - val_mae: 1.9547 - val_mse: 8.2645\n",
            "Epoch 397/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.7368 - mae: 1.3432 - mse: 3.7368 - val_loss: 8.3996 - val_mae: 2.0264 - val_mse: 8.3996\n",
            "Epoch 398/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.8899 - mae: 1.3500 - mse: 3.8899 - val_loss: 8.3650 - val_mae: 1.9891 - val_mse: 8.3650\n",
            "Epoch 399/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.9546 - mae: 1.3499 - mse: 3.9546 - val_loss: 8.2014 - val_mae: 1.9422 - val_mse: 8.2014\n",
            "Epoch 400/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.9314 - mae: 1.3362 - mse: 3.9314 - val_loss: 8.2409 - val_mae: 1.9556 - val_mse: 8.2409\n",
            "Epoch 401/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.6194 - mae: 1.2832 - mse: 3.6194 - val_loss: 8.1436 - val_mae: 1.9469 - val_mse: 8.1436\n",
            "Epoch 402/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.7576 - mae: 1.3081 - mse: 3.7576 - val_loss: 8.5449 - val_mae: 2.0232 - val_mse: 8.5449\n",
            "Epoch 403/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.7535 - mae: 1.3210 - mse: 3.7535 - val_loss: 8.6828 - val_mae: 2.0344 - val_mse: 8.6828\n",
            "Epoch 404/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.9773 - mae: 1.3419 - mse: 3.9773 - val_loss: 8.4504 - val_mae: 1.9786 - val_mse: 8.4504\n",
            "Epoch 405/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.7008 - mae: 1.3097 - mse: 3.7008 - val_loss: 8.3216 - val_mae: 2.0022 - val_mse: 8.3216\n",
            "Epoch 406/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.8294 - mae: 1.3402 - mse: 3.8294 - val_loss: 8.1230 - val_mae: 1.9395 - val_mse: 8.1230\n",
            "Epoch 407/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.7299 - mae: 1.3012 - mse: 3.7299 - val_loss: 8.6550 - val_mae: 2.0202 - val_mse: 8.6550\n",
            "Epoch 408/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.7922 - mae: 1.3178 - mse: 3.7922 - val_loss: 8.2558 - val_mae: 1.9348 - val_mse: 8.2558\n",
            "Epoch 409/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.7190 - mae: 1.2761 - mse: 3.7190 - val_loss: 8.4502 - val_mae: 1.9944 - val_mse: 8.4502\n",
            "Epoch 410/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.6100 - mae: 1.3119 - mse: 3.6100 - val_loss: 8.8254 - val_mae: 2.0256 - val_mse: 8.8254\n",
            "Epoch 411/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.8993 - mae: 1.3169 - mse: 3.8993 - val_loss: 8.1550 - val_mae: 1.9441 - val_mse: 8.1550\n",
            "Epoch 412/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.7336 - mae: 1.2922 - mse: 3.7336 - val_loss: 8.5301 - val_mae: 2.0005 - val_mse: 8.5301\n",
            "Epoch 413/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.5992 - mae: 1.2910 - mse: 3.5992 - val_loss: 8.1426 - val_mae: 1.9707 - val_mse: 8.1426\n",
            "Epoch 414/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.7454 - mae: 1.3066 - mse: 3.7454 - val_loss: 8.7261 - val_mae: 2.0479 - val_mse: 8.7261\n",
            "Epoch 415/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.9030 - mae: 1.3252 - mse: 3.9030 - val_loss: 8.2875 - val_mae: 1.9856 - val_mse: 8.2875\n",
            "Epoch 416/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.7447 - mae: 1.3111 - mse: 3.7447 - val_loss: 8.3787 - val_mae: 1.9973 - val_mse: 8.3787\n",
            "Epoch 417/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.7153 - mae: 1.3088 - mse: 3.7153 - val_loss: 8.4705 - val_mae: 2.0086 - val_mse: 8.4705\n",
            "Epoch 418/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.6596 - mae: 1.2751 - mse: 3.6596 - val_loss: 8.8820 - val_mae: 2.0667 - val_mse: 8.8820\n",
            "Epoch 419/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.7527 - mae: 1.3260 - mse: 3.7527 - val_loss: 8.0569 - val_mae: 1.9591 - val_mse: 8.0569\n",
            "Epoch 420/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.7432 - mae: 1.3212 - mse: 3.7432 - val_loss: 8.1231 - val_mae: 1.9533 - val_mse: 8.1231\n",
            "Epoch 421/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.8166 - mae: 1.2971 - mse: 3.8166 - val_loss: 8.3946 - val_mae: 2.0049 - val_mse: 8.3946\n",
            "Epoch 422/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.8208 - mae: 1.3242 - mse: 3.8208 - val_loss: 8.1772 - val_mae: 1.9292 - val_mse: 8.1772\n",
            "Epoch 423/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3.6402 - mae: 1.2591 - mse: 3.6402 - val_loss: 8.7509 - val_mae: 2.0452 - val_mse: 8.7509\n",
            "Epoch 424/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.8372 - mae: 1.3199 - mse: 3.8372 - val_loss: 8.3912 - val_mae: 1.9780 - val_mse: 8.3912\n",
            "Epoch 425/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.7145 - mae: 1.2910 - mse: 3.7145 - val_loss: 8.4626 - val_mae: 2.0142 - val_mse: 8.4626\n",
            "Epoch 426/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.5847 - mae: 1.2908 - mse: 3.5847 - val_loss: 8.3660 - val_mae: 1.9901 - val_mse: 8.3660\n",
            "Epoch 427/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.7228 - mae: 1.3028 - mse: 3.7228 - val_loss: 8.5543 - val_mae: 1.9993 - val_mse: 8.5543\n",
            "Epoch 428/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.0022 - mae: 1.3494 - mse: 4.0022 - val_loss: 8.2007 - val_mae: 1.9821 - val_mse: 8.2007\n",
            "Epoch 429/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.6584 - mae: 1.2840 - mse: 3.6584 - val_loss: 8.2458 - val_mae: 1.9820 - val_mse: 8.2458\n",
            "Epoch 430/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.7467 - mae: 1.2974 - mse: 3.7467 - val_loss: 8.2900 - val_mae: 1.9765 - val_mse: 8.2900\n",
            "Epoch 431/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.7374 - mae: 1.3090 - mse: 3.7374 - val_loss: 8.1200 - val_mae: 1.9404 - val_mse: 8.1200\n",
            "Epoch 432/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.6587 - mae: 1.2828 - mse: 3.6587 - val_loss: 8.9213 - val_mae: 2.0768 - val_mse: 8.9213\n",
            "Epoch 433/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.7633 - mae: 1.3201 - mse: 3.7633 - val_loss: 8.3381 - val_mae: 1.9935 - val_mse: 8.3381\n",
            "Epoch 434/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.6837 - mae: 1.3180 - mse: 3.6837 - val_loss: 8.1878 - val_mae: 1.9742 - val_mse: 8.1878\n",
            "Epoch 435/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.6972 - mae: 1.2847 - mse: 3.6972 - val_loss: 8.1341 - val_mae: 1.9584 - val_mse: 8.1341\n",
            "Epoch 436/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3.5589 - mae: 1.2512 - mse: 3.5589 - val_loss: 8.4333 - val_mae: 2.0015 - val_mse: 8.4333\n",
            "Epoch 437/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.6644 - mae: 1.2875 - mse: 3.6644 - val_loss: 8.2526 - val_mae: 1.9713 - val_mse: 8.2526\n",
            "Epoch 438/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.6159 - mae: 1.2780 - mse: 3.6159 - val_loss: 8.5062 - val_mae: 1.9905 - val_mse: 8.5062\n",
            "Epoch 439/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.7759 - mae: 1.2893 - mse: 3.7759 - val_loss: 9.3768 - val_mae: 2.1801 - val_mse: 9.3768\n",
            "Epoch 440/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.5902 - mae: 1.2929 - mse: 3.5902 - val_loss: 8.1703 - val_mae: 1.9639 - val_mse: 8.1703\n",
            "Epoch 441/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.7425 - mae: 1.2963 - mse: 3.7425 - val_loss: 8.1416 - val_mae: 1.9614 - val_mse: 8.1416\n",
            "Epoch 442/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.6619 - mae: 1.2802 - mse: 3.6619 - val_loss: 8.3506 - val_mae: 2.0120 - val_mse: 8.3506\n",
            "Epoch 443/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.7184 - mae: 1.2951 - mse: 3.7184 - val_loss: 8.4677 - val_mae: 2.0244 - val_mse: 8.4677\n",
            "Epoch 444/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.6710 - mae: 1.3098 - mse: 3.6710 - val_loss: 8.7761 - val_mae: 2.0601 - val_mse: 8.7761\n",
            "Epoch 445/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.7152 - mae: 1.3102 - mse: 3.7152 - val_loss: 8.4123 - val_mae: 1.9913 - val_mse: 8.4123\n",
            "Epoch 446/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.5818 - mae: 1.2505 - mse: 3.5818 - val_loss: 8.2714 - val_mae: 1.9603 - val_mse: 8.2714\n",
            "Epoch 447/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.6291 - mae: 1.2814 - mse: 3.6291 - val_loss: 8.6861 - val_mae: 2.0507 - val_mse: 8.6861\n",
            "Epoch 448/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.9128 - mae: 1.3337 - mse: 3.9128 - val_loss: 8.3893 - val_mae: 2.0137 - val_mse: 8.3893\n",
            "Epoch 449/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.5482 - mae: 1.2453 - mse: 3.5482 - val_loss: 8.3914 - val_mae: 1.9843 - val_mse: 8.3914\n",
            "Epoch 450/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.7318 - mae: 1.2675 - mse: 3.7318 - val_loss: 8.9230 - val_mae: 2.0902 - val_mse: 8.9230\n",
            "Epoch 451/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.6579 - mae: 1.2954 - mse: 3.6579 - val_loss: 8.6415 - val_mae: 2.0580 - val_mse: 8.6415\n",
            "Epoch 452/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.5438 - mae: 1.2507 - mse: 3.5438 - val_loss: 8.4086 - val_mae: 1.9607 - val_mse: 8.4086\n",
            "Epoch 453/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.6501 - mae: 1.2821 - mse: 3.6501 - val_loss: 8.6787 - val_mae: 2.0617 - val_mse: 8.6787\n",
            "Epoch 454/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.7637 - mae: 1.3007 - mse: 3.7637 - val_loss: 8.2830 - val_mae: 1.9695 - val_mse: 8.2830\n",
            "Epoch 455/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.6108 - mae: 1.2773 - mse: 3.6108 - val_loss: 8.1644 - val_mae: 1.9625 - val_mse: 8.1644\n",
            "Epoch 456/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.7247 - mae: 1.2906 - mse: 3.7247 - val_loss: 8.2659 - val_mae: 1.9711 - val_mse: 8.2659\n",
            "Epoch 457/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.5538 - mae: 1.2660 - mse: 3.5538 - val_loss: 8.2070 - val_mae: 1.9684 - val_mse: 8.2070\n",
            "Epoch 458/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.6920 - mae: 1.2954 - mse: 3.6920 - val_loss: 7.9747 - val_mae: 1.9226 - val_mse: 7.9747\n",
            "Epoch 459/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.5189 - mae: 1.2520 - mse: 3.5189 - val_loss: 8.2520 - val_mae: 1.9819 - val_mse: 8.2520\n",
            "Epoch 460/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.8072 - mae: 1.3184 - mse: 3.8072 - val_loss: 8.0777 - val_mae: 1.9529 - val_mse: 8.0777\n",
            "Epoch 461/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.5756 - mae: 1.2633 - mse: 3.5756 - val_loss: 8.3548 - val_mae: 2.0044 - val_mse: 8.3548\n",
            "Epoch 462/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.7266 - mae: 1.2699 - mse: 3.7266 - val_loss: 8.9817 - val_mae: 2.1046 - val_mse: 8.9817\n",
            "Epoch 463/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.7488 - mae: 1.2715 - mse: 3.7488 - val_loss: 8.3688 - val_mae: 2.0083 - val_mse: 8.3688\n",
            "Epoch 464/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.5163 - mae: 1.2298 - mse: 3.5163 - val_loss: 8.2598 - val_mae: 1.9442 - val_mse: 8.2598\n",
            "Epoch 465/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.6291 - mae: 1.2745 - mse: 3.6291 - val_loss: 8.0918 - val_mae: 1.9499 - val_mse: 8.0918\n",
            "Epoch 466/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.5730 - mae: 1.2469 - mse: 3.5730 - val_loss: 8.1415 - val_mae: 1.9753 - val_mse: 8.1415\n",
            "Epoch 467/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.5398 - mae: 1.2614 - mse: 3.5398 - val_loss: 8.5050 - val_mae: 2.0109 - val_mse: 8.5050\n",
            "Epoch 468/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.7578 - mae: 1.2904 - mse: 3.7578 - val_loss: 8.3890 - val_mae: 1.9888 - val_mse: 8.3890\n",
            "Epoch 469/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.5465 - mae: 1.2666 - mse: 3.5465 - val_loss: 8.2888 - val_mae: 1.9969 - val_mse: 8.2888\n",
            "Epoch 470/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.5277 - mae: 1.2677 - mse: 3.5277 - val_loss: 8.0412 - val_mae: 1.9246 - val_mse: 8.0412\n",
            "Epoch 471/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.3900 - mae: 1.2159 - mse: 3.3900 - val_loss: 10.0517 - val_mae: 2.2947 - val_mse: 10.0517\n",
            "Epoch 472/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.0404 - mae: 1.3698 - mse: 4.0404 - val_loss: 8.4776 - val_mae: 1.9944 - val_mse: 8.4776\n",
            "Epoch 473/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.5077 - mae: 1.2553 - mse: 3.5077 - val_loss: 8.0775 - val_mae: 1.9700 - val_mse: 8.0775\n",
            "Epoch 474/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.4547 - mae: 1.2530 - mse: 3.4547 - val_loss: 8.6964 - val_mae: 2.0609 - val_mse: 8.6964\n",
            "Epoch 475/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.6410 - mae: 1.3020 - mse: 3.6410 - val_loss: 8.1903 - val_mae: 1.9576 - val_mse: 8.1903\n",
            "Epoch 476/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.6317 - mae: 1.2994 - mse: 3.6317 - val_loss: 8.3921 - val_mae: 1.9945 - val_mse: 8.3921\n",
            "Epoch 477/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.7008 - mae: 1.2845 - mse: 3.7008 - val_loss: 9.1549 - val_mae: 2.1412 - val_mse: 9.1549\n",
            "Epoch 478/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.5065 - mae: 1.2411 - mse: 3.5065 - val_loss: 8.8716 - val_mae: 2.0769 - val_mse: 8.8716\n",
            "Epoch 479/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.6022 - mae: 1.2706 - mse: 3.6022 - val_loss: 7.8796 - val_mae: 1.9419 - val_mse: 7.8796\n",
            "Epoch 480/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.4861 - mae: 1.2531 - mse: 3.4861 - val_loss: 8.2630 - val_mae: 1.9663 - val_mse: 8.2630\n",
            "Epoch 481/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.5728 - mae: 1.2800 - mse: 3.5728 - val_loss: 8.0612 - val_mae: 1.9600 - val_mse: 8.0612\n",
            "Epoch 482/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.6817 - mae: 1.2650 - mse: 3.6817 - val_loss: 8.1079 - val_mae: 1.9361 - val_mse: 8.1079\n",
            "Epoch 483/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.5151 - mae: 1.2476 - mse: 3.5151 - val_loss: 8.5862 - val_mae: 2.0131 - val_mse: 8.5862\n",
            "Epoch 484/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.5223 - mae: 1.2568 - mse: 3.5223 - val_loss: 7.8417 - val_mae: 1.9116 - val_mse: 7.8417\n",
            "Epoch 485/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.5196 - mae: 1.2683 - mse: 3.5196 - val_loss: 8.1662 - val_mae: 1.9662 - val_mse: 8.1662\n",
            "Epoch 486/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.4463 - mae: 1.2496 - mse: 3.4463 - val_loss: 8.2640 - val_mae: 1.9892 - val_mse: 8.2640\n",
            "Epoch 487/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.8373 - mae: 1.3032 - mse: 3.8373 - val_loss: 7.9726 - val_mae: 1.9350 - val_mse: 7.9726\n",
            "Epoch 488/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.6189 - mae: 1.2563 - mse: 3.6189 - val_loss: 7.9706 - val_mae: 1.9224 - val_mse: 7.9706\n",
            "Epoch 489/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.5256 - mae: 1.2478 - mse: 3.5256 - val_loss: 8.2130 - val_mae: 1.9680 - val_mse: 8.2130\n",
            "Epoch 490/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.4993 - mae: 1.2412 - mse: 3.4993 - val_loss: 8.7803 - val_mae: 2.0672 - val_mse: 8.7803\n",
            "Epoch 491/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.5901 - mae: 1.2515 - mse: 3.5901 - val_loss: 7.9598 - val_mae: 1.9426 - val_mse: 7.9598\n",
            "Epoch 492/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.4946 - mae: 1.2069 - mse: 3.4946 - val_loss: 8.5627 - val_mae: 2.0315 - val_mse: 8.5627\n",
            "Epoch 493/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.4990 - mae: 1.2423 - mse: 3.4990 - val_loss: 9.1183 - val_mae: 2.1191 - val_mse: 9.1183\n",
            "Epoch 494/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.6142 - mae: 1.2630 - mse: 3.6142 - val_loss: 8.5049 - val_mae: 2.0374 - val_mse: 8.5049\n",
            "Epoch 495/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.4459 - mae: 1.2273 - mse: 3.4459 - val_loss: 8.1896 - val_mae: 1.9417 - val_mse: 8.1896\n",
            "Epoch 496/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.5012 - mae: 1.2401 - mse: 3.5012 - val_loss: 7.9698 - val_mae: 1.9323 - val_mse: 7.9698\n",
            "Epoch 497/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.5527 - mae: 1.2480 - mse: 3.5527 - val_loss: 8.3193 - val_mae: 2.0006 - val_mse: 8.3193\n",
            "Epoch 498/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.4875 - mae: 1.2466 - mse: 3.4875 - val_loss: 8.0727 - val_mae: 1.9503 - val_mse: 8.0727\n",
            "Epoch 499/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.6422 - mae: 1.2379 - mse: 3.6422 - val_loss: 8.6417 - val_mae: 2.0463 - val_mse: 8.6417\n",
            "Epoch 500/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.5514 - mae: 1.2550 - mse: 3.5514 - val_loss: 7.8623 - val_mae: 1.9469 - val_mse: 7.8623\n",
            "Epoch 501/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.5097 - mae: 1.2182 - mse: 3.5097 - val_loss: 8.3195 - val_mae: 2.0008 - val_mse: 8.3195\n",
            "Epoch 502/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.4221 - mae: 1.2444 - mse: 3.4221 - val_loss: 8.1881 - val_mae: 1.9903 - val_mse: 8.1881\n",
            "Epoch 503/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.5038 - mae: 1.2436 - mse: 3.5038 - val_loss: 8.1524 - val_mae: 1.9786 - val_mse: 8.1524\n",
            "Epoch 504/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.7080 - mae: 1.2381 - mse: 3.7080 - val_loss: 7.9632 - val_mae: 1.9404 - val_mse: 7.9632\n",
            "Epoch 505/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.5957 - mae: 1.2735 - mse: 3.5957 - val_loss: 8.4573 - val_mae: 2.0147 - val_mse: 8.4573\n",
            "Epoch 506/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.3865 - mae: 1.1990 - mse: 3.3865 - val_loss: 7.8371 - val_mae: 1.9224 - val_mse: 7.8371\n",
            "Epoch 507/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.3012 - mae: 1.1823 - mse: 3.3012 - val_loss: 9.4504 - val_mae: 2.1972 - val_mse: 9.4504\n",
            "Epoch 508/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.5630 - mae: 1.2458 - mse: 3.5630 - val_loss: 8.0358 - val_mae: 1.9572 - val_mse: 8.0358\n",
            "Epoch 509/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.4490 - mae: 1.2024 - mse: 3.4490 - val_loss: 8.0838 - val_mae: 1.9691 - val_mse: 8.0838\n",
            "Epoch 510/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.5049 - mae: 1.2703 - mse: 3.5049 - val_loss: 7.8505 - val_mae: 1.9152 - val_mse: 7.8505\n",
            "Epoch 511/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.4517 - mae: 1.1846 - mse: 3.4517 - val_loss: 7.9263 - val_mae: 1.9498 - val_mse: 7.9263\n",
            "Epoch 512/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.3881 - mae: 1.2241 - mse: 3.3881 - val_loss: 8.2830 - val_mae: 1.9958 - val_mse: 8.2830\n",
            "Epoch 513/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.4775 - mae: 1.2376 - mse: 3.4775 - val_loss: 8.0454 - val_mae: 1.9630 - val_mse: 8.0454\n",
            "Epoch 514/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.4196 - mae: 1.2339 - mse: 3.4196 - val_loss: 8.0260 - val_mae: 1.9888 - val_mse: 8.0260\n",
            "Epoch 515/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.5626 - mae: 1.2203 - mse: 3.5626 - val_loss: 7.8616 - val_mae: 1.9297 - val_mse: 7.8616\n",
            "Epoch 516/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.6325 - mae: 1.2526 - mse: 3.6325 - val_loss: 7.8404 - val_mae: 1.9359 - val_mse: 7.8404\n",
            "Epoch 517/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.4141 - mae: 1.2150 - mse: 3.4141 - val_loss: 7.9585 - val_mae: 1.9510 - val_mse: 7.9585\n",
            "Epoch 518/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.5228 - mae: 1.2118 - mse: 3.5228 - val_loss: 8.5944 - val_mae: 2.0577 - val_mse: 8.5944\n",
            "Epoch 519/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.5104 - mae: 1.2156 - mse: 3.5104 - val_loss: 8.4638 - val_mae: 2.0269 - val_mse: 8.4638\n",
            "Epoch 520/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.4177 - mae: 1.2353 - mse: 3.4177 - val_loss: 8.3656 - val_mae: 1.9883 - val_mse: 8.3656\n",
            "Epoch 521/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.7453 - mae: 1.2869 - mse: 3.7453 - val_loss: 7.9127 - val_mae: 1.9408 - val_mse: 7.9127\n",
            "Epoch 522/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.3417 - mae: 1.2033 - mse: 3.3417 - val_loss: 8.0131 - val_mae: 1.9737 - val_mse: 8.0131\n",
            "Epoch 523/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.4241 - mae: 1.2093 - mse: 3.4241 - val_loss: 8.2939 - val_mae: 1.9979 - val_mse: 8.2939\n",
            "Epoch 524/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.6289 - mae: 1.2327 - mse: 3.6289 - val_loss: 7.9582 - val_mae: 1.9435 - val_mse: 7.9582\n",
            "Epoch 525/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.5244 - mae: 1.2635 - mse: 3.5244 - val_loss: 8.0126 - val_mae: 1.9895 - val_mse: 8.0126\n",
            "Epoch 526/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.4465 - mae: 1.2350 - mse: 3.4465 - val_loss: 8.4040 - val_mae: 2.0015 - val_mse: 8.4040\n",
            "Epoch 527/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.4004 - mae: 1.2020 - mse: 3.4004 - val_loss: 8.1630 - val_mae: 1.9569 - val_mse: 8.1630\n",
            "Epoch 528/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.4516 - mae: 1.1965 - mse: 3.4516 - val_loss: 8.4950 - val_mae: 2.0532 - val_mse: 8.4950\n",
            "Epoch 529/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.3987 - mae: 1.2028 - mse: 3.3987 - val_loss: 7.9324 - val_mae: 1.9313 - val_mse: 7.9324\n",
            "Epoch 530/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.4199 - mae: 1.2172 - mse: 3.4199 - val_loss: 8.0110 - val_mae: 1.9561 - val_mse: 8.0110\n",
            "Epoch 531/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.3516 - mae: 1.2414 - mse: 3.3516 - val_loss: 7.9218 - val_mae: 1.9178 - val_mse: 7.9218\n",
            "Epoch 532/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.3819 - mae: 1.2206 - mse: 3.3819 - val_loss: 7.9180 - val_mae: 1.9545 - val_mse: 7.9180\n",
            "Epoch 533/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.3669 - mae: 1.2053 - mse: 3.3669 - val_loss: 7.8555 - val_mae: 1.9166 - val_mse: 7.8555\n",
            "Epoch 534/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.4786 - mae: 1.2321 - mse: 3.4786 - val_loss: 8.1023 - val_mae: 1.9791 - val_mse: 8.1023\n",
            "Epoch 535/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.4773 - mae: 1.2750 - mse: 3.4773 - val_loss: 8.3032 - val_mae: 2.0146 - val_mse: 8.3032\n",
            "Epoch 536/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.4050 - mae: 1.2166 - mse: 3.4050 - val_loss: 7.9139 - val_mae: 1.9528 - val_mse: 7.9139\n",
            "Epoch 537/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.4186 - mae: 1.2112 - mse: 3.4186 - val_loss: 9.3910 - val_mae: 2.2055 - val_mse: 9.3910\n",
            "Epoch 538/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.3463 - mae: 1.1908 - mse: 3.3463 - val_loss: 8.0401 - val_mae: 1.9771 - val_mse: 8.0401\n",
            "Epoch 539/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.3780 - mae: 1.2094 - mse: 3.3780 - val_loss: 8.3926 - val_mae: 2.0247 - val_mse: 8.3926\n",
            "Epoch 540/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.4101 - mae: 1.2030 - mse: 3.4101 - val_loss: 8.2541 - val_mae: 1.9908 - val_mse: 8.2541\n",
            "Epoch 541/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.3691 - mae: 1.1990 - mse: 3.3691 - val_loss: 8.3663 - val_mae: 2.0009 - val_mse: 8.3663\n",
            "Epoch 542/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.4027 - mae: 1.2150 - mse: 3.4027 - val_loss: 8.0168 - val_mae: 1.9525 - val_mse: 8.0168\n",
            "Epoch 543/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.3660 - mae: 1.2057 - mse: 3.3660 - val_loss: 8.3897 - val_mae: 1.9964 - val_mse: 8.3897\n",
            "Epoch 544/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.4845 - mae: 1.2214 - mse: 3.4845 - val_loss: 8.0354 - val_mae: 1.9709 - val_mse: 8.0354\n",
            "Epoch 545/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.4597 - mae: 1.1997 - mse: 3.4597 - val_loss: 8.0258 - val_mae: 1.9668 - val_mse: 8.0258\n",
            "Epoch 546/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.3015 - mae: 1.1742 - mse: 3.3015 - val_loss: 8.4724 - val_mae: 2.0225 - val_mse: 8.4724\n",
            "Epoch 547/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.3195 - mae: 1.1741 - mse: 3.3195 - val_loss: 8.6957 - val_mae: 2.0562 - val_mse: 8.6957\n",
            "Epoch 548/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.4796 - mae: 1.2188 - mse: 3.4796 - val_loss: 8.0987 - val_mae: 1.9591 - val_mse: 8.0987\n",
            "Epoch 549/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.3513 - mae: 1.1858 - mse: 3.3513 - val_loss: 7.7334 - val_mae: 1.9186 - val_mse: 7.7334\n",
            "Epoch 550/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.3627 - mae: 1.2052 - mse: 3.3627 - val_loss: 8.0319 - val_mae: 1.9757 - val_mse: 8.0319\n",
            "Epoch 551/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.2980 - mae: 1.1974 - mse: 3.2980 - val_loss: 9.1918 - val_mae: 2.1489 - val_mse: 9.1918\n",
            "Epoch 552/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.4786 - mae: 1.2282 - mse: 3.4786 - val_loss: 9.3783 - val_mae: 2.1908 - val_mse: 9.3783\n",
            "Epoch 553/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.3662 - mae: 1.2450 - mse: 3.3662 - val_loss: 8.2923 - val_mae: 2.0061 - val_mse: 8.2923\n",
            "Epoch 554/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.3148 - mae: 1.2005 - mse: 3.3148 - val_loss: 7.8062 - val_mae: 1.9471 - val_mse: 7.8062\n",
            "Epoch 555/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.3414 - mae: 1.2096 - mse: 3.3414 - val_loss: 9.0312 - val_mae: 2.1291 - val_mse: 9.0312\n",
            "Epoch 556/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.5949 - mae: 1.2469 - mse: 3.5949 - val_loss: 8.5983 - val_mae: 2.0394 - val_mse: 8.5983\n",
            "Epoch 557/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.5234 - mae: 1.2345 - mse: 3.5234 - val_loss: 8.2823 - val_mae: 2.0117 - val_mse: 8.2823\n",
            "Epoch 558/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.3309 - mae: 1.1771 - mse: 3.3309 - val_loss: 8.1420 - val_mae: 1.9951 - val_mse: 8.1420\n",
            "Epoch 559/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.4652 - mae: 1.1769 - mse: 3.4652 - val_loss: 7.9572 - val_mae: 1.9663 - val_mse: 7.9572\n",
            "Epoch 560/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.3588 - mae: 1.2018 - mse: 3.3588 - val_loss: 8.0448 - val_mae: 1.9509 - val_mse: 8.0448\n",
            "Epoch 561/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.2848 - mae: 1.1758 - mse: 3.2848 - val_loss: 8.1396 - val_mae: 1.9767 - val_mse: 8.1396\n",
            "Epoch 562/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.4853 - mae: 1.2006 - mse: 3.4853 - val_loss: 8.9624 - val_mae: 2.1186 - val_mse: 8.9624\n",
            "Epoch 563/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.4185 - mae: 1.1963 - mse: 3.4185 - val_loss: 8.2528 - val_mae: 2.0002 - val_mse: 8.2528\n",
            "Epoch 564/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.1995 - mae: 1.1560 - mse: 3.1995 - val_loss: 8.0180 - val_mae: 1.9739 - val_mse: 8.0180\n",
            "Epoch 565/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.4579 - mae: 1.2507 - mse: 3.4579 - val_loss: 7.8990 - val_mae: 1.9687 - val_mse: 7.8990\n",
            "Epoch 566/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.5164 - mae: 1.2117 - mse: 3.5164 - val_loss: 8.0596 - val_mae: 1.9802 - val_mse: 8.0596\n",
            "Epoch 567/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.2269 - mae: 1.1654 - mse: 3.2269 - val_loss: 7.8961 - val_mae: 1.9369 - val_mse: 7.8961\n",
            "Epoch 568/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.3025 - mae: 1.1805 - mse: 3.3025 - val_loss: 8.3800 - val_mae: 1.9862 - val_mse: 8.3800\n",
            "Epoch 569/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.5224 - mae: 1.2380 - mse: 3.5224 - val_loss: 7.9483 - val_mae: 1.9388 - val_mse: 7.9483\n",
            "Epoch 570/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.3147 - mae: 1.1863 - mse: 3.3147 - val_loss: 8.2418 - val_mae: 2.0093 - val_mse: 8.2418\n",
            "Epoch 571/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.2163 - mae: 1.1683 - mse: 3.2163 - val_loss: 8.4092 - val_mae: 2.0214 - val_mse: 8.4092\n",
            "Epoch 572/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.2159 - mae: 1.1730 - mse: 3.2159 - val_loss: 8.6474 - val_mae: 2.0628 - val_mse: 8.6474\n",
            "Epoch 573/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.2074 - mae: 1.1808 - mse: 3.2074 - val_loss: 8.3206 - val_mae: 1.9999 - val_mse: 8.3206\n",
            "Epoch 574/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.5315 - mae: 1.2252 - mse: 3.5315 - val_loss: 8.6302 - val_mae: 2.0479 - val_mse: 8.6302\n",
            "Epoch 575/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.2961 - mae: 1.1869 - mse: 3.2961 - val_loss: 8.1769 - val_mae: 1.9681 - val_mse: 8.1769\n",
            "Epoch 576/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.3937 - mae: 1.2278 - mse: 3.3937 - val_loss: 7.8856 - val_mae: 1.9356 - val_mse: 7.8856\n",
            "Epoch 577/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.4516 - mae: 1.2035 - mse: 3.4516 - val_loss: 8.1510 - val_mae: 1.9856 - val_mse: 8.1510\n",
            "Epoch 578/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.3608 - mae: 1.1896 - mse: 3.3608 - val_loss: 8.2395 - val_mae: 1.9912 - val_mse: 8.2395\n",
            "Epoch 579/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.2532 - mae: 1.1555 - mse: 3.2532 - val_loss: 8.4321 - val_mae: 2.0401 - val_mse: 8.4321\n",
            "Epoch 580/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.4743 - mae: 1.2015 - mse: 3.4743 - val_loss: 8.0211 - val_mae: 1.9752 - val_mse: 8.0211\n",
            "Epoch 581/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.3066 - mae: 1.1930 - mse: 3.3066 - val_loss: 8.1238 - val_mae: 1.9831 - val_mse: 8.1238\n",
            "Epoch 582/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.2725 - mae: 1.1592 - mse: 3.2725 - val_loss: 8.3859 - val_mae: 1.9999 - val_mse: 8.3859\n",
            "Epoch 583/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.4629 - mae: 1.2318 - mse: 3.4629 - val_loss: 8.0305 - val_mae: 1.9729 - val_mse: 8.0305\n",
            "Epoch 584/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.4101 - mae: 1.2004 - mse: 3.4101 - val_loss: 9.6773 - val_mae: 2.2389 - val_mse: 9.6773\n",
            "Epoch 585/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.5215 - mae: 1.2198 - mse: 3.5215 - val_loss: 7.8496 - val_mae: 1.9463 - val_mse: 7.8496\n",
            "Epoch 586/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.2495 - mae: 1.1845 - mse: 3.2495 - val_loss: 7.8879 - val_mae: 1.9543 - val_mse: 7.8879\n",
            "Epoch 587/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.2713 - mae: 1.1663 - mse: 3.2713 - val_loss: 8.1467 - val_mae: 1.9899 - val_mse: 8.1467\n",
            "Epoch 588/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.1730 - mae: 1.1385 - mse: 3.1730 - val_loss: 8.0905 - val_mae: 1.9814 - val_mse: 8.0905\n",
            "Epoch 589/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.2174 - mae: 1.1872 - mse: 3.2174 - val_loss: 7.7736 - val_mae: 1.9410 - val_mse: 7.7736\n",
            "Epoch 590/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.2378 - mae: 1.1714 - mse: 3.2378 - val_loss: 8.9845 - val_mae: 2.1422 - val_mse: 8.9845\n",
            "Epoch 591/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.3204 - mae: 1.1965 - mse: 3.3204 - val_loss: 7.9492 - val_mae: 1.9491 - val_mse: 7.9492\n",
            "Epoch 592/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.2112 - mae: 1.1604 - mse: 3.2112 - val_loss: 8.4002 - val_mae: 2.0302 - val_mse: 8.4002\n",
            "Epoch 593/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.4247 - mae: 1.2105 - mse: 3.4247 - val_loss: 8.8958 - val_mae: 2.1173 - val_mse: 8.8958\n",
            "Epoch 594/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.1747 - mae: 1.1921 - mse: 3.1747 - val_loss: 8.6551 - val_mae: 2.0650 - val_mse: 8.6551\n",
            "Epoch 595/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.3163 - mae: 1.1579 - mse: 3.3163 - val_loss: 8.5508 - val_mae: 2.0334 - val_mse: 8.5508\n",
            "Epoch 596/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.3056 - mae: 1.1680 - mse: 3.3056 - val_loss: 8.5396 - val_mae: 2.0370 - val_mse: 8.5396\n",
            "Epoch 597/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.4996 - mae: 1.2144 - mse: 3.4996 - val_loss: 8.1842 - val_mae: 1.9918 - val_mse: 8.1842\n",
            "Epoch 598/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.3108 - mae: 1.1651 - mse: 3.3108 - val_loss: 8.2436 - val_mae: 2.0075 - val_mse: 8.2436\n",
            "Epoch 599/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.1351 - mae: 1.1434 - mse: 3.1351 - val_loss: 8.2315 - val_mae: 1.9916 - val_mse: 8.2315\n",
            "Epoch 600/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.3730 - mae: 1.1891 - mse: 3.3730 - val_loss: 8.2583 - val_mae: 1.9904 - val_mse: 8.2583\n",
            "Epoch 601/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.1829 - mae: 1.1413 - mse: 3.1829 - val_loss: 8.3906 - val_mae: 2.0394 - val_mse: 8.3906\n",
            "Epoch 602/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.1439 - mae: 1.1622 - mse: 3.1439 - val_loss: 8.8241 - val_mae: 2.0696 - val_mse: 8.8241\n",
            "Epoch 603/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.3776 - mae: 1.1887 - mse: 3.3776 - val_loss: 8.5113 - val_mae: 2.0710 - val_mse: 8.5113\n",
            "Epoch 604/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.3492 - mae: 1.1979 - mse: 3.3492 - val_loss: 8.0946 - val_mae: 1.9838 - val_mse: 8.0946\n",
            "Epoch 605/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.2432 - mae: 1.1667 - mse: 3.2432 - val_loss: 8.0147 - val_mae: 1.9571 - val_mse: 8.0147\n",
            "Epoch 606/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.1916 - mae: 1.1474 - mse: 3.1916 - val_loss: 8.1282 - val_mae: 1.9931 - val_mse: 8.1282\n",
            "Epoch 607/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.2802 - mae: 1.1655 - mse: 3.2802 - val_loss: 8.2832 - val_mae: 2.0171 - val_mse: 8.2832\n",
            "Epoch 608/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.1675 - mae: 1.1737 - mse: 3.1675 - val_loss: 8.2908 - val_mae: 1.9742 - val_mse: 8.2908\n",
            "Epoch 609/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.1724 - mae: 1.1371 - mse: 3.1724 - val_loss: 7.8732 - val_mae: 1.9213 - val_mse: 7.8732\n",
            "Epoch 610/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.3355 - mae: 1.2167 - mse: 3.3355 - val_loss: 8.1801 - val_mae: 1.9471 - val_mse: 8.1801\n",
            "Epoch 611/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.1508 - mae: 1.1776 - mse: 3.1508 - val_loss: 8.1302 - val_mae: 1.9632 - val_mse: 8.1302\n",
            "Epoch 612/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.1732 - mae: 1.1613 - mse: 3.1732 - val_loss: 8.1617 - val_mae: 2.0043 - val_mse: 8.1617\n",
            "Epoch 613/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.2924 - mae: 1.1753 - mse: 3.2924 - val_loss: 8.6316 - val_mae: 2.0457 - val_mse: 8.6316\n",
            "Epoch 614/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.4287 - mae: 1.1959 - mse: 3.4287 - val_loss: 7.8871 - val_mae: 1.9306 - val_mse: 7.8871\n",
            "Epoch 615/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.1099 - mae: 1.1324 - mse: 3.1099 - val_loss: 8.1055 - val_mae: 1.9436 - val_mse: 8.1055\n",
            "Epoch 616/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.2044 - mae: 1.1543 - mse: 3.2044 - val_loss: 8.9118 - val_mae: 2.0829 - val_mse: 8.9118\n",
            "Epoch 617/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.2667 - mae: 1.1736 - mse: 3.2667 - val_loss: 8.0748 - val_mae: 1.9411 - val_mse: 8.0748\n",
            "Epoch 618/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.2137 - mae: 1.1472 - mse: 3.2137 - val_loss: 8.1587 - val_mae: 1.9959 - val_mse: 8.1587\n",
            "Epoch 619/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.1538 - mae: 1.1457 - mse: 3.1538 - val_loss: 7.7578 - val_mae: 1.9114 - val_mse: 7.7578\n",
            "Epoch 620/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.1164 - mae: 1.1550 - mse: 3.1164 - val_loss: 8.1104 - val_mae: 1.9753 - val_mse: 8.1104\n",
            "Epoch 621/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.2060 - mae: 1.1661 - mse: 3.2060 - val_loss: 8.2260 - val_mae: 1.9715 - val_mse: 8.2260\n",
            "Epoch 622/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.4548 - mae: 1.2214 - mse: 3.4548 - val_loss: 7.7836 - val_mae: 1.9162 - val_mse: 7.7836\n",
            "Epoch 623/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.2337 - mae: 1.1577 - mse: 3.2337 - val_loss: 8.0519 - val_mae: 1.9679 - val_mse: 8.0519\n",
            "Epoch 624/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.0988 - mae: 1.1303 - mse: 3.0988 - val_loss: 8.5099 - val_mae: 2.0347 - val_mse: 8.5099\n",
            "Epoch 625/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.1052 - mae: 1.1481 - mse: 3.1052 - val_loss: 8.2777 - val_mae: 2.0221 - val_mse: 8.2777\n",
            "Epoch 626/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.2375 - mae: 1.1848 - mse: 3.2375 - val_loss: 8.2969 - val_mae: 2.0144 - val_mse: 8.2969\n",
            "Epoch 627/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.3745 - mae: 1.1682 - mse: 3.3745 - val_loss: 7.9847 - val_mae: 1.9557 - val_mse: 7.9847\n",
            "Epoch 628/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.2689 - mae: 1.1533 - mse: 3.2689 - val_loss: 8.0113 - val_mae: 1.9576 - val_mse: 8.0113\n",
            "Epoch 629/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.1423 - mae: 1.1506 - mse: 3.1423 - val_loss: 8.4885 - val_mae: 2.0339 - val_mse: 8.4885\n",
            "Epoch 630/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.3112 - mae: 1.1941 - mse: 3.3112 - val_loss: 8.3185 - val_mae: 2.0028 - val_mse: 8.3185\n",
            "Epoch 631/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.0394 - mae: 1.1130 - mse: 3.0394 - val_loss: 8.0462 - val_mae: 1.9671 - val_mse: 8.0462\n",
            "Epoch 632/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.3884 - mae: 1.2084 - mse: 3.3884 - val_loss: 8.0817 - val_mae: 1.9691 - val_mse: 8.0817\n",
            "Epoch 633/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.2531 - mae: 1.1555 - mse: 3.2531 - val_loss: 7.9579 - val_mae: 1.9788 - val_mse: 7.9579\n",
            "Epoch 634/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.1498 - mae: 1.1257 - mse: 3.1498 - val_loss: 8.4346 - val_mae: 2.0278 - val_mse: 8.4346\n",
            "Epoch 635/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.1348 - mae: 1.1428 - mse: 3.1348 - val_loss: 7.9243 - val_mae: 1.9498 - val_mse: 7.9243\n",
            "Epoch 636/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.2264 - mae: 1.1407 - mse: 3.2264 - val_loss: 7.9734 - val_mae: 1.9529 - val_mse: 7.9734\n",
            "Epoch 637/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.1283 - mae: 1.1324 - mse: 3.1283 - val_loss: 8.1358 - val_mae: 1.9917 - val_mse: 8.1358\n",
            "Epoch 638/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.1614 - mae: 1.1402 - mse: 3.1614 - val_loss: 8.2312 - val_mae: 2.0016 - val_mse: 8.2312\n",
            "Epoch 639/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.2021 - mae: 1.1568 - mse: 3.2021 - val_loss: 7.9237 - val_mae: 1.9423 - val_mse: 7.9237\n",
            "Epoch 640/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.2199 - mae: 1.1382 - mse: 3.2199 - val_loss: 8.5171 - val_mae: 2.0071 - val_mse: 8.5171\n",
            "Epoch 641/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.1046 - mae: 1.1308 - mse: 3.1046 - val_loss: 8.0544 - val_mae: 1.9611 - val_mse: 8.0544\n",
            "Epoch 642/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.2059 - mae: 1.1636 - mse: 3.2059 - val_loss: 7.9200 - val_mae: 1.9227 - val_mse: 7.9200\n",
            "Epoch 643/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.1315 - mae: 1.1268 - mse: 3.1315 - val_loss: 8.3145 - val_mae: 2.0060 - val_mse: 8.3145\n",
            "Epoch 644/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.2946 - mae: 1.1761 - mse: 3.2946 - val_loss: 8.2789 - val_mae: 1.9849 - val_mse: 8.2789\n",
            "Epoch 645/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.1004 - mae: 1.1253 - mse: 3.1004 - val_loss: 8.3241 - val_mae: 2.0198 - val_mse: 8.3241\n",
            "Epoch 646/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.0757 - mae: 1.1062 - mse: 3.0757 - val_loss: 8.4214 - val_mae: 2.0029 - val_mse: 8.4214\n",
            "Epoch 647/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3.5139 - mae: 1.2009 - mse: 3.5139 - val_loss: 8.3230 - val_mae: 2.0035 - val_mse: 8.3230\n",
            "Epoch 648/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.2818 - mae: 1.1581 - mse: 3.2818 - val_loss: 8.1731 - val_mae: 1.9900 - val_mse: 8.1731\n",
            "Epoch 649/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.0680 - mae: 1.1323 - mse: 3.0680 - val_loss: 8.0347 - val_mae: 1.9833 - val_mse: 8.0347\n",
            "Epoch 650/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.1875 - mae: 1.1188 - mse: 3.1875 - val_loss: 8.3496 - val_mae: 2.0431 - val_mse: 8.3496\n",
            "Epoch 651/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.9325 - mae: 1.1162 - mse: 2.9325 - val_loss: 9.0524 - val_mae: 2.1304 - val_mse: 9.0524\n",
            "Epoch 652/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.1630 - mae: 1.1734 - mse: 3.1630 - val_loss: 8.0922 - val_mae: 1.9768 - val_mse: 8.0922\n",
            "Epoch 653/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.1429 - mae: 1.1442 - mse: 3.1429 - val_loss: 8.2109 - val_mae: 1.9935 - val_mse: 8.2109\n",
            "Epoch 654/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.0890 - mae: 1.1452 - mse: 3.0890 - val_loss: 8.2158 - val_mae: 1.9829 - val_mse: 8.2158\n",
            "Epoch 655/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.1023 - mae: 1.1311 - mse: 3.1023 - val_loss: 8.1638 - val_mae: 1.9803 - val_mse: 8.1638\n",
            "Epoch 656/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.0886 - mae: 1.1092 - mse: 3.0886 - val_loss: 8.4070 - val_mae: 2.0336 - val_mse: 8.4070\n",
            "Epoch 657/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.0874 - mae: 1.1503 - mse: 3.0874 - val_loss: 8.1527 - val_mae: 1.9860 - val_mse: 8.1527\n",
            "Epoch 658/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.2485 - mae: 1.1689 - mse: 3.2485 - val_loss: 8.1558 - val_mae: 2.0185 - val_mse: 8.1558\n",
            "Epoch 659/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.1077 - mae: 1.1223 - mse: 3.1077 - val_loss: 8.3410 - val_mae: 2.0302 - val_mse: 8.3410\n",
            "Epoch 660/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.2235 - mae: 1.1641 - mse: 3.2235 - val_loss: 8.7210 - val_mae: 2.0785 - val_mse: 8.7210\n",
            "Epoch 661/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.1095 - mae: 1.1124 - mse: 3.1095 - val_loss: 8.3480 - val_mae: 2.0087 - val_mse: 8.3480\n",
            "Epoch 662/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.0353 - mae: 1.1284 - mse: 3.0353 - val_loss: 9.4261 - val_mae: 2.2156 - val_mse: 9.4261\n",
            "Epoch 663/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.2648 - mae: 1.1853 - mse: 3.2648 - val_loss: 8.0713 - val_mae: 1.9688 - val_mse: 8.0713\n",
            "Epoch 664/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.0292 - mae: 1.1274 - mse: 3.0292 - val_loss: 8.2623 - val_mae: 1.9967 - val_mse: 8.2623\n",
            "Epoch 665/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.1337 - mae: 1.1411 - mse: 3.1337 - val_loss: 8.3678 - val_mae: 2.0271 - val_mse: 8.3678\n",
            "Epoch 666/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.1925 - mae: 1.1421 - mse: 3.1925 - val_loss: 7.8585 - val_mae: 1.9432 - val_mse: 7.8585\n",
            "Epoch 667/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.0177 - mae: 1.1196 - mse: 3.0177 - val_loss: 8.7671 - val_mae: 2.1160 - val_mse: 8.7671\n",
            "Epoch 668/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.3280 - mae: 1.1882 - mse: 3.3280 - val_loss: 8.2494 - val_mae: 2.0077 - val_mse: 8.2494\n",
            "Epoch 669/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.0705 - mae: 1.1463 - mse: 3.0705 - val_loss: 8.2055 - val_mae: 2.0283 - val_mse: 8.2055\n",
            "Epoch 670/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.0630 - mae: 1.1156 - mse: 3.0630 - val_loss: 8.4745 - val_mae: 2.0454 - val_mse: 8.4745\n",
            "Epoch 671/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.0505 - mae: 1.1156 - mse: 3.0505 - val_loss: 7.8906 - val_mae: 1.9540 - val_mse: 7.8906\n",
            "Epoch 672/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.0858 - mae: 1.1342 - mse: 3.0858 - val_loss: 8.5005 - val_mae: 2.0591 - val_mse: 8.5005\n",
            "Epoch 673/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.1140 - mae: 1.1395 - mse: 3.1140 - val_loss: 8.5613 - val_mae: 2.0485 - val_mse: 8.5613\n",
            "Epoch 674/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.1095 - mae: 1.1604 - mse: 3.1095 - val_loss: 8.0881 - val_mae: 1.9640 - val_mse: 8.0881\n",
            "Epoch 675/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.0453 - mae: 1.1236 - mse: 3.0453 - val_loss: 8.1022 - val_mae: 1.9727 - val_mse: 8.1022\n",
            "Epoch 676/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.2176 - mae: 1.1696 - mse: 3.2176 - val_loss: 7.9687 - val_mae: 1.9657 - val_mse: 7.9687\n",
            "Epoch 677/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.0184 - mae: 1.0998 - mse: 3.0184 - val_loss: 8.3399 - val_mae: 2.0326 - val_mse: 8.3399\n",
            "Epoch 678/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.8998 - mae: 1.0855 - mse: 2.8998 - val_loss: 8.1089 - val_mae: 2.0039 - val_mse: 8.1089\n",
            "Epoch 679/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.1281 - mae: 1.1639 - mse: 3.1281 - val_loss: 7.8784 - val_mae: 1.9661 - val_mse: 7.8784\n",
            "Epoch 680/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.0349 - mae: 1.1218 - mse: 3.0349 - val_loss: 7.9702 - val_mae: 1.9510 - val_mse: 7.9702\n",
            "Epoch 681/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.9871 - mae: 1.1040 - mse: 2.9871 - val_loss: 8.1490 - val_mae: 1.9824 - val_mse: 8.1490\n",
            "Epoch 682/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.0479 - mae: 1.1311 - mse: 3.0479 - val_loss: 8.3671 - val_mae: 2.0184 - val_mse: 8.3671\n",
            "Epoch 683/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.1728 - mae: 1.1096 - mse: 3.1728 - val_loss: 7.9010 - val_mae: 1.9456 - val_mse: 7.9010\n",
            "Epoch 684/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.9642 - mae: 1.0759 - mse: 2.9642 - val_loss: 9.3355 - val_mae: 2.1890 - val_mse: 9.3355\n",
            "Epoch 685/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.9693 - mae: 1.1118 - mse: 2.9693 - val_loss: 8.2141 - val_mae: 2.0529 - val_mse: 8.2141\n",
            "Epoch 686/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.0611 - mae: 1.1260 - mse: 3.0611 - val_loss: 9.2145 - val_mae: 2.1567 - val_mse: 9.2145\n",
            "Epoch 687/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.1334 - mae: 1.1134 - mse: 3.1334 - val_loss: 8.7395 - val_mae: 2.0760 - val_mse: 8.7395\n",
            "Epoch 688/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.9527 - mae: 1.1124 - mse: 2.9527 - val_loss: 8.3532 - val_mae: 2.0281 - val_mse: 8.3532\n",
            "Epoch 689/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.1936 - mae: 1.1391 - mse: 3.1936 - val_loss: 8.2728 - val_mae: 2.0243 - val_mse: 8.2728\n",
            "Epoch 690/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.0019 - mae: 1.0959 - mse: 3.0019 - val_loss: 7.9631 - val_mae: 1.9532 - val_mse: 7.9631\n",
            "Epoch 691/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.0161 - mae: 1.1247 - mse: 3.0161 - val_loss: 7.7016 - val_mae: 1.9337 - val_mse: 7.7016\n",
            "Epoch 692/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.0343 - mae: 1.1306 - mse: 3.0343 - val_loss: 7.9449 - val_mae: 1.9385 - val_mse: 7.9449\n",
            "Epoch 693/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.0331 - mae: 1.1247 - mse: 3.0331 - val_loss: 8.1168 - val_mae: 1.9916 - val_mse: 8.1168\n",
            "Epoch 694/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.9718 - mae: 1.0785 - mse: 2.9718 - val_loss: 9.8438 - val_mae: 2.2777 - val_mse: 9.8438\n",
            "Epoch 695/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.0958 - mae: 1.1546 - mse: 3.0958 - val_loss: 8.6807 - val_mae: 2.0690 - val_mse: 8.6807\n",
            "Epoch 696/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.0092 - mae: 1.0939 - mse: 3.0092 - val_loss: 8.1779 - val_mae: 2.0005 - val_mse: 8.1779\n",
            "Epoch 697/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.9593 - mae: 1.0808 - mse: 2.9593 - val_loss: 7.8400 - val_mae: 1.9454 - val_mse: 7.8400\n",
            "Epoch 698/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.0305 - mae: 1.1141 - mse: 3.0305 - val_loss: 8.6753 - val_mae: 2.0803 - val_mse: 8.6753\n",
            "Epoch 699/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.0647 - mae: 1.1413 - mse: 3.0647 - val_loss: 7.7992 - val_mae: 1.9418 - val_mse: 7.7992\n",
            "Epoch 700/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.0440 - mae: 1.1127 - mse: 3.0440 - val_loss: 8.1341 - val_mae: 2.0028 - val_mse: 8.1341\n",
            "Epoch 701/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.0972 - mae: 1.1323 - mse: 3.0972 - val_loss: 8.4079 - val_mae: 2.0154 - val_mse: 8.4079\n",
            "Epoch 702/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.9496 - mae: 1.0956 - mse: 2.9496 - val_loss: 7.9019 - val_mae: 1.9646 - val_mse: 7.9019\n",
            "Epoch 703/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.9960 - mae: 1.0924 - mse: 2.9960 - val_loss: 8.2808 - val_mae: 2.0406 - val_mse: 8.2808\n",
            "Epoch 704/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.1330 - mae: 1.1363 - mse: 3.1330 - val_loss: 8.2709 - val_mae: 1.9970 - val_mse: 8.2709\n",
            "Epoch 705/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.9087 - mae: 1.0769 - mse: 2.9087 - val_loss: 8.5598 - val_mae: 2.0618 - val_mse: 8.5598\n",
            "Epoch 706/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.2191 - mae: 1.1437 - mse: 3.2191 - val_loss: 8.1735 - val_mae: 2.0128 - val_mse: 8.1735\n",
            "Epoch 707/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.9439 - mae: 1.0727 - mse: 2.9439 - val_loss: 7.9525 - val_mae: 1.9602 - val_mse: 7.9525\n",
            "Epoch 708/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.0431 - mae: 1.1334 - mse: 3.0431 - val_loss: 8.8667 - val_mae: 2.1061 - val_mse: 8.8667\n",
            "Epoch 709/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.8588 - mae: 1.1021 - mse: 2.8588 - val_loss: 8.4375 - val_mae: 2.0679 - val_mse: 8.4375\n",
            "Epoch 710/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.1164 - mae: 1.1311 - mse: 3.1164 - val_loss: 8.2229 - val_mae: 2.0116 - val_mse: 8.2229\n",
            "Epoch 711/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.8775 - mae: 1.1108 - mse: 2.8775 - val_loss: 7.9875 - val_mae: 1.9692 - val_mse: 7.9875\n",
            "Epoch 712/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.8260 - mae: 1.0844 - mse: 2.8260 - val_loss: 9.3101 - val_mae: 2.1466 - val_mse: 9.3101\n",
            "Epoch 713/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.2075 - mae: 1.1470 - mse: 3.2075 - val_loss: 8.5963 - val_mae: 2.0654 - val_mse: 8.5963\n",
            "Epoch 714/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.9745 - mae: 1.1107 - mse: 2.9745 - val_loss: 8.0730 - val_mae: 1.9836 - val_mse: 8.0730\n",
            "Epoch 715/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.9577 - mae: 1.0853 - mse: 2.9577 - val_loss: 8.3455 - val_mae: 2.0306 - val_mse: 8.3455\n",
            "Epoch 716/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.9165 - mae: 1.0749 - mse: 2.9165 - val_loss: 9.4688 - val_mae: 2.2178 - val_mse: 9.4688\n",
            "Epoch 717/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.0012 - mae: 1.1472 - mse: 3.0012 - val_loss: 7.9861 - val_mae: 1.9405 - val_mse: 7.9861\n",
            "Epoch 718/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.1427 - mae: 1.1588 - mse: 3.1427 - val_loss: 8.1153 - val_mae: 1.9832 - val_mse: 8.1153\n",
            "Epoch 719/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.9003 - mae: 1.0709 - mse: 2.9003 - val_loss: 8.5428 - val_mae: 2.0369 - val_mse: 8.5428\n",
            "Epoch 720/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.9168 - mae: 1.1262 - mse: 2.9168 - val_loss: 8.2155 - val_mae: 2.0153 - val_mse: 8.2155\n",
            "Epoch 721/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.0021 - mae: 1.1220 - mse: 3.0021 - val_loss: 7.9851 - val_mae: 1.9784 - val_mse: 7.9851\n",
            "Epoch 722/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.9143 - mae: 1.0720 - mse: 2.9143 - val_loss: 8.2172 - val_mae: 2.0244 - val_mse: 8.2172\n",
            "Epoch 723/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.9212 - mae: 1.0964 - mse: 2.9212 - val_loss: 8.8419 - val_mae: 2.1255 - val_mse: 8.8419\n",
            "Epoch 724/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.9176 - mae: 1.1086 - mse: 2.9176 - val_loss: 7.9377 - val_mae: 1.9416 - val_mse: 7.9377\n",
            "Epoch 725/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.0563 - mae: 1.1326 - mse: 3.0563 - val_loss: 8.4128 - val_mae: 2.0367 - val_mse: 8.4128\n",
            "Epoch 726/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.9939 - mae: 1.1137 - mse: 2.9939 - val_loss: 9.0900 - val_mae: 2.1372 - val_mse: 9.0900\n",
            "Epoch 727/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.0907 - mae: 1.1423 - mse: 3.0907 - val_loss: 8.8123 - val_mae: 2.0928 - val_mse: 8.8123\n",
            "Epoch 728/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.0085 - mae: 1.0810 - mse: 3.0085 - val_loss: 8.6189 - val_mae: 2.0607 - val_mse: 8.6189\n",
            "Epoch 729/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.9410 - mae: 1.0970 - mse: 2.9410 - val_loss: 8.2566 - val_mae: 2.0029 - val_mse: 8.2566\n",
            "Epoch 730/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.8634 - mae: 1.0761 - mse: 2.8634 - val_loss: 8.3342 - val_mae: 2.0065 - val_mse: 8.3342\n",
            "Epoch 731/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.8946 - mae: 1.0890 - mse: 2.8946 - val_loss: 8.2744 - val_mae: 2.0117 - val_mse: 8.2744\n",
            "Epoch 732/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.8935 - mae: 1.1224 - mse: 2.8935 - val_loss: 8.3310 - val_mae: 1.9793 - val_mse: 8.3310\n",
            "Epoch 733/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.2953 - mae: 1.1555 - mse: 3.2953 - val_loss: 8.1940 - val_mae: 1.9699 - val_mse: 8.1940\n",
            "Epoch 734/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.8815 - mae: 1.0828 - mse: 2.8815 - val_loss: 8.2100 - val_mae: 2.0322 - val_mse: 8.2100\n",
            "Epoch 735/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.7956 - mae: 1.1058 - mse: 2.7956 - val_loss: 8.4289 - val_mae: 2.0040 - val_mse: 8.4289\n",
            "Epoch 736/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.0282 - mae: 1.1201 - mse: 3.0282 - val_loss: 8.3281 - val_mae: 2.0043 - val_mse: 8.3281\n",
            "Epoch 737/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.8441 - mae: 1.0597 - mse: 2.8441 - val_loss: 8.2136 - val_mae: 2.0195 - val_mse: 8.2136\n",
            "Epoch 738/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.0512 - mae: 1.1049 - mse: 3.0512 - val_loss: 8.1158 - val_mae: 1.9657 - val_mse: 8.1158\n",
            "Epoch 739/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.9559 - mae: 1.1217 - mse: 2.9559 - val_loss: 8.5009 - val_mae: 2.0389 - val_mse: 8.5009\n",
            "Epoch 740/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.9497 - mae: 1.0832 - mse: 2.9497 - val_loss: 8.6461 - val_mae: 2.0401 - val_mse: 8.6461\n",
            "Epoch 741/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.9876 - mae: 1.0824 - mse: 2.9876 - val_loss: 9.3766 - val_mae: 2.1818 - val_mse: 9.3766\n",
            "Epoch 742/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.0127 - mae: 1.1349 - mse: 3.0127 - val_loss: 8.2485 - val_mae: 1.9968 - val_mse: 8.2485\n",
            "Epoch 743/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.7957 - mae: 1.0569 - mse: 2.7957 - val_loss: 7.9930 - val_mae: 1.9621 - val_mse: 7.9930\n",
            "Epoch 744/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.7699 - mae: 1.0342 - mse: 2.7699 - val_loss: 8.0455 - val_mae: 1.9700 - val_mse: 8.0455\n",
            "Epoch 745/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.9094 - mae: 1.1126 - mse: 2.9094 - val_loss: 8.9344 - val_mae: 2.1049 - val_mse: 8.9344\n",
            "Epoch 746/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.9587 - mae: 1.1049 - mse: 2.9587 - val_loss: 8.6796 - val_mae: 2.0730 - val_mse: 8.6796\n",
            "Epoch 747/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.8149 - mae: 1.0766 - mse: 2.8149 - val_loss: 8.0001 - val_mae: 1.9508 - val_mse: 8.0001\n",
            "Epoch 748/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.8068 - mae: 1.0431 - mse: 2.8068 - val_loss: 8.2660 - val_mae: 2.0124 - val_mse: 8.2660\n",
            "Epoch 749/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.9422 - mae: 1.1120 - mse: 2.9422 - val_loss: 8.2052 - val_mae: 1.9876 - val_mse: 8.2052\n",
            "Epoch 750/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.9740 - mae: 1.0831 - mse: 2.9740 - val_loss: 8.4356 - val_mae: 2.0105 - val_mse: 8.4356\n",
            "Epoch 751/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.8085 - mae: 1.0744 - mse: 2.8085 - val_loss: 9.1164 - val_mae: 2.1559 - val_mse: 9.1164\n",
            "Epoch 752/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.9695 - mae: 1.1054 - mse: 2.9695 - val_loss: 8.0205 - val_mae: 1.9835 - val_mse: 8.0205\n",
            "Epoch 753/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.8306 - mae: 1.0766 - mse: 2.8306 - val_loss: 8.5917 - val_mae: 2.0576 - val_mse: 8.5917\n",
            "Epoch 754/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.9748 - mae: 1.0960 - mse: 2.9748 - val_loss: 8.4471 - val_mae: 2.0358 - val_mse: 8.4471\n",
            "Epoch 755/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.8566 - mae: 1.0670 - mse: 2.8566 - val_loss: 8.7594 - val_mae: 2.0623 - val_mse: 8.7594\n",
            "Epoch 756/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.0076 - mae: 1.0910 - mse: 3.0076 - val_loss: 8.2249 - val_mae: 1.9769 - val_mse: 8.2249\n",
            "Epoch 757/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.8044 - mae: 1.0709 - mse: 2.8044 - val_loss: 8.2918 - val_mae: 2.0386 - val_mse: 8.2918\n",
            "Epoch 758/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.1106 - mae: 1.1331 - mse: 3.1106 - val_loss: 8.3580 - val_mae: 2.0215 - val_mse: 8.3580\n",
            "Epoch 759/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.9184 - mae: 1.0595 - mse: 2.9184 - val_loss: 9.1257 - val_mae: 2.1477 - val_mse: 9.1257\n",
            "Epoch 760/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.8672 - mae: 1.0675 - mse: 2.8672 - val_loss: 8.2288 - val_mae: 1.9898 - val_mse: 8.2288\n",
            "Epoch 761/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.0401 - mae: 1.0904 - mse: 3.0401 - val_loss: 8.5457 - val_mae: 2.0454 - val_mse: 8.5457\n",
            "Epoch 762/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.8535 - mae: 1.0616 - mse: 2.8535 - val_loss: 8.5660 - val_mae: 2.0316 - val_mse: 8.5660\n",
            "Epoch 763/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.8195 - mae: 1.0595 - mse: 2.8195 - val_loss: 8.2264 - val_mae: 1.9984 - val_mse: 8.2264\n",
            "Epoch 764/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.7710 - mae: 1.0400 - mse: 2.7710 - val_loss: 8.8092 - val_mae: 2.0938 - val_mse: 8.8092\n",
            "Epoch 765/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.9062 - mae: 1.0951 - mse: 2.9062 - val_loss: 8.7323 - val_mae: 2.0963 - val_mse: 8.7323\n",
            "Epoch 766/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.9215 - mae: 1.1087 - mse: 2.9215 - val_loss: 8.7984 - val_mae: 2.1189 - val_mse: 8.7984\n",
            "Epoch 767/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.8155 - mae: 1.0762 - mse: 2.8155 - val_loss: 8.7796 - val_mae: 2.1045 - val_mse: 8.7796\n",
            "Epoch 768/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.8207 - mae: 1.0714 - mse: 2.8207 - val_loss: 8.2093 - val_mae: 2.0236 - val_mse: 8.2093\n",
            "Epoch 769/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.8829 - mae: 1.1075 - mse: 2.8829 - val_loss: 8.7667 - val_mae: 2.0813 - val_mse: 8.7667\n",
            "Epoch 770/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.7094 - mae: 1.0724 - mse: 2.7094 - val_loss: 8.4388 - val_mae: 2.0761 - val_mse: 8.4388\n",
            "Epoch 771/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.8141 - mae: 1.0535 - mse: 2.8141 - val_loss: 9.4734 - val_mae: 2.1993 - val_mse: 9.4734\n",
            "Epoch 772/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.8756 - mae: 1.0460 - mse: 2.8756 - val_loss: 9.6564 - val_mae: 2.2450 - val_mse: 9.6564\n",
            "Epoch 773/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.9407 - mae: 1.0979 - mse: 2.9407 - val_loss: 9.1539 - val_mae: 2.1586 - val_mse: 9.1539\n",
            "Epoch 774/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.8145 - mae: 1.0493 - mse: 2.8145 - val_loss: 8.1689 - val_mae: 1.9851 - val_mse: 8.1689\n",
            "Epoch 775/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.7402 - mae: 1.0189 - mse: 2.7402 - val_loss: 8.8157 - val_mae: 2.1045 - val_mse: 8.8157\n",
            "Epoch 776/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.8451 - mae: 1.0600 - mse: 2.8451 - val_loss: 8.3720 - val_mae: 2.0154 - val_mse: 8.3720\n",
            "Epoch 777/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.9512 - mae: 1.1238 - mse: 2.9512 - val_loss: 8.2932 - val_mae: 2.0219 - val_mse: 8.2932\n",
            "Epoch 778/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.8570 - mae: 1.0859 - mse: 2.8570 - val_loss: 8.8210 - val_mae: 2.0862 - val_mse: 8.8210\n",
            "Epoch 779/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.9031 - mae: 1.0611 - mse: 2.9031 - val_loss: 8.2262 - val_mae: 2.0131 - val_mse: 8.2262\n",
            "Epoch 780/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.8624 - mae: 1.1027 - mse: 2.8624 - val_loss: 8.1051 - val_mae: 1.9750 - val_mse: 8.1051\n",
            "Epoch 781/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.7999 - mae: 1.0368 - mse: 2.7999 - val_loss: 8.6538 - val_mae: 2.0559 - val_mse: 8.6538\n",
            "Epoch 782/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.7555 - mae: 1.0471 - mse: 2.7555 - val_loss: 9.2969 - val_mae: 2.1815 - val_mse: 9.2969\n",
            "Epoch 783/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.8131 - mae: 1.0707 - mse: 2.8131 - val_loss: 8.4206 - val_mae: 2.0606 - val_mse: 8.4206\n",
            "Epoch 784/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.9869 - mae: 1.1113 - mse: 2.9869 - val_loss: 8.7132 - val_mae: 2.0769 - val_mse: 8.7132\n",
            "Epoch 785/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.7475 - mae: 1.0451 - mse: 2.7475 - val_loss: 8.4637 - val_mae: 2.0526 - val_mse: 8.4637\n",
            "Epoch 786/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.6845 - mae: 1.0433 - mse: 2.6845 - val_loss: 8.8704 - val_mae: 2.1172 - val_mse: 8.8704\n",
            "Epoch 787/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.7565 - mae: 1.0698 - mse: 2.7565 - val_loss: 8.1977 - val_mae: 2.0043 - val_mse: 8.1977\n",
            "Epoch 788/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.8744 - mae: 1.0886 - mse: 2.8744 - val_loss: 8.0267 - val_mae: 1.9767 - val_mse: 8.0267\n",
            "Epoch 789/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.7569 - mae: 1.0571 - mse: 2.7569 - val_loss: 8.8604 - val_mae: 2.1305 - val_mse: 8.8604\n",
            "Epoch 790/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.8217 - mae: 1.0719 - mse: 2.8217 - val_loss: 8.3414 - val_mae: 2.0317 - val_mse: 8.3414\n",
            "Epoch 791/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.7467 - mae: 1.0303 - mse: 2.7467 - val_loss: 8.5031 - val_mae: 2.0435 - val_mse: 8.5031\n",
            "Epoch 792/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.9778 - mae: 1.1157 - mse: 2.9778 - val_loss: 8.2087 - val_mae: 1.9975 - val_mse: 8.2087\n",
            "Epoch 793/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.7604 - mae: 1.0352 - mse: 2.7604 - val_loss: 8.3336 - val_mae: 2.0572 - val_mse: 8.3336\n",
            "Epoch 794/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.8101 - mae: 1.0568 - mse: 2.8101 - val_loss: 8.4238 - val_mae: 2.0749 - val_mse: 8.4238\n",
            "Epoch 795/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.8278 - mae: 1.0709 - mse: 2.8278 - val_loss: 8.3150 - val_mae: 2.0293 - val_mse: 8.3150\n",
            "Epoch 796/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.7052 - mae: 1.0451 - mse: 2.7052 - val_loss: 8.4309 - val_mae: 2.0225 - val_mse: 8.4309\n",
            "Epoch 797/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.0190 - mae: 1.0933 - mse: 3.0190 - val_loss: 8.3419 - val_mae: 2.0496 - val_mse: 8.3419\n",
            "Epoch 798/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.6574 - mae: 1.0167 - mse: 2.6574 - val_loss: 8.2243 - val_mae: 2.0051 - val_mse: 8.2243\n",
            "Epoch 799/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.8274 - mae: 1.0786 - mse: 2.8274 - val_loss: 8.7198 - val_mae: 2.1180 - val_mse: 8.7198\n",
            "Epoch 800/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.7587 - mae: 1.0442 - mse: 2.7587 - val_loss: 8.3914 - val_mae: 2.0437 - val_mse: 8.3914\n",
            "Epoch 801/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.7976 - mae: 1.0709 - mse: 2.7976 - val_loss: 8.8362 - val_mae: 2.1197 - val_mse: 8.8362\n",
            "Epoch 802/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.6982 - mae: 1.0304 - mse: 2.6982 - val_loss: 9.4715 - val_mae: 2.2000 - val_mse: 9.4715\n",
            "Epoch 803/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.6811 - mae: 1.0940 - mse: 2.6811 - val_loss: 8.4002 - val_mae: 2.0329 - val_mse: 8.4002\n",
            "Epoch 804/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.8021 - mae: 1.0809 - mse: 2.8021 - val_loss: 8.8951 - val_mae: 2.1228 - val_mse: 8.8951\n",
            "Epoch 805/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.7638 - mae: 1.0978 - mse: 2.7638 - val_loss: 8.2447 - val_mae: 2.0227 - val_mse: 8.2447\n",
            "Epoch 806/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.7936 - mae: 1.0255 - mse: 2.7936 - val_loss: 8.3964 - val_mae: 2.0371 - val_mse: 8.3964\n",
            "Epoch 807/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.8011 - mae: 1.0876 - mse: 2.8011 - val_loss: 8.7732 - val_mae: 2.1018 - val_mse: 8.7732\n",
            "Epoch 808/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.8006 - mae: 1.0612 - mse: 2.8006 - val_loss: 8.7824 - val_mae: 2.0955 - val_mse: 8.7824\n",
            "Epoch 809/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.6231 - mae: 1.0268 - mse: 2.6231 - val_loss: 8.4302 - val_mae: 2.0584 - val_mse: 8.4302\n",
            "Epoch 810/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.7313 - mae: 1.0247 - mse: 2.7313 - val_loss: 8.0808 - val_mae: 1.9764 - val_mse: 8.0808\n",
            "Epoch 811/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.6951 - mae: 1.0547 - mse: 2.6951 - val_loss: 8.1005 - val_mae: 2.0026 - val_mse: 8.1005\n",
            "Epoch 812/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.8890 - mae: 1.0916 - mse: 2.8890 - val_loss: 8.6844 - val_mae: 2.0807 - val_mse: 8.6844\n",
            "Epoch 813/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.9450 - mae: 1.0884 - mse: 2.9450 - val_loss: 8.2074 - val_mae: 2.0039 - val_mse: 8.2074\n",
            "Epoch 814/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.6459 - mae: 1.0017 - mse: 2.6459 - val_loss: 8.2697 - val_mae: 2.0127 - val_mse: 8.2697\n",
            "Epoch 815/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.6908 - mae: 1.0510 - mse: 2.6908 - val_loss: 8.3005 - val_mae: 2.0349 - val_mse: 8.3005\n",
            "Epoch 816/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.7494 - mae: 1.0746 - mse: 2.7494 - val_loss: 7.9313 - val_mae: 1.9732 - val_mse: 7.9313\n",
            "Epoch 817/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.7737 - mae: 1.0576 - mse: 2.7737 - val_loss: 8.0315 - val_mae: 1.9712 - val_mse: 8.0315\n",
            "Epoch 818/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.6914 - mae: 1.0149 - mse: 2.6914 - val_loss: 8.5891 - val_mae: 2.1050 - val_mse: 8.5891\n",
            "Epoch 819/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.7930 - mae: 1.0801 - mse: 2.7930 - val_loss: 8.1815 - val_mae: 1.9903 - val_mse: 8.1815\n",
            "Epoch 820/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.6347 - mae: 1.0365 - mse: 2.6347 - val_loss: 7.9158 - val_mae: 1.9757 - val_mse: 7.9158\n",
            "Epoch 821/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.8120 - mae: 1.0730 - mse: 2.8120 - val_loss: 8.4489 - val_mae: 2.0459 - val_mse: 8.4489\n",
            "Epoch 822/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.7964 - mae: 1.0716 - mse: 2.7964 - val_loss: 8.7237 - val_mae: 2.0969 - val_mse: 8.7237\n",
            "Epoch 823/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.6307 - mae: 1.0293 - mse: 2.6307 - val_loss: 8.9219 - val_mae: 2.1244 - val_mse: 8.9219\n",
            "Epoch 824/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.8353 - mae: 1.0808 - mse: 2.8353 - val_loss: 8.0837 - val_mae: 1.9946 - val_mse: 8.0837\n",
            "Epoch 825/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.6301 - mae: 1.0199 - mse: 2.6301 - val_loss: 8.8923 - val_mae: 2.1267 - val_mse: 8.8923\n",
            "Epoch 826/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.6612 - mae: 1.0375 - mse: 2.6612 - val_loss: 8.5039 - val_mae: 2.0414 - val_mse: 8.5039\n",
            "Epoch 827/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.8385 - mae: 1.0573 - mse: 2.8385 - val_loss: 8.5685 - val_mae: 2.0702 - val_mse: 8.5685\n",
            "Epoch 828/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.7946 - mae: 1.0370 - mse: 2.7946 - val_loss: 9.1716 - val_mae: 2.1790 - val_mse: 9.1716\n",
            "Epoch 829/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.6770 - mae: 1.0568 - mse: 2.6770 - val_loss: 8.5711 - val_mae: 2.0429 - val_mse: 8.5711\n",
            "Epoch 830/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.8508 - mae: 1.0760 - mse: 2.8508 - val_loss: 8.4437 - val_mae: 2.0392 - val_mse: 8.4437\n",
            "Epoch 831/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.6343 - mae: 1.0231 - mse: 2.6343 - val_loss: 8.9253 - val_mae: 2.1556 - val_mse: 8.9253\n",
            "Epoch 832/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.8036 - mae: 1.1049 - mse: 2.8036 - val_loss: 8.8130 - val_mae: 2.1127 - val_mse: 8.8130\n",
            "Epoch 833/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.7876 - mae: 1.0426 - mse: 2.7876 - val_loss: 8.5684 - val_mae: 2.0777 - val_mse: 8.5684\n",
            "Epoch 834/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.6849 - mae: 1.0304 - mse: 2.6849 - val_loss: 8.5460 - val_mae: 2.0779 - val_mse: 8.5460\n",
            "Epoch 835/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.8184 - mae: 1.0603 - mse: 2.8184 - val_loss: 9.0146 - val_mae: 2.1254 - val_mse: 9.0146\n",
            "Epoch 836/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.7952 - mae: 1.0458 - mse: 2.7952 - val_loss: 8.2117 - val_mae: 2.0186 - val_mse: 8.2117\n",
            "Epoch 837/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.7435 - mae: 1.0235 - mse: 2.7435 - val_loss: 8.2786 - val_mae: 2.0180 - val_mse: 8.2786\n",
            "Epoch 838/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.6922 - mae: 1.0610 - mse: 2.6922 - val_loss: 8.9436 - val_mae: 2.1035 - val_mse: 8.9436\n",
            "Epoch 839/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.8357 - mae: 1.0513 - mse: 2.8357 - val_loss: 8.4063 - val_mae: 2.0319 - val_mse: 8.4063\n",
            "Epoch 840/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.6682 - mae: 1.0256 - mse: 2.6682 - val_loss: 8.4106 - val_mae: 2.0681 - val_mse: 8.4106\n",
            "Epoch 841/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.6482 - mae: 1.0095 - mse: 2.6482 - val_loss: 8.4262 - val_mae: 2.0671 - val_mse: 8.4262\n",
            "Epoch 842/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.6942 - mae: 1.0287 - mse: 2.6942 - val_loss: 8.7509 - val_mae: 2.0785 - val_mse: 8.7509\n",
            "Epoch 843/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.6185 - mae: 1.0015 - mse: 2.6185 - val_loss: 9.4032 - val_mae: 2.1968 - val_mse: 9.4032\n",
            "Epoch 844/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.7844 - mae: 1.0796 - mse: 2.7844 - val_loss: 8.4867 - val_mae: 2.0721 - val_mse: 8.4867\n",
            "Epoch 845/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.5880 - mae: 1.0264 - mse: 2.5880 - val_loss: 9.3116 - val_mae: 2.1654 - val_mse: 9.3116\n",
            "Epoch 846/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.6699 - mae: 1.0491 - mse: 2.6699 - val_loss: 8.2152 - val_mae: 2.0164 - val_mse: 8.2152\n",
            "Epoch 847/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.7734 - mae: 1.0418 - mse: 2.7734 - val_loss: 8.4426 - val_mae: 2.0319 - val_mse: 8.4426\n",
            "Epoch 848/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.7643 - mae: 1.0742 - mse: 2.7643 - val_loss: 8.6548 - val_mae: 2.0784 - val_mse: 8.6548\n",
            "Epoch 849/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.6536 - mae: 1.0485 - mse: 2.6536 - val_loss: 8.5069 - val_mae: 2.0769 - val_mse: 8.5069\n",
            "Epoch 850/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.6059 - mae: 1.0150 - mse: 2.6059 - val_loss: 8.3001 - val_mae: 2.0244 - val_mse: 8.3001\n",
            "Epoch 851/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.6730 - mae: 1.0425 - mse: 2.6730 - val_loss: 9.3720 - val_mae: 2.1761 - val_mse: 9.3720\n",
            "Epoch 852/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.5842 - mae: 1.0147 - mse: 2.5842 - val_loss: 9.0056 - val_mae: 2.1186 - val_mse: 9.0056\n",
            "Epoch 853/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.7342 - mae: 1.0525 - mse: 2.7342 - val_loss: 8.3664 - val_mae: 2.0418 - val_mse: 8.3664\n",
            "Epoch 854/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.7545 - mae: 1.0697 - mse: 2.7545 - val_loss: 8.7293 - val_mae: 2.1088 - val_mse: 8.7293\n",
            "Epoch 855/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.6259 - mae: 1.0018 - mse: 2.6259 - val_loss: 8.2657 - val_mae: 2.0144 - val_mse: 8.2657\n",
            "Epoch 856/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.6624 - mae: 1.0400 - mse: 2.6624 - val_loss: 9.0612 - val_mae: 2.1283 - val_mse: 9.0612\n",
            "Epoch 857/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.6770 - mae: 1.0039 - mse: 2.6770 - val_loss: 8.6913 - val_mae: 2.0650 - val_mse: 8.6913\n",
            "Epoch 858/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.6620 - mae: 0.9846 - mse: 2.6620 - val_loss: 8.3122 - val_mae: 2.0060 - val_mse: 8.3122\n",
            "Epoch 859/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.7332 - mae: 1.0745 - mse: 2.7332 - val_loss: 8.4084 - val_mae: 2.0593 - val_mse: 8.4084\n",
            "Epoch 860/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.7382 - mae: 1.0291 - mse: 2.7382 - val_loss: 8.5898 - val_mae: 2.0835 - val_mse: 8.5898\n",
            "Epoch 861/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.7762 - mae: 1.0341 - mse: 2.7762 - val_loss: 8.2742 - val_mae: 2.0397 - val_mse: 8.2742\n",
            "Epoch 862/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.6091 - mae: 1.0484 - mse: 2.6091 - val_loss: 8.3534 - val_mae: 2.0255 - val_mse: 8.3534\n",
            "Epoch 863/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.6079 - mae: 1.0396 - mse: 2.6079 - val_loss: 8.3272 - val_mae: 2.0442 - val_mse: 8.3272\n",
            "Epoch 864/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.8027 - mae: 1.0738 - mse: 2.8027 - val_loss: 8.6912 - val_mae: 2.1119 - val_mse: 8.6912\n",
            "Epoch 865/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.6249 - mae: 1.0311 - mse: 2.6249 - val_loss: 8.5222 - val_mae: 2.0728 - val_mse: 8.5222\n",
            "Epoch 866/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.4920 - mae: 0.9912 - mse: 2.4920 - val_loss: 8.5895 - val_mae: 2.0714 - val_mse: 8.5895\n",
            "Epoch 867/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.7544 - mae: 1.0817 - mse: 2.7544 - val_loss: 8.5835 - val_mae: 2.0635 - val_mse: 8.5835\n",
            "Epoch 868/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.7256 - mae: 1.0268 - mse: 2.7256 - val_loss: 9.3179 - val_mae: 2.1948 - val_mse: 9.3179\n",
            "Epoch 869/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.5869 - mae: 1.0059 - mse: 2.5869 - val_loss: 9.0310 - val_mae: 2.1518 - val_mse: 9.0310\n",
            "Epoch 870/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.5597 - mae: 1.0510 - mse: 2.5597 - val_loss: 8.3642 - val_mae: 2.0703 - val_mse: 8.3642\n",
            "Epoch 871/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.7239 - mae: 1.0081 - mse: 2.7239 - val_loss: 8.4837 - val_mae: 2.0524 - val_mse: 8.4837\n",
            "Epoch 872/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.6064 - mae: 1.0062 - mse: 2.6064 - val_loss: 8.1525 - val_mae: 1.9943 - val_mse: 8.1525\n",
            "Epoch 873/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.8007 - mae: 1.0527 - mse: 2.8007 - val_loss: 8.3857 - val_mae: 2.0383 - val_mse: 8.3857\n",
            "Epoch 874/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.5184 - mae: 1.0113 - mse: 2.5184 - val_loss: 8.2798 - val_mae: 2.0314 - val_mse: 8.2798\n",
            "Epoch 875/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2.6336 - mae: 1.0416 - mse: 2.6336 - val_loss: 8.2257 - val_mae: 1.9948 - val_mse: 8.2257\n",
            "Epoch 876/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.6794 - mae: 1.0371 - mse: 2.6794 - val_loss: 9.3224 - val_mae: 2.1730 - val_mse: 9.3224\n",
            "Epoch 877/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.6851 - mae: 1.0073 - mse: 2.6851 - val_loss: 9.1561 - val_mae: 2.1653 - val_mse: 9.1561\n",
            "Epoch 878/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.6761 - mae: 1.0255 - mse: 2.6761 - val_loss: 8.1658 - val_mae: 1.9984 - val_mse: 8.1658\n",
            "Epoch 879/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.6409 - mae: 1.0406 - mse: 2.6409 - val_loss: 8.1124 - val_mae: 1.9975 - val_mse: 8.1124\n",
            "Epoch 880/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.5647 - mae: 0.9993 - mse: 2.5647 - val_loss: 8.9592 - val_mae: 2.1689 - val_mse: 8.9592\n",
            "Epoch 881/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.6165 - mae: 1.0201 - mse: 2.6165 - val_loss: 8.9237 - val_mae: 2.1176 - val_mse: 8.9237\n",
            "Epoch 882/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.7903 - mae: 1.0520 - mse: 2.7903 - val_loss: 8.2642 - val_mae: 2.0192 - val_mse: 8.2642\n",
            "Epoch 883/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.6105 - mae: 1.0503 - mse: 2.6105 - val_loss: 8.3921 - val_mae: 2.0286 - val_mse: 8.3921\n",
            "Epoch 884/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.7380 - mae: 1.0291 - mse: 2.7380 - val_loss: 8.8705 - val_mae: 2.0988 - val_mse: 8.8705\n",
            "Epoch 885/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.5663 - mae: 0.9860 - mse: 2.5663 - val_loss: 8.4029 - val_mae: 2.0456 - val_mse: 8.4029\n",
            "Epoch 886/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.5309 - mae: 1.0070 - mse: 2.5309 - val_loss: 9.1655 - val_mae: 2.1943 - val_mse: 9.1655\n",
            "Epoch 887/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.6757 - mae: 1.0539 - mse: 2.6757 - val_loss: 8.6590 - val_mae: 2.0867 - val_mse: 8.6590\n",
            "Epoch 888/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.6721 - mae: 1.0464 - mse: 2.6721 - val_loss: 8.1400 - val_mae: 2.0286 - val_mse: 8.1400\n",
            "Epoch 889/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.6080 - mae: 1.0362 - mse: 2.6080 - val_loss: 8.2179 - val_mae: 2.0150 - val_mse: 8.2179\n",
            "Epoch 890/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.5328 - mae: 0.9705 - mse: 2.5328 - val_loss: 9.1574 - val_mae: 2.1347 - val_mse: 9.1574\n",
            "Epoch 891/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.6826 - mae: 1.0224 - mse: 2.6826 - val_loss: 8.6303 - val_mae: 2.0593 - val_mse: 8.6303\n",
            "Epoch 892/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.5139 - mae: 1.0021 - mse: 2.5139 - val_loss: 8.6590 - val_mae: 2.0444 - val_mse: 8.6590\n",
            "Epoch 893/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.7106 - mae: 1.0511 - mse: 2.7106 - val_loss: 8.6975 - val_mae: 2.0980 - val_mse: 8.6975\n",
            "Epoch 894/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.6133 - mae: 1.0038 - mse: 2.6133 - val_loss: 10.0087 - val_mae: 2.3247 - val_mse: 10.0087\n",
            "Epoch 895/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.5934 - mae: 1.0245 - mse: 2.5934 - val_loss: 8.4291 - val_mae: 2.0434 - val_mse: 8.4291\n",
            "Epoch 896/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.7920 - mae: 1.0582 - mse: 2.7920 - val_loss: 8.4166 - val_mae: 2.0394 - val_mse: 8.4166\n",
            "Epoch 897/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.5677 - mae: 1.0183 - mse: 2.5677 - val_loss: 8.5821 - val_mae: 2.0781 - val_mse: 8.5821\n",
            "Epoch 898/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.4524 - mae: 0.9745 - mse: 2.4524 - val_loss: 8.1041 - val_mae: 2.0151 - val_mse: 8.1041\n",
            "Epoch 899/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.5561 - mae: 1.0234 - mse: 2.5561 - val_loss: 8.3419 - val_mae: 2.0200 - val_mse: 8.3419\n",
            "Epoch 900/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.5794 - mae: 1.0267 - mse: 2.5794 - val_loss: 8.0636 - val_mae: 2.0138 - val_mse: 8.0636\n",
            "Epoch 901/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.4233 - mae: 0.9579 - mse: 2.4233 - val_loss: 9.5646 - val_mae: 2.2169 - val_mse: 9.5646\n",
            "Epoch 902/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.5722 - mae: 1.0400 - mse: 2.5722 - val_loss: 8.4473 - val_mae: 2.0296 - val_mse: 8.4473\n",
            "Epoch 903/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.6892 - mae: 1.0418 - mse: 2.6892 - val_loss: 8.7965 - val_mae: 2.0985 - val_mse: 8.7965\n",
            "Epoch 904/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.7275 - mae: 1.0446 - mse: 2.7275 - val_loss: 8.3904 - val_mae: 2.0653 - val_mse: 8.3904\n",
            "Epoch 905/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.5493 - mae: 0.9933 - mse: 2.5493 - val_loss: 8.3820 - val_mae: 2.0714 - val_mse: 8.3820\n",
            "Epoch 906/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.5613 - mae: 1.0060 - mse: 2.5613 - val_loss: 8.6056 - val_mae: 2.0906 - val_mse: 8.6056\n",
            "Epoch 907/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.3900 - mae: 0.9699 - mse: 2.3900 - val_loss: 9.8748 - val_mae: 2.2511 - val_mse: 9.8748\n",
            "Epoch 908/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.6252 - mae: 1.0179 - mse: 2.6252 - val_loss: 9.8972 - val_mae: 2.2675 - val_mse: 9.8972\n",
            "Epoch 909/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.6538 - mae: 1.0536 - mse: 2.6538 - val_loss: 8.5289 - val_mae: 2.0486 - val_mse: 8.5289\n",
            "Epoch 910/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.6545 - mae: 1.0638 - mse: 2.6545 - val_loss: 8.7324 - val_mae: 2.0961 - val_mse: 8.7324\n",
            "Epoch 911/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.5344 - mae: 0.9947 - mse: 2.5344 - val_loss: 8.3815 - val_mae: 2.0372 - val_mse: 8.3815\n",
            "Epoch 912/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.4942 - mae: 0.9926 - mse: 2.4942 - val_loss: 8.9790 - val_mae: 2.1601 - val_mse: 8.9790\n",
            "Epoch 913/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.5735 - mae: 0.9897 - mse: 2.5735 - val_loss: 8.7037 - val_mae: 2.0992 - val_mse: 8.7037\n",
            "Epoch 914/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.5842 - mae: 0.9787 - mse: 2.5842 - val_loss: 8.7294 - val_mae: 2.0957 - val_mse: 8.7294\n",
            "Epoch 915/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.5641 - mae: 1.0151 - mse: 2.5641 - val_loss: 9.1561 - val_mae: 2.1628 - val_mse: 9.1561\n",
            "Epoch 916/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.5828 - mae: 1.0499 - mse: 2.5828 - val_loss: 8.0666 - val_mae: 2.0012 - val_mse: 8.0666\n",
            "Epoch 917/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.5455 - mae: 1.0192 - mse: 2.5455 - val_loss: 8.5003 - val_mae: 2.0831 - val_mse: 8.5003\n",
            "Epoch 918/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.6179 - mae: 1.0341 - mse: 2.6179 - val_loss: 8.6571 - val_mae: 2.0996 - val_mse: 8.6571\n",
            "Epoch 919/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.7300 - mae: 1.0337 - mse: 2.7300 - val_loss: 8.0943 - val_mae: 2.0072 - val_mse: 8.0943\n",
            "Epoch 920/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.6007 - mae: 0.9925 - mse: 2.6007 - val_loss: 8.3580 - val_mae: 2.0561 - val_mse: 8.3580\n",
            "Epoch 921/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.4629 - mae: 0.9688 - mse: 2.4629 - val_loss: 8.3189 - val_mae: 2.0472 - val_mse: 8.3189\n",
            "Epoch 922/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.5216 - mae: 0.9989 - mse: 2.5216 - val_loss: 8.9070 - val_mae: 2.1142 - val_mse: 8.9070\n",
            "Epoch 923/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.5004 - mae: 1.0223 - mse: 2.5004 - val_loss: 8.0053 - val_mae: 1.9948 - val_mse: 8.0053\n",
            "Epoch 924/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.4669 - mae: 1.0034 - mse: 2.4669 - val_loss: 8.5181 - val_mae: 2.0828 - val_mse: 8.5181\n",
            "Epoch 925/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.3262 - mae: 0.9790 - mse: 2.3262 - val_loss: 8.8414 - val_mae: 2.1450 - val_mse: 8.8414\n",
            "Epoch 926/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.6663 - mae: 1.0463 - mse: 2.6663 - val_loss: 8.3128 - val_mae: 2.0241 - val_mse: 8.3128\n",
            "Epoch 927/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.5071 - mae: 1.0034 - mse: 2.5071 - val_loss: 9.3435 - val_mae: 2.2072 - val_mse: 9.3435\n",
            "Epoch 928/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.4826 - mae: 1.0046 - mse: 2.4826 - val_loss: 9.7134 - val_mae: 2.2618 - val_mse: 9.7134\n",
            "Epoch 929/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.5502 - mae: 1.0148 - mse: 2.5502 - val_loss: 8.4411 - val_mae: 2.0823 - val_mse: 8.4411\n",
            "Epoch 930/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.5087 - mae: 0.9896 - mse: 2.5087 - val_loss: 8.9871 - val_mae: 2.1344 - val_mse: 8.9871\n",
            "Epoch 931/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.5004 - mae: 0.9967 - mse: 2.5004 - val_loss: 8.5517 - val_mae: 2.0958 - val_mse: 8.5517\n",
            "Epoch 932/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.7689 - mae: 1.0258 - mse: 2.7689 - val_loss: 8.9893 - val_mae: 2.1378 - val_mse: 8.9893\n",
            "Epoch 933/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.4932 - mae: 0.9839 - mse: 2.4932 - val_loss: 8.3120 - val_mae: 2.0478 - val_mse: 8.3120\n",
            "Epoch 934/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.4669 - mae: 0.9794 - mse: 2.4669 - val_loss: 9.8233 - val_mae: 2.2481 - val_mse: 9.8233\n",
            "Epoch 935/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.4594 - mae: 1.0675 - mse: 2.4594 - val_loss: 8.4232 - val_mae: 2.0490 - val_mse: 8.4232\n",
            "Epoch 936/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.6826 - mae: 1.0411 - mse: 2.6826 - val_loss: 8.6074 - val_mae: 2.0851 - val_mse: 8.6074\n",
            "Epoch 937/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.4744 - mae: 0.9989 - mse: 2.4744 - val_loss: 9.0316 - val_mae: 2.1396 - val_mse: 9.0316\n",
            "Epoch 938/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.5450 - mae: 1.0236 - mse: 2.5450 - val_loss: 9.2864 - val_mae: 2.1598 - val_mse: 9.2864\n",
            "Epoch 939/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.6151 - mae: 1.0418 - mse: 2.6151 - val_loss: 8.6789 - val_mae: 2.0551 - val_mse: 8.6789\n",
            "Epoch 940/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.5477 - mae: 0.9986 - mse: 2.5477 - val_loss: 10.1785 - val_mae: 2.2946 - val_mse: 10.1785\n",
            "Epoch 941/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.5108 - mae: 0.9961 - mse: 2.5108 - val_loss: 9.4525 - val_mae: 2.2199 - val_mse: 9.4525\n",
            "Epoch 942/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.5762 - mae: 1.0063 - mse: 2.5762 - val_loss: 8.7733 - val_mae: 2.1082 - val_mse: 8.7733\n",
            "Epoch 943/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.3599 - mae: 0.9510 - mse: 2.3599 - val_loss: 8.4872 - val_mae: 2.0760 - val_mse: 8.4872\n",
            "Epoch 944/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.5627 - mae: 1.0140 - mse: 2.5627 - val_loss: 9.3967 - val_mae: 2.1960 - val_mse: 9.3967\n",
            "Epoch 945/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.6085 - mae: 1.0336 - mse: 2.6085 - val_loss: 8.5453 - val_mae: 2.0392 - val_mse: 8.5453\n",
            "Epoch 946/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.3217 - mae: 0.9395 - mse: 2.3217 - val_loss: 8.8549 - val_mae: 2.1233 - val_mse: 8.8549\n",
            "Epoch 947/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.5238 - mae: 1.0006 - mse: 2.5238 - val_loss: 9.3795 - val_mae: 2.1864 - val_mse: 9.3795\n",
            "Epoch 948/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.4905 - mae: 0.9977 - mse: 2.4905 - val_loss: 9.1794 - val_mae: 2.1775 - val_mse: 9.1794\n",
            "Epoch 949/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.6210 - mae: 1.0867 - mse: 2.6210 - val_loss: 8.5572 - val_mae: 2.0724 - val_mse: 8.5572\n",
            "Epoch 950/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.5394 - mae: 1.0032 - mse: 2.5394 - val_loss: 9.4191 - val_mae: 2.2035 - val_mse: 9.4191\n",
            "Epoch 951/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.5227 - mae: 0.9900 - mse: 2.5227 - val_loss: 8.2235 - val_mae: 2.0069 - val_mse: 8.2235\n",
            "Epoch 952/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.5112 - mae: 1.0158 - mse: 2.5112 - val_loss: 8.7682 - val_mae: 2.0965 - val_mse: 8.7682\n",
            "Epoch 953/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.3711 - mae: 0.9653 - mse: 2.3711 - val_loss: 8.3596 - val_mae: 2.0359 - val_mse: 8.3596\n",
            "Epoch 954/1000\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 2.5640 - mae: 0.9745 - mse: 2.5640 - val_loss: 8.6869 - val_mae: 2.0996 - val_mse: 8.6869\n",
            "Epoch 955/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.4231 - mae: 1.0085 - mse: 2.4231 - val_loss: 9.0681 - val_mae: 2.1829 - val_mse: 9.0681\n",
            "Epoch 956/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.4764 - mae: 0.9831 - mse: 2.4764 - val_loss: 8.8408 - val_mae: 2.0876 - val_mse: 8.8408\n",
            "Epoch 957/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.3771 - mae: 0.9548 - mse: 2.3771 - val_loss: 9.1808 - val_mae: 2.1536 - val_mse: 9.1808\n",
            "Epoch 958/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.6137 - mae: 1.0319 - mse: 2.6137 - val_loss: 8.9665 - val_mae: 2.1633 - val_mse: 8.9665\n",
            "Epoch 959/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.4107 - mae: 0.9910 - mse: 2.4107 - val_loss: 8.8824 - val_mae: 2.1245 - val_mse: 8.8824\n",
            "Epoch 960/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.4588 - mae: 1.0339 - mse: 2.4588 - val_loss: 8.7292 - val_mae: 2.1033 - val_mse: 8.7292\n",
            "Epoch 961/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.4071 - mae: 0.9568 - mse: 2.4071 - val_loss: 8.5405 - val_mae: 2.0424 - val_mse: 8.5405\n",
            "Epoch 962/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.4311 - mae: 1.0198 - mse: 2.4311 - val_loss: 8.8985 - val_mae: 2.1135 - val_mse: 8.8985\n",
            "Epoch 963/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.6276 - mae: 1.0130 - mse: 2.6276 - val_loss: 8.6741 - val_mae: 2.0836 - val_mse: 8.6741\n",
            "Epoch 964/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.3458 - mae: 0.9429 - mse: 2.3458 - val_loss: 8.6658 - val_mae: 2.1169 - val_mse: 8.6658\n",
            "Epoch 965/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.5268 - mae: 1.0011 - mse: 2.5268 - val_loss: 8.4169 - val_mae: 2.0649 - val_mse: 8.4169\n",
            "Epoch 966/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.5494 - mae: 1.0256 - mse: 2.5494 - val_loss: 9.0851 - val_mae: 2.1801 - val_mse: 9.0851\n",
            "Epoch 967/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.5841 - mae: 0.9948 - mse: 2.5841 - val_loss: 8.6953 - val_mae: 2.1109 - val_mse: 8.6953\n",
            "Epoch 968/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.4018 - mae: 0.9814 - mse: 2.4018 - val_loss: 8.6331 - val_mae: 2.0824 - val_mse: 8.6331\n",
            "Epoch 969/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.3674 - mae: 0.9626 - mse: 2.3674 - val_loss: 8.8003 - val_mae: 2.0763 - val_mse: 8.8003\n",
            "Epoch 970/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.7003 - mae: 1.0338 - mse: 2.7003 - val_loss: 8.3921 - val_mae: 2.0642 - val_mse: 8.3921\n",
            "Epoch 971/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.5824 - mae: 1.0457 - mse: 2.5824 - val_loss: 8.7097 - val_mae: 2.0828 - val_mse: 8.7097\n",
            "Epoch 972/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.3849 - mae: 0.9655 - mse: 2.3849 - val_loss: 8.5129 - val_mae: 2.0706 - val_mse: 8.5129\n",
            "Epoch 973/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.4420 - mae: 0.9661 - mse: 2.4420 - val_loss: 8.5421 - val_mae: 2.0710 - val_mse: 8.5421\n",
            "Epoch 974/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.3763 - mae: 0.9622 - mse: 2.3763 - val_loss: 8.2219 - val_mae: 2.0513 - val_mse: 8.2219\n",
            "Epoch 975/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.3977 - mae: 0.9854 - mse: 2.3977 - val_loss: 8.2830 - val_mae: 2.0474 - val_mse: 8.2830\n",
            "Epoch 976/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.4232 - mae: 0.9709 - mse: 2.4232 - val_loss: 8.6002 - val_mae: 2.1038 - val_mse: 8.6002\n",
            "Epoch 977/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.5410 - mae: 1.0422 - mse: 2.5410 - val_loss: 8.6860 - val_mae: 2.1264 - val_mse: 8.6860\n",
            "Epoch 978/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.3984 - mae: 0.9836 - mse: 2.3984 - val_loss: 8.7376 - val_mae: 2.0972 - val_mse: 8.7376\n",
            "Epoch 979/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.6058 - mae: 1.0129 - mse: 2.6058 - val_loss: 8.6084 - val_mae: 2.0864 - val_mse: 8.6084\n",
            "Epoch 980/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.3568 - mae: 0.9502 - mse: 2.3568 - val_loss: 8.7393 - val_mae: 2.1318 - val_mse: 8.7393\n",
            "Epoch 981/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.4989 - mae: 1.0108 - mse: 2.4989 - val_loss: 9.2272 - val_mae: 2.1969 - val_mse: 9.2272\n",
            "Epoch 982/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.3183 - mae: 0.9699 - mse: 2.3183 - val_loss: 9.0567 - val_mae: 2.1521 - val_mse: 9.0567\n",
            "Epoch 983/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.4050 - mae: 0.9563 - mse: 2.4050 - val_loss: 8.3686 - val_mae: 2.0676 - val_mse: 8.3686\n",
            "Epoch 984/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.3503 - mae: 0.9671 - mse: 2.3503 - val_loss: 9.7322 - val_mae: 2.2435 - val_mse: 9.7322\n",
            "Epoch 985/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.5416 - mae: 1.0167 - mse: 2.5416 - val_loss: 8.5807 - val_mae: 2.1032 - val_mse: 8.5807\n",
            "Epoch 986/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.3795 - mae: 0.9549 - mse: 2.3795 - val_loss: 9.1704 - val_mae: 2.1254 - val_mse: 9.1704\n",
            "Epoch 987/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.4793 - mae: 1.0022 - mse: 2.4793 - val_loss: 8.8851 - val_mae: 2.1081 - val_mse: 8.8851\n",
            "Epoch 988/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.2836 - mae: 0.9740 - mse: 2.2836 - val_loss: 9.5371 - val_mae: 2.2213 - val_mse: 9.5371\n",
            "Epoch 989/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.2937 - mae: 0.9659 - mse: 2.2937 - val_loss: 8.6506 - val_mae: 2.0806 - val_mse: 8.6506\n",
            "Epoch 990/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.5237 - mae: 0.9950 - mse: 2.5237 - val_loss: 8.6241 - val_mae: 2.1124 - val_mse: 8.6241\n",
            "Epoch 991/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.4283 - mae: 0.9495 - mse: 2.4283 - val_loss: 8.1570 - val_mae: 2.0282 - val_mse: 8.1570\n",
            "Epoch 992/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.3459 - mae: 0.9476 - mse: 2.3459 - val_loss: 8.4221 - val_mae: 2.0765 - val_mse: 8.4221\n",
            "Epoch 993/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.2763 - mae: 0.9530 - mse: 2.2763 - val_loss: 9.7140 - val_mae: 2.2553 - val_mse: 9.7140\n",
            "Epoch 994/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.7453 - mae: 1.0292 - mse: 2.7453 - val_loss: 8.3894 - val_mae: 2.0646 - val_mse: 8.3894\n",
            "Epoch 995/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.3988 - mae: 0.9854 - mse: 2.3988 - val_loss: 8.5021 - val_mae: 2.0660 - val_mse: 8.5021\n",
            "Epoch 996/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.2990 - mae: 0.9348 - mse: 2.2990 - val_loss: 8.4038 - val_mae: 2.0509 - val_mse: 8.4038\n",
            "Epoch 997/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.3941 - mae: 0.9353 - mse: 2.3941 - val_loss: 9.1630 - val_mae: 2.1559 - val_mse: 9.1630\n",
            "Epoch 998/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.5288 - mae: 1.0148 - mse: 2.5288 - val_loss: 8.9207 - val_mae: 2.1113 - val_mse: 8.9207\n",
            "Epoch 999/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.2807 - mae: 0.9486 - mse: 2.2807 - val_loss: 8.6620 - val_mae: 2.0836 - val_mse: 8.6620\n",
            "Epoch 1000/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.3267 - mae: 0.9691 - mse: 2.3267 - val_loss: 8.4873 - val_mae: 2.0789 - val_mse: 8.4873\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KummoA7tn0cz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "edf9671f-1607-4721-b33b-bb760e707524"
      },
      "source": [
        "model = build_model()\n",
        "\n",
        "# The patience parameter is the amount of epochs to check for improvement\n",
        "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
        "\n",
        "early_history = model.fit(x_train, y_train, \n",
        "                    epochs=EPOCHS, validation_split = 0.2, verbose=1, \n",
        "                    callbacks=[early_stop])"
      ],
      "execution_count": 279,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 579.7316 - mae: 22.7006 - mse: 579.7315 - val_loss: 541.8793 - val_mae: 21.8815 - val_mse: 541.8793\n",
            "Epoch 2/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 531.4675 - mae: 21.5990 - mse: 531.4675 - val_loss: 497.2432 - val_mae: 20.8240 - val_mse: 497.2432\n",
            "Epoch 3/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 486.3747 - mae: 20.5277 - mse: 486.3747 - val_loss: 450.5235 - val_mae: 19.6539 - val_mse: 450.5235\n",
            "Epoch 4/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 437.6641 - mae: 19.2965 - mse: 437.6641 - val_loss: 398.7807 - val_mae: 18.2910 - val_mse: 398.7807\n",
            "Epoch 5/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 384.3129 - mae: 17.9017 - mse: 384.3129 - val_loss: 343.7638 - val_mae: 16.7713 - val_mse: 343.7638\n",
            "Epoch 6/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 329.0893 - mae: 16.3590 - mse: 329.0893 - val_loss: 286.8764 - val_mae: 15.1671 - val_mse: 286.8764\n",
            "Epoch 7/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 271.7264 - mae: 14.7473 - mse: 271.7264 - val_loss: 228.8260 - val_mae: 13.4476 - val_mse: 228.8260\n",
            "Epoch 8/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 214.8775 - mae: 13.0345 - mse: 214.8775 - val_loss: 173.7717 - val_mae: 11.6572 - val_mse: 173.7717\n",
            "Epoch 9/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 161.7273 - mae: 11.2593 - mse: 161.7273 - val_loss: 125.2626 - val_mae: 9.8488 - val_mse: 125.2626\n",
            "Epoch 10/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 115.1348 - mae: 9.4684 - mse: 115.1348 - val_loss: 83.3284 - val_mae: 7.9882 - val_mse: 83.3284\n",
            "Epoch 11/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 77.7374 - mae: 7.6967 - mse: 77.7374 - val_loss: 54.2722 - val_mae: 6.3898 - val_mse: 54.2722\n",
            "Epoch 12/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 52.0265 - mae: 6.1608 - mse: 52.0265 - val_loss: 36.0331 - val_mae: 4.9999 - val_mse: 36.0331\n",
            "Epoch 13/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 36.5343 - mae: 5.0167 - mse: 36.5343 - val_loss: 27.1549 - val_mae: 4.2528 - val_mse: 27.1549\n",
            "Epoch 14/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 28.9175 - mae: 4.4491 - mse: 28.9175 - val_loss: 23.4438 - val_mae: 3.8784 - val_mse: 23.4438\n",
            "Epoch 15/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 25.3424 - mae: 4.1165 - mse: 25.3424 - val_loss: 21.2126 - val_mae: 3.6496 - val_mse: 21.2126\n",
            "Epoch 16/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 22.8849 - mae: 3.8703 - mse: 22.8849 - val_loss: 19.4139 - val_mae: 3.4540 - val_mse: 19.4139\n",
            "Epoch 17/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 20.7937 - mae: 3.6865 - mse: 20.7937 - val_loss: 17.8047 - val_mae: 3.2969 - val_mse: 17.8047\n",
            "Epoch 18/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 19.0785 - mae: 3.4704 - mse: 19.0785 - val_loss: 16.7417 - val_mae: 3.1937 - val_mse: 16.7417\n",
            "Epoch 19/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 17.5806 - mae: 3.3255 - mse: 17.5806 - val_loss: 15.7413 - val_mae: 3.1312 - val_mse: 15.7413\n",
            "Epoch 20/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 16.4535 - mae: 3.2094 - mse: 16.4535 - val_loss: 14.7811 - val_mae: 2.9833 - val_mse: 14.7811\n",
            "Epoch 21/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 15.4329 - mae: 3.0630 - mse: 15.4329 - val_loss: 13.6600 - val_mae: 2.8526 - val_mse: 13.6600\n",
            "Epoch 22/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 14.7665 - mae: 2.9329 - mse: 14.7665 - val_loss: 13.2277 - val_mae: 2.8057 - val_mse: 13.2277\n",
            "Epoch 23/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 14.6352 - mae: 2.8969 - mse: 14.6352 - val_loss: 12.8353 - val_mae: 2.7475 - val_mse: 12.8353\n",
            "Epoch 24/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 13.5741 - mae: 2.8083 - mse: 13.5741 - val_loss: 12.4958 - val_mae: 2.6926 - val_mse: 12.4958\n",
            "Epoch 25/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 13.1109 - mae: 2.7494 - mse: 13.1109 - val_loss: 12.2586 - val_mae: 2.6252 - val_mse: 12.2586\n",
            "Epoch 26/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 12.6301 - mae: 2.6595 - mse: 12.6301 - val_loss: 11.9046 - val_mae: 2.5903 - val_mse: 11.9046\n",
            "Epoch 27/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 12.2447 - mae: 2.6491 - mse: 12.2447 - val_loss: 11.6106 - val_mae: 2.5057 - val_mse: 11.6106\n",
            "Epoch 28/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 11.8870 - mae: 2.5908 - mse: 11.8870 - val_loss: 11.5184 - val_mae: 2.4864 - val_mse: 11.5184\n",
            "Epoch 29/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 11.7439 - mae: 2.5694 - mse: 11.7439 - val_loss: 11.1678 - val_mae: 2.4361 - val_mse: 11.1678\n",
            "Epoch 30/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 11.2882 - mae: 2.5361 - mse: 11.2882 - val_loss: 10.6729 - val_mae: 2.3815 - val_mse: 10.6729\n",
            "Epoch 31/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 11.1794 - mae: 2.5131 - mse: 11.1794 - val_loss: 10.6488 - val_mae: 2.3751 - val_mse: 10.6488\n",
            "Epoch 32/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 10.7020 - mae: 2.4440 - mse: 10.7020 - val_loss: 10.6505 - val_mae: 2.3471 - val_mse: 10.6505\n",
            "Epoch 33/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 10.7661 - mae: 2.4528 - mse: 10.7661 - val_loss: 10.3062 - val_mae: 2.3293 - val_mse: 10.3062\n",
            "Epoch 34/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 10.4601 - mae: 2.4293 - mse: 10.4601 - val_loss: 10.3243 - val_mae: 2.2924 - val_mse: 10.3243\n",
            "Epoch 35/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 10.2194 - mae: 2.3571 - mse: 10.2194 - val_loss: 10.3630 - val_mae: 2.2937 - val_mse: 10.3630\n",
            "Epoch 36/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 9.9922 - mae: 2.3442 - mse: 9.9922 - val_loss: 9.9988 - val_mae: 2.2665 - val_mse: 9.9988\n",
            "Epoch 37/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 9.8804 - mae: 2.3495 - mse: 9.8804 - val_loss: 9.9084 - val_mae: 2.2670 - val_mse: 9.9084\n",
            "Epoch 38/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 9.7227 - mae: 2.3427 - mse: 9.7227 - val_loss: 9.7394 - val_mae: 2.2231 - val_mse: 9.7394\n",
            "Epoch 39/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 9.7315 - mae: 2.3109 - mse: 9.7315 - val_loss: 9.6856 - val_mae: 2.2241 - val_mse: 9.6856\n",
            "Epoch 40/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 9.3315 - mae: 2.2772 - mse: 9.3315 - val_loss: 9.7607 - val_mae: 2.2326 - val_mse: 9.7607\n",
            "Epoch 41/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 9.1975 - mae: 2.2574 - mse: 9.1975 - val_loss: 9.5262 - val_mae: 2.1888 - val_mse: 9.5262\n",
            "Epoch 42/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 9.1349 - mae: 2.2468 - mse: 9.1349 - val_loss: 9.5368 - val_mae: 2.2031 - val_mse: 9.5368\n",
            "Epoch 43/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 8.9202 - mae: 2.2059 - mse: 8.9202 - val_loss: 9.2885 - val_mae: 2.1652 - val_mse: 9.2885\n",
            "Epoch 44/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 8.9256 - mae: 2.2343 - mse: 8.9256 - val_loss: 9.5256 - val_mae: 2.1939 - val_mse: 9.5256\n",
            "Epoch 45/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 8.5943 - mae: 2.2003 - mse: 8.5943 - val_loss: 9.3518 - val_mae: 2.1882 - val_mse: 9.3518\n",
            "Epoch 46/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 8.8284 - mae: 2.1880 - mse: 8.8284 - val_loss: 9.3219 - val_mae: 2.1360 - val_mse: 9.3219\n",
            "Epoch 47/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 8.4584 - mae: 2.1391 - mse: 8.4584 - val_loss: 9.3553 - val_mae: 2.2119 - val_mse: 9.3553\n",
            "Epoch 48/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 8.4873 - mae: 2.1563 - mse: 8.4873 - val_loss: 9.2125 - val_mae: 2.1688 - val_mse: 9.2125\n",
            "Epoch 49/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 8.5039 - mae: 2.1471 - mse: 8.5039 - val_loss: 9.1463 - val_mae: 2.1309 - val_mse: 9.1463\n",
            "Epoch 50/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 8.2051 - mae: 2.1223 - mse: 8.2051 - val_loss: 9.5160 - val_mae: 2.2742 - val_mse: 9.5160\n",
            "Epoch 51/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 8.1780 - mae: 2.1230 - mse: 8.1780 - val_loss: 9.7392 - val_mae: 2.2453 - val_mse: 9.7392\n",
            "Epoch 52/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 8.2963 - mae: 2.1385 - mse: 8.2963 - val_loss: 8.9890 - val_mae: 2.1666 - val_mse: 8.9890\n",
            "Epoch 53/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 7.8326 - mae: 2.0521 - mse: 7.8326 - val_loss: 8.9265 - val_mae: 2.1012 - val_mse: 8.9265\n",
            "Epoch 54/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 7.9180 - mae: 2.0608 - mse: 7.9180 - val_loss: 8.8536 - val_mae: 2.0993 - val_mse: 8.8536\n",
            "Epoch 55/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.8877 - mae: 2.0804 - mse: 7.8877 - val_loss: 8.8864 - val_mae: 2.1082 - val_mse: 8.8864\n",
            "Epoch 56/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.9937 - mae: 2.0731 - mse: 7.9937 - val_loss: 8.7210 - val_mae: 2.0920 - val_mse: 8.7210\n",
            "Epoch 57/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.6634 - mae: 2.0325 - mse: 7.6634 - val_loss: 8.9357 - val_mae: 2.1139 - val_mse: 8.9357\n",
            "Epoch 58/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 7.5959 - mae: 2.0472 - mse: 7.5959 - val_loss: 8.9073 - val_mae: 2.1395 - val_mse: 8.9073\n",
            "Epoch 59/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 7.7033 - mae: 2.0106 - mse: 7.7033 - val_loss: 8.9242 - val_mae: 2.1441 - val_mse: 8.9242\n",
            "Epoch 60/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 7.3346 - mae: 1.9996 - mse: 7.3346 - val_loss: 8.6869 - val_mae: 2.0865 - val_mse: 8.6869\n",
            "Epoch 61/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.6505 - mae: 2.0323 - mse: 7.6505 - val_loss: 8.6263 - val_mae: 2.0683 - val_mse: 8.6263\n",
            "Epoch 62/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 7.4540 - mae: 2.0218 - mse: 7.4540 - val_loss: 8.5852 - val_mae: 2.0670 - val_mse: 8.5852\n",
            "Epoch 63/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 7.5319 - mae: 2.0218 - mse: 7.5319 - val_loss: 8.5994 - val_mae: 2.0722 - val_mse: 8.5994\n",
            "Epoch 64/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 7.3925 - mae: 2.0125 - mse: 7.3925 - val_loss: 8.5131 - val_mae: 2.0788 - val_mse: 8.5131\n",
            "Epoch 65/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 7.4136 - mae: 2.0005 - mse: 7.4136 - val_loss: 8.7132 - val_mae: 2.1142 - val_mse: 8.7132\n",
            "Epoch 66/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7.1515 - mae: 2.0044 - mse: 7.1515 - val_loss: 8.6341 - val_mae: 2.0877 - val_mse: 8.6341\n",
            "Epoch 67/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 7.4062 - mae: 1.9831 - mse: 7.4062 - val_loss: 8.5192 - val_mae: 2.0760 - val_mse: 8.5192\n",
            "Epoch 68/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 7.1590 - mae: 1.9626 - mse: 7.1590 - val_loss: 8.5787 - val_mae: 2.0896 - val_mse: 8.5787\n",
            "Epoch 69/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 6.9777 - mae: 1.9604 - mse: 6.9777 - val_loss: 8.6504 - val_mae: 2.1088 - val_mse: 8.6504\n",
            "Epoch 70/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 7.1500 - mae: 1.9623 - mse: 7.1500 - val_loss: 8.5753 - val_mae: 2.0835 - val_mse: 8.5753\n",
            "Epoch 71/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 6.9938 - mae: 1.9516 - mse: 6.9938 - val_loss: 8.5564 - val_mae: 2.0761 - val_mse: 8.5564\n",
            "Epoch 72/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 6.8928 - mae: 1.9236 - mse: 6.8928 - val_loss: 8.8004 - val_mae: 2.1253 - val_mse: 8.8004\n",
            "Epoch 73/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 6.8283 - mae: 1.9343 - mse: 6.8283 - val_loss: 8.5129 - val_mae: 2.0811 - val_mse: 8.5129\n",
            "Epoch 74/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 6.8461 - mae: 1.9173 - mse: 6.8461 - val_loss: 8.4659 - val_mae: 2.0403 - val_mse: 8.4659\n",
            "Epoch 75/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.8586 - mae: 1.9211 - mse: 6.8586 - val_loss: 8.3356 - val_mae: 2.0269 - val_mse: 8.3356\n",
            "Epoch 76/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 6.8708 - mae: 1.9418 - mse: 6.8708 - val_loss: 8.4386 - val_mae: 2.0556 - val_mse: 8.4386\n",
            "Epoch 77/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 6.7926 - mae: 1.9446 - mse: 6.7926 - val_loss: 8.5012 - val_mae: 2.0701 - val_mse: 8.5012\n",
            "Epoch 78/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 6.6172 - mae: 1.8863 - mse: 6.6172 - val_loss: 8.5983 - val_mae: 2.1026 - val_mse: 8.5983\n",
            "Epoch 79/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 6.9705 - mae: 1.9361 - mse: 6.9705 - val_loss: 8.2986 - val_mae: 2.0294 - val_mse: 8.2986\n",
            "Epoch 80/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 6.6303 - mae: 1.8859 - mse: 6.6303 - val_loss: 8.4304 - val_mae: 2.0534 - val_mse: 8.4304\n",
            "Epoch 81/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 6.5491 - mae: 1.8826 - mse: 6.5491 - val_loss: 8.5560 - val_mae: 2.0535 - val_mse: 8.5560\n",
            "Epoch 82/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 6.6804 - mae: 1.8736 - mse: 6.6804 - val_loss: 8.4508 - val_mae: 2.0410 - val_mse: 8.4508\n",
            "Epoch 83/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 6.6595 - mae: 1.8945 - mse: 6.6595 - val_loss: 8.3209 - val_mae: 2.0226 - val_mse: 8.3209\n",
            "Epoch 84/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 6.8394 - mae: 1.9195 - mse: 6.8394 - val_loss: 8.3616 - val_mae: 2.0541 - val_mse: 8.3616\n",
            "Epoch 85/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.5304 - mae: 1.8721 - mse: 6.5304 - val_loss: 8.3855 - val_mae: 2.0165 - val_mse: 8.3855\n",
            "Epoch 86/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 6.5264 - mae: 1.8609 - mse: 6.5264 - val_loss: 8.4242 - val_mae: 2.0586 - val_mse: 8.4242\n",
            "Epoch 87/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 6.5035 - mae: 1.8725 - mse: 6.5035 - val_loss: 8.5903 - val_mae: 2.0695 - val_mse: 8.5903\n",
            "Epoch 88/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 6.6121 - mae: 1.8494 - mse: 6.6121 - val_loss: 8.4242 - val_mae: 2.0585 - val_mse: 8.4242\n",
            "Epoch 89/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 6.3885 - mae: 1.8462 - mse: 6.3885 - val_loss: 9.1170 - val_mae: 2.1509 - val_mse: 9.1170\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KpdvPQDzqW1Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "2841a984-aad6-4080-9590-8d6290a6b7ec"
      },
      "source": [
        "loss, mae, mse = model.evaluate(x_test, y_test, verbose=2)\n",
        "\n",
        "print(\"Testing set Mean Abs Error: {:5.2f} MPG\".format(mae))"
      ],
      "execution_count": 280,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3/3 - 0s - loss: 13.4944 - mae: 2.4653 - mse: 13.4944\n",
            "Testing set Mean Abs Error:  2.47 MPG\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mS5QRT2HqhWw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "26949116-a498-4983-d73b-751530d36093"
      },
      "source": [
        "test_predictions = model.predict(x_test)\n",
        "\n",
        "a = plt.axes(aspect='equal')\n",
        "plt.scatter(y_test, test_predictions)\n",
        "plt.xlabel('True Values [MPG]')\n",
        "plt.ylabel('Predictions [MPG]')\n",
        "lims = [0, 50]\n",
        "plt.xlim(lims)\n",
        "plt.ylim(lims)\n",
        "_ = plt.plot(lims, lims)\n"
      ],
      "execution_count": 283,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ffixSBHrAip",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}