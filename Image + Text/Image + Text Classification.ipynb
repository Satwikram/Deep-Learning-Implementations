{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Image + Text Classification.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOYo0UbkDJh9JxYUXgiCez3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Satwikram/Deep-Learning-Implementations/blob/master/Image%20%2B%20Text/Image%20%2B%20Text%20Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Author: Satwik Ram K"
      ],
      "metadata": {
        "id": "MpZ8RrqgfzUc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Connecting to kaggle"
      ],
      "metadata": {
        "id": "UQFQRWfFf2yo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-length",
                  "5271"
                ],
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": "OK"
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "XCBI92BOfqnD",
        "outputId": "37fac526-3901-4be4-95ca-8ac3abd29bb7"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-be28b1cf-6db7-4b7a-b2e5-d8a61bd96a6c\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-be28b1cf-6db7-4b7a-b2e5-d8a61bd96a6c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.upload()\n",
        "\n",
        "! mkdir ~/.kaggle\n",
        "\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "\n",
        "! chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Downloading the Dataset"
      ],
      "metadata": {
        "id": "hHfEgm9TgVzA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d fushenggg/3-class-cat-dog-car-dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1BmHp7ZkgBoe",
        "outputId": "de03a7b6-fb8f-4e40-a461-cac24cfd2662"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading 3-class-cat-dog-car-dataset.zip to /content\n",
            " 97% 120M/123M [00:02<00:00, 59.2MB/s] \n",
            "100% 123M/123M [00:03<00:00, 42.9MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d rmisra/news-headlines-dataset-for-sarcasm-detection"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P5Rv72tLgYsW",
        "outputId": "0a786c51-4589-4c24-bc44-52ca4118f4ef"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading news-headlines-dataset-for-sarcasm-detection.zip to /content\n",
            "\r  0% 0.00/3.30M [00:00<?, ?B/s]\n",
            "\r100% 3.30M/3.30M [00:00<00:00, 127MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/3-class-cat-dog-car-dataset.zip\n",
        "!unzip /content/news-headlines-dataset-for-sarcasm-detection.zip"
      ],
      "metadata": {
        "id": "515q0vzqg71T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importing Dependencies"
      ],
      "metadata": {
        "id": "SnGP9F_BiHgl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import string\n",
        "import re\n",
        "\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.layers import Dense, Input, Flatten, Conv2D, MaxPool2D, GlobalAveragePooling1D, BatchNormalization, Embedding, Bidirectional, LSTM\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import spacy\n",
        "from unicodedata import normalize\n",
        "\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "3Ck1RMEyhCnk"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading the data"
      ],
      "metadata": {
        "id": "3uupdAgqiq8a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_json(\"/content/Sarcasm_Headlines_Dataset.json\", lines=True)\n",
        "df.drop(columns=\"article_link\", axis=1, inplace = True)"
      ],
      "metadata": {
        "id": "JDEnNuJlikXH"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"is_sarcastic\"].value_counts().plot(kind=\"bar\");"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        },
        "id": "j8yfbt4hiujE",
        "outputId": "6173ad1a-d92d-46a6-d79b-392608be930c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cleaning the Data"
      ],
      "metadata": {
        "id": "DpVaDKr1leBi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])"
      ],
      "metadata": {
        "id": "fVLTw-V0ltPm"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text):\n",
        "\n",
        "    text = normalize(\"NFKD\", text) #Normalization\n",
        "\n",
        "    text = re.sub(r\"[^\\w\\s]\",\"\", text) #Remove Punc\n",
        "\n",
        "    text = \" \".join([token.lemma_ for token in nlp(text) if not token.is_stop])\n",
        "\n",
        "    text = re.sub(\"\\s+\", \" \", text)\n",
        "\n",
        "    return text"
      ],
      "metadata": {
        "id": "R-A5sxLFi0zg"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_img(fname):\n",
        "\n",
        "  target_size = (150, 150)\n",
        "  img = plt.imread(fname)\n",
        "\n",
        "  img = cv2.resize(img, target_size) \n",
        "\n",
        "  # Normalization\n",
        "  img = img/255.0\n",
        "\n",
        "  return img"
      ],
      "metadata": {
        "id": "qhXWETOsluJI"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Taking Dataset"
      ],
      "metadata": {
        "id": "OWmOBthxl65m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = Path(r\"/content/cats_dogs_cars/cats_dogs_cars/data\")\n",
        "\n",
        "labels = {\"car\": 0, \"cat\": 1, \"dog\": 2}\n",
        "\n",
        "X1 = []\n",
        "\n",
        "y1 = []\n",
        "\n",
        "for fname in tqdm(os.listdir(data_dir)):\n",
        "\n",
        "  img = clean_img(data_dir / fname)\n",
        "\n",
        "  X1.extend([img])\n",
        "  y1.extend([labels[fname.split(\".\")[0]]])\n",
        "\n",
        "X1 = np.array(X1)\n",
        "y1 = np.array(y1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j5RcozU6l3_y",
        "outputId": "5cae8b78-9dd9-48cf-fd97-28f04e0c46d5"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3000/3000 [00:11<00:00, 254.05it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"headline\"] = df[\"headline\"].apply(clean_text)\n",
        "\n",
        "X2 = df[\"headline\"].values\n",
        "y2 = df[\"is_sarcastic\"].values"
      ],
      "metadata": {
        "id": "KoFDz45zmqzM"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Text Tokenization"
      ],
      "metadata": {
        "id": "7AIZU_IooZBr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 10000\n",
        "embedding_dim = 16\n",
        "max_length = 150\n",
        "\n",
        "tokenizer = Tokenizer(num_words = vocab_size, oov_token = \"<oov>\")\n",
        "\n",
        "tokenizer.fit_on_texts(X2)\n",
        "sequence = tokenizer.texts_to_sequences(X2)\n",
        "\n",
        "X2 = pad_sequences(sequence, maxlen = max_length, truncating = \"post\")"
      ],
      "metadata": {
        "id": "hIWnfYjCoX_Q"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Spliting Data into Train and Test"
      ],
      "metadata": {
        "id": "R4Wt2DLgnhpI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train1, X_test1, y_train1, y_test1 = train_test_split(X1, y1, test_size = 0.2, random_state = 42, stratify=y1)\n",
        "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y2, test_size = 0.2, random_state = 42, stratify=y2)"
      ],
      "metadata": {
        "id": "_9ooFfikm58j"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Building the model"
      ],
      "metadata": {
        "id": "5ln2QUx6puwB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model():\n",
        "\n",
        "  input1 = Input(shape=X_train1[0].shape, name=\"Image Input Layer\")\n",
        "  input2 = Input(shape=X_train2[0].shape, name=\"Text Input Layer\")\n",
        "\n",
        "  x1 = Conv2D(filters=256, kernel_size=(5, 5), strides=(1, 1), padding=\"valid\", activation=\"relu\")(input1)\n",
        "  x1 = MaxPool2D(pool_size=(2,2))(x1)\n",
        "  x1 = BatchNormalization()(x1)\n",
        "\n",
        "  x1 = Conv2D(filters=128, kernel_size=(5, 5), strides=(1, 1), padding=\"valid\", activation=\"relu\")(x1)\n",
        "  x1 = MaxPool2D(pool_size=(2,2))(x1)\n",
        "  x1 = BatchNormalization()(x1)\n",
        "\n",
        "  x1 = Flatten()(x1)\n",
        "  x1 = Dense(units=512, activation=\"relu\")(x1)\n",
        "\n",
        "  output1 = Dense(units=3, activation=\"softmax\", name=\"image_output\")(x1)\n",
        "\n",
        "  x2 = Embedding(vocab_size, embedding_dim, input_length = max_length)(input2)\n",
        "  \n",
        "  x2 = Bidirectional(LSTM(64, return_sequences = True))(x2)\n",
        "  x2 = Bidirectional(LSTM(64))(x2)\n",
        "  x2 = Dense(64, activation = \"relu\")(x2)\n",
        "  \n",
        "  output2 = Dense(1, activation=\"sigmoid\", name=\"text_output\")(x2)\n",
        "\n",
        "  # Building Model\n",
        "  model = Model(inputs=[input1, input2], outputs=[output1, output2])\n",
        "\n",
        "  print(model.summary())\n",
        "\n",
        "  tf.keras.utils.plot_model(model, \"model.png\", show_shapes=True, show_dtype=True, dpi=300, expand_nested=True,\n",
        "                            show_layer_activations=True)\n",
        "  \n",
        "  \n",
        "  return model"
      ],
      "metadata": {
        "id": "dXC9xF8ApY8F"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_model()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EX5biLw9s7UE",
        "outputId": "ee464256-14c5-4275-8383-5dc5eb0f6d0b"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " Image Input Layer (InputLayer)  [(None, 150, 150, 3  0          []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 146, 146, 25  19456       ['Image Input Layer[0][0]']      \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " max_pooling2d_4 (MaxPooling2D)  (None, 73, 73, 256)  0          ['conv2d_5[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 73, 73, 256)  1024       ['max_pooling2d_4[0][0]']        \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 69, 69, 128)  819328      ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " Text Input Layer (InputLayer)  [(None, 150)]        0           []                               \n",
            "                                                                                                  \n",
            " max_pooling2d_5 (MaxPooling2D)  (None, 34, 34, 128)  0          ['conv2d_6[0][0]']               \n",
            "                                                                                                  \n",
            " embedding_2 (Embedding)        (None, 150, 16)      160000      ['Text Input Layer[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 34, 34, 128)  512        ['max_pooling2d_5[0][0]']        \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " bidirectional_4 (Bidirectional  (None, 150, 128)    41472       ['embedding_2[0][0]']            \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " flatten_2 (Flatten)            (None, 147968)       0           ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " bidirectional_5 (Bidirectional  (None, 128)         98816       ['bidirectional_4[0][0]']        \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " dense_8 (Dense)                (None, 512)          75760128    ['flatten_2[0][0]']              \n",
            "                                                                                                  \n",
            " dense_9 (Dense)                (None, 64)           8256        ['bidirectional_5[0][0]']        \n",
            "                                                                                                  \n",
            " image_output (Dense)           (None, 3)            1539        ['dense_8[0][0]']                \n",
            "                                                                                                  \n",
            " text_output (Dense)            (None, 1)            65          ['dense_9[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 76,910,596\n",
            "Trainable params: 76,909,828\n",
            "Non-trainable params: 768\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compiling the model"
      ],
      "metadata": {
        "id": "3FFPbD97ulU9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    loss = {\n",
        "        \"image_output\": tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "        \"text_output\": tf.keras.losses.BinaryCrossentropy(),\n",
        "    },\n",
        "\n",
        "    metrics = {\n",
        "        \"image_output\": 'accuracy',\n",
        "        \"text_output\": 'accuracy',\n",
        "    },\n",
        "\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        ")"
      ],
      "metadata": {
        "id": "6WHrrVE_uoCJ"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training the model"
      ],
      "metadata": {
        "id": "Vdf--UYVtl4t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train2.shape, y_train2.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ddc5I4L3xgvg",
        "outputId": "a444e816-c150-4ac9-a004-3b9c517a7f69"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((21367, 150), (21367,))"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x=[X_train1, X_train2], y=[y_train1, y_train2])"
      ],
      "metadata": {
        "id": "lJ8CBjw_s98h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "XYF-GOenvY5x"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}