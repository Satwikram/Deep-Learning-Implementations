{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Face Emotion Detection.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1yFxm-WWgM4MIA8CDDvaqiN8h14-F8Adm",
      "authorship_tag": "ABX9TyNwrhOOp8d9Z4Z/FsEHrKcZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Satwikram/Deep-Learning-Notebooks/blob/master/CNN/Face_Emotion_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2Z_adE6ymrW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "@Author: Satwik Ram K\n",
        "\n",
        "Face Emotion Detection using Tensorflow\n",
        "\n",
        "\"\"\"\n",
        "# Importing Libraries\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9LLKOqyKFgu4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_class = 6\n",
        "batch_size = 64\n",
        "img_size = (48, 48, 1)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WDeO81SqbG57",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! unzip /content/fer2013_1.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AyzmceV_GBjm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data_dir = '/content/fer2013_1/train'\n",
        "val_data_dir = '/content/fer2013_1/validation'"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03LKLJ_EGNV2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, BatchNormalization, Activation, Flatten"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90H0r2iOHwE5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSYeBlWsIAky",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Data Augmentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "    fill_mode = 'nearest',\n",
        "    rescale = 1./255,\n",
        "    rotation_range=30,\n",
        "    shear_range=0.3,\n",
        "    zoom_range=0.3,\n",
        "    width_shift_range=0.4,\n",
        "    height_shift_range=0.4,\n",
        "    horizontal_flip=True,\n",
        ")"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTVQ0e3ZIs1i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_datagen = ImageDataGenerator(rescale=1./255)\n"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sx3f79tVIwTS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "59de701b-9115-4e70-cb47-c4c9fb4cfd3c"
      },
      "source": [
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    color_mode = 'grayscale',\n",
        "    target_size = img_size[:2],\n",
        "    batch_size = batch_size,\n",
        "    class_mode = 'categorical' \n",
        ")"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 28273 images belonging to 6 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNVY3E7hJcV6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "06bfc3ed-7efa-4b38-f424-9058b2fa3f46"
      },
      "source": [
        "val_generator = val_datagen.flow_from_directory(\n",
        "    val_data_dir,\n",
        "    color_mode = 'grayscale',\n",
        "    target_size = img_size[:2],\n",
        "    batch_size = batch_size,\n",
        "    class_mode = 'categorical' \n",
        ")"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 3534 images belonging to 6 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WG5dhx0pJsmX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import ELU\n"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YNH12ZDDKCMa",
        "colab_type": "text"
      },
      "source": [
        "Building Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "laogAcaKJ6e6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model():\n",
        "\n",
        "  model = Sequential()\n",
        "\n",
        "  model.add(Conv2D(32, (5, 5), padding = \"same\", input_shape = img_size))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Dropout(0.2))\n",
        "\n",
        "  # Block #2: second CONV => RELU => CONV => RELU => POOL\n",
        "  # layer set\n",
        "  model.add(Conv2D(64, (5, 5), padding=\"same\"))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "  model.add(Conv2D(256, (5, 5), padding=\"same\"))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Dropout(0.2))\n",
        "\n",
        "  # Block #3: third CONV => RELU => CONV => RELU => POOL\n",
        "  # layer set\n",
        "  model.add(Conv2D(256, (5, 5), padding=\"same\"))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "  model.add(Conv2D(512, (5, 5), padding=\"same\"))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Dropout(0.2))\n",
        "\n",
        "  # Block #4: third CONV => RELU => CONV => RELU => POOL\n",
        "  # layer set\n",
        "  model.add(Conv2D(1024, (5, 5), padding=\"same\"))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "  model.add(Conv2D(1024, (5, 5), padding=\"same\"))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Dropout(0.2))\n",
        "\n",
        "  # Block #5: first set of FC => RELU layers\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(1024))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(0.5))\n",
        "\n",
        "  # Block #6: second set of FC => RELU layers\n",
        "  model.add(Dense(2048))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(0.5))\n",
        "\n",
        "  # Block #7: softmax classifier\n",
        "  model.add(Dense(num_class))\n",
        "  model.add(Activation(\"softmax\"))\n",
        "\n",
        "  return model"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UqU3N6DKqXi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = build_model()"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfvL2rGTK6Cu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fbc68730-dd39-4f4e-ff5d-6270c7c9d085"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_7 (Conv2D)            (None, 48, 48, 32)        832       \n",
            "_________________________________________________________________\n",
            "activation_10 (Activation)   (None, 48, 48, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_9 (Batch (None, 48, 48, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 24, 24, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 24, 24, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 24, 24, 64)        51264     \n",
            "_________________________________________________________________\n",
            "activation_11 (Activation)   (None, 24, 24, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_10 (Batc (None, 24, 24, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 24, 24, 256)       409856    \n",
            "_________________________________________________________________\n",
            "activation_12 (Activation)   (None, 24, 24, 256)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_11 (Batc (None, 24, 24, 256)       1024      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 12, 12, 256)       0         \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 12, 12, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 12, 12, 256)       1638656   \n",
            "_________________________________________________________________\n",
            "activation_13 (Activation)   (None, 12, 12, 256)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_12 (Batc (None, 12, 12, 256)       1024      \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 12, 12, 512)       3277312   \n",
            "_________________________________________________________________\n",
            "activation_14 (Activation)   (None, 12, 12, 512)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_13 (Batc (None, 12, 12, 512)       2048      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 6, 6, 512)         0         \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 6, 6, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 6, 6, 1024)        13108224  \n",
            "_________________________________________________________________\n",
            "activation_15 (Activation)   (None, 6, 6, 1024)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_14 (Batc (None, 6, 6, 1024)        4096      \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 6, 6, 1024)        26215424  \n",
            "_________________________________________________________________\n",
            "activation_16 (Activation)   (None, 6, 6, 1024)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_15 (Batc (None, 6, 6, 1024)        4096      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 3, 3, 1024)        0         \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 3, 3, 1024)        0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 9216)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1024)              9438208   \n",
            "_________________________________________________________________\n",
            "activation_17 (Activation)   (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_16 (Batc (None, 1024)              4096      \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 2048)              2099200   \n",
            "_________________________________________________________________\n",
            "activation_18 (Activation)   (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_17 (Batc (None, 2048)              8192      \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 6)                 12294     \n",
            "_________________________________________________________________\n",
            "activation_19 (Activation)   (None, 6)                 0         \n",
            "=================================================================\n",
            "Total params: 56,276,230\n",
            "Trainable params: 56,263,750\n",
            "Non-trainable params: 12,480\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zw54SD9eK-z9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.optimizers import RMSprop, SGD, Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "                     \n",
        "checkpoint = ModelCheckpoint(\"emotions.h5\",\n",
        "                             monitor=\"val_loss\",\n",
        "                             mode=\"min\",\n",
        "                             save_best_only = True,\n",
        "                             verbose=1)\n",
        "\n"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bScIy5c_LZVP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "earlystop = EarlyStopping(monitor = 'val_loss', \n",
        "                          min_delta = 0, \n",
        "                          patience = 3,\n",
        "                          verbose = 1,\n",
        "                          restore_best_weights = True)\n"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCqL7IFPLiUw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reduce_lr = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.2, patience = 3, verbose = 1, min_delta = 0.0001)\n",
        "\n",
        "# we put our call backs into a callback list\n",
        "callbacks = [earlystop, checkpoint, reduce_lr]\n"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51oUU4qwLlwg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We use a very small learning rate \n",
        "model.compile(loss = 'categorical_crossentropy',\n",
        "              optimizer = Adam(lr=0.001),\n",
        "              metrics = ['accuracy'])\n"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTD_Ggy5LoFM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nb_train_samples = 28291\n",
        "nb_validation_samples = 3534\n",
        "epochs = 10"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WaO-1JNILqHg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch = nb_train_samples // batch_size,\n",
        "    epochs = epochs,\n",
        "    callbacks = callbacks,\n",
        "    validation_data = val_generator,\n",
        "    validation_steps = nb_validation_samples // batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PrRT6cUoL23_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import sklearn\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "nb_train_samples = 28273\n",
        "nb_validation_samples = 3534\n",
        "\n",
        "# We need to recreate our validation generator with shuffle = false\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "        validation_data_dir,\n",
        "        color_mode = 'grayscale',\n",
        "        target_size=(img_rows, img_cols),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical',\n",
        "        shuffle=False)\n",
        "\n",
        "class_labels = validation_generator.class_indices\n",
        "class_labels = {v: k for k, v in class_labels.items()}\n",
        "classes = list(class_labels.values())\n",
        "\n",
        "#Confution Matrix and Classification Report\n",
        "Y_pred = model.predict_generator(validation_generator, nb_validation_samples // batch_size+1)\n",
        "y_pred = np.argmax(Y_pred, axis=1)\n",
        "\n",
        "print('Confusion Matrix')\n",
        "print(confusion_matrix(validation_generator.classes, y_pred))\n",
        "print('Classification Report')\n",
        "target_names = list(class_labels.values())\n",
        "print(classification_report(validation_generator.classes, y_pred, target_names=target_names))\n",
        "\n",
        "plt.figure(figsize=(8,8))\n",
        "cnf_matrix = confusion_matrix(validation_generator.classes, y_pred)\n",
        "\n",
        "plt.imshow(cnf_matrix, interpolation='nearest')\n",
        "plt.colorbar()\n",
        "tick_marks = np.arange(len(classes))\n",
        "_ = plt.xticks(tick_marks, classes, rotation=90)\n",
        "_ = plt.yticks(tick_marks, classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULita9TwPLo1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}