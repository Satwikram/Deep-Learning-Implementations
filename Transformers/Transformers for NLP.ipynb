{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transformers for NLP.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1o7w_UrapcnBRzj-tHSVcq5nIFJgqj16N",
      "authorship_tag": "ABX9TyO1mYD1MmsUTCuCZMF7KppC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Satwikram/Deep-Learning-Notebooks/blob/master/Transformers/Transformers%20for%20NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTAERX5F6ZHd",
        "colab_type": "text"
      },
      "source": [
        "Author: Satwik Ram K\n",
        "\n",
        "Implementaion of Transformer in NLP\n",
        "\n",
        "French to English Translation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nacuf3rC3hKW",
        "colab_type": "text"
      },
      "source": [
        "Imorting Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0D0I23EL33H9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import re\n",
        "import math \n",
        "import time"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RFvd6Qie4Kmh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "import tensorflow_datasets as tfds"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jfNDAEp-4Yvh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "41a2ec87-cd22-46fe-c283-c2978d1696f2"
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.2.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2KUdmBEs5l7S",
        "colab_type": "text"
      },
      "source": [
        "Loading data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XLwgA9EV4f23",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(\"/content/drive/My Drive/Transformers/europarl-v7.fr-en.en\", mode = 'r', encoding = 'utf-8') as f:\n",
        "  euro_eng = f.read()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "djw_LgJF6K0s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(\"/content/drive/My Drive/Transformers/europarl-v7.fr-en.fr\", mode = 'r', encoding = 'utf-8') as f:\n",
        "  euro_fr = f.read()"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1zFi1uMq6LtV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(\"/content/drive/My Drive/Transformers/P85-Non-Breaking-Prefix.en\", mode = 'r', encoding = 'utf-8') as f:\n",
        "  non_breaking_prefix_eng = f.read()"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCeTA_h86NfY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(\"/content/drive/My Drive/Transformers/P85-Non-Breaking-Prefix.fr\", mode = 'r', encoding = 'utf-8') as f:\n",
        "  non_breaking_prefix_fr = f.read()"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eWDak3y7V2K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "29d408e3-3bed-4496-98e5-f83bfe33fdba"
      },
      "source": [
        "euro_eng[:50]"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Resumption of the session\\nI declare resumed the se'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eUPhaiLx7lpA",
        "colab_type": "text"
      },
      "source": [
        "Cleaning the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iX42xGfG7hMB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "non_breaking_prefix_eng = non_breaking_prefix_eng.split(\"\\n\")\n",
        "non_breaking_prefix_eng = ['' + pref + '.' for pref in non_breaking_prefix_eng]"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCHaRfCS8ZmZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "non_breaking_prefix_fr = non_breaking_prefix_fr.split(\"\\n\")\n",
        "non_breaking_prefix_fr = ['' + pref + '.' for pref in non_breaking_prefix_fr]"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EtQvK1F78pbI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        },
        "outputId": "66f24e80-1f81-4975-df01-8bd8f5b5c93d"
      },
      "source": [
        "non_breaking_prefix_eng"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['a.',\n",
              " 'b.',\n",
              " 'c.',\n",
              " 'd.',\n",
              " 'e.',\n",
              " 'f.',\n",
              " 'g.',\n",
              " 'h.',\n",
              " 'i.',\n",
              " 'j.',\n",
              " 'k.',\n",
              " 'l.',\n",
              " 'm.',\n",
              " 'n.',\n",
              " 'o.',\n",
              " 'p.',\n",
              " 'q.',\n",
              " 'r.',\n",
              " 's.',\n",
              " 't.',\n",
              " 'u.',\n",
              " 'v.',\n",
              " 'w.',\n",
              " 'x.',\n",
              " 'y.',\n",
              " 'z.',\n",
              " 'messrs.',\n",
              " 'mlle.',\n",
              " 'mme.',\n",
              " 'mr.',\n",
              " 'mrs.',\n",
              " 'ms.',\n",
              " 'ph.',\n",
              " 'prof.',\n",
              " 'sr.',\n",
              " 'st.',\n",
              " 'a.m.',\n",
              " 'p.m.',\n",
              " 'vs.',\n",
              " 'i.e.',\n",
              " 'e.g.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xZtRlOo9ssr",
        "colab_type": "text"
      },
      "source": [
        "Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ppTkwqrs8vh0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpus_eng = euro_eng\n",
        "for prefix in non_breaking_prefix_eng:\n",
        "  corpus_eng = corpus_eng.replace(prefix, prefix + '###')\n",
        "\n",
        "corpus_eng = re.sub(r\"\\.(?=[A-Z]|[a-z]|[0-9])\", \".###\", corpus_eng)\n",
        "corpus_eng = re.sub(r\"\\.###\", \"\",  corpus_eng)\n",
        "corpus_eng = re.sub(r\"  +\", \"\",  corpus_eng)\n",
        "corpus_eng.split(\"\\n\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cIJknaxB_flu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpus_fr = euro_fr\n",
        "for prefix in non_breaking_prefix_fr:\n",
        "  corpus_fr = corpus_fr.replace(prefix, prefix + '###')\n",
        "\n",
        "corpus_fr = re.sub(r\"\\.(?=[A-Z]|[a-z]|[0-9])\", \".###\", corpus_fr)\n",
        "corpus_fr = re.sub(r\"\\.###\", \"\",  corpus_fr)\n",
        "corpus_fr = re.sub(r\"  +\", \"\",  corpus_fr)\n",
        "corpus_fr.split(\"\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJXSTMpSAFGC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer_eng = tfds.features.text.SubwordTextEncoder.build_from_corpus(\n",
        "    corpus_eng, target_vocab_size = 2**13\n",
        ")\n",
        "tokenizer_fr = tfds.features.text.SubwordTextEncoder.build_from_corpus(\n",
        "    corpus_fr, target_vocab_size = 2**13\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4ZTDIXpA8ZP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "VOCAB_SIZE_ENG = tokenizer_en.vovab_size + 2\n",
        "VOCAB_SIZE_FR = tokenizer_en.vovab_size + 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tN7g08znCHoi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inputs = [[VOCAB_SIZE_EN-2] + tokenizer_en.encode(sentence) + [VOCAB_SIZE_EN-1]\n",
        "          for sentence in corpus_eng]\n",
        "outputs = [[VOCAB_SIZE_FR-2] + tokenizer_fr.encode(sentence) + [VOCAB_SIZE_FR-1]\n",
        "           for sentence in corpus_fr]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rBZOzmA3DAzB",
        "colab_type": "text"
      },
      "source": [
        "Removing Longer Sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yc6joEuHCtJP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_LENGTH = 20\n",
        "idx_to_remove = [count for count, sent in enumerate(inputs)\n",
        "                 if len(sent) > MAX_LENGTH]\n",
        "for idx in reversed(idx_to_remove):\n",
        "    del inputs[idx]\n",
        "    del outputs[idx]\n",
        "idx_to_remove = [count for count, sent in enumerate(outputs)\n",
        "                 if len(sent) > MAX_LENGTH]\n",
        "for idx in reversed(idx_to_remove):\n",
        "    del inputs[idx]\n",
        "    del outputs[idx]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUPnti1cDP9l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inputs = tf.keras.preprocessing.sequence.pad_sequences(inputs,\n",
        "                                                       value=0,\n",
        "                                                       padding='post',\n",
        "                                                       maxlen=MAX_LENGTH)\n",
        "outputs = tf.keras.preprocessing.sequence.pad_sequences(outputs,\n",
        "                                                        value=0,\n",
        "                                                        padding='post',\n",
        "                                                        maxlen=MAX_LENGTH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "luWXYBg3Dkjs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "BUFFER_SIZE = 20000\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((inputs, outputs))\n",
        "\n",
        "dataset = dataset.cache()\n",
        "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}